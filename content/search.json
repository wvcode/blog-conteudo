[
  {
    "objectID": "walter.html",
    "href": "walter.html",
    "title": "Walter R. Paixão-Côrtes",
    "section": "",
    "text": "Walter é um profissional da área de TI com mais de 25 anos de experiência. Atualmente, trabalha como Product Line Manager na Dell Technologies e atua como Engenheiro Analista de Dados em projetos independentes.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2020\nMestrado em Ciência da Computação - 2015\nBacharelado em Ciência da Computação - 2002\n\nCTI - FURG\n\nTecnólogo em Processamento de Dados - 1993\n\n\n\n\nCertificados\n\nAnalista de Requisitos, IIBA - 2016\nScrum Master, ScrumAlliance, 2017\n\n\n\nExperiência\n\nDell Technologies\n\nProduct Line Manager - 2022 - …\nProduct Designer - 2019 - 2022\nPrincipal Soft. Engineer - 2017 - 2019\nLead Senior Software Engineer - 2008 - 2017\nLead Software Engineer - 2005 - 2008\n\nAccenture\n\nConsultor - 2003 - 2005\n\nBankorp Consultores Associados\n\nConsultor - 2001 - 2003\n\nBinário Internet\n\nLead Software Engineer - 1999 - 2001\n\nCSI - Consultoria e Sistemas de Informação\n\nSoftware Engineer - 1996 - 1999\n\nOutras Empresas\n\nEstagiário/Programador - 1993 - 1996"
  },
  {
    "objectID": "posts/data-010/index.html",
    "href": "posts/data-010/index.html",
    "title": "[VDP] - Introdução",
    "section": "",
    "text": "Olá Cientista de Dados!!!\nO curso de Visualização de Dados com Python tem por objetivo habilitar os alunos (e futuros Cientistas de Dados) a utilizar a linguagem Python para:\n\nrealizar análises de dados em grandes volumes e nos mais diferentes formatos\ncriar gráficos que transmitam a informação de maneira agradável e direta\naprender sobre tipos de visualização de dados que vão além dos gráficos de barras, linhas e tortas.\n\nAo longo do curso você irá aprender a utilizar algumas das bibliotecas Python mais famosas na área de Ciência de Dados: Requests, Pandas, Seaborn, MatplotLib, Plotly e muito mais.\nEntão, não perca mais tempo e comece o curso agora mesmo!\nUm abraço, Walter.\n\nNavegação\n\n\n\nAnterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre o Blog",
    "section": "",
    "text": "O WV Code é um blog de tecnologia criado por dois profissionais da área: Vanessa S.M. Paixão Côrtes e Walter R. Paixão Côrtes. Este blog tem por objetivo realizar a divulgação de conteúdo tecnológico de forma gratuita e em bom Português, tornando o vasto conteúdo de nossa área mais acessível para aqueles que estão iniciando na área e ainda não dominam o Inglês, bem como para quem ainda não consegue pagar por conteúdo on-line. Além de aprender com nossas publicações interativas, você pode ter acesso aos nossos repositórios de código no github.\n \n  \n   \n  \n    \n     Github\n  \n\n\n\n\nQuem faz o Blog?\n\nVanessa S.M. Paixão-Côrtes\nWalter R. Paixão-Côrtes"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html",
    "href": "posts/p0003-powerbiclient/index.html",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#introdução",
    "href": "posts/p0003-powerbiclient/index.html#introdução",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "href": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "title": "Power BI no Jupyter!",
    "section": "PowerBI - Rápida Introdução",
    "text": "PowerBI - Rápida Introdução\nO Power BI é uma poderosa ferramenta de business intelligence desenvolvida pela Microsoft, projetada para ajudar as empresas a visualizar e analisar seus dados de maneira intuitiva e interativa. Com recursos avançados de criação de relatórios, painéis e dashboards personalizados, o Power BI permite que os usuários transformem seus dados em informações acionáveis, facilitando a tomada de decisões informadas em tempo real. E todo esse poder pode ser entregue tanto de forma independente quanto integrada a outros meios, através do que chamamos de embedded reports.\n\nPower BI Embeddings\nAs capacidades de embedding do Power BI permitem que os desenvolvedores incorporem relatórios, painéis e visualizações interativas do Power BI diretamente em seus aplicativos, sites ou portais. Essa funcionalidade de integração oferece uma maneira flexível e personalizada de compartilhar informações e insights com usuários finais, proporcionando uma experiência perfeita e integrada. Com as capacidades de embedding do Power BI, os desenvolvedores podem aproveitar as APIs e SDKs disponíveis para incorporar visualizações interativas em seus aplicativos existentes, personalizar a aparência e a funcionalidade, controlar a segurança e permissões de acesso aos dados e até mesmo habilitar recursos como filtragem dinâmica e interação com os dados subjacentes. Essa flexibilidade permite que as organizações integrem as poderosas capacidades analíticas do Power BI diretamente em seus fluxos de trabalho, fornecendo aos usuários acesso direto a informações relevantes e atualizadas, tudo dentro do contexto de sua própria aplicação.\nEntre outros conhecimentos, para trabalhar com embeddings, é necessário compreender:\n\nLinguagens de programação: Ter conhecimentos básicos de programação é fundamental para interagir com as APIs e SDKs do Power BI. Python, JavaScript e .NET são exemplos de linguagens comumente usadas.\nDesenvolvimento web: Familiaridade com desenvolvimento web é importante para incorporar e personalizar visualizações do Power BI. Isso inclui conhecimentos em HTML, CSS e JavaScript para integrar o código do Power BI em aplicativos e sites.\nAutenticação e segurança: Compreender os conceitos de autenticação e autorização é crucial para garantir a segurança dos dados. Isso envolve entender como autenticar usuários no Power BI e definir permissões de acesso adequadas.\nPower BI Desktop e serviço Power BI: Ter conhecimento sobre o Power BI Desktop e o serviço Power BI é essencial. Isso inclui habilidades em criação de relatórios, painéis e visualizações interativas, além de recursos de filtragem e interação.\nModelagem e transformação de dados: Noções básicas de modelagem e transformação de dados são úteis para preparar os dados antes de incorporá-los. Isso envolve limpeza, filtragem e organização dos dados para criar visualizações eficazes.\n\nNeste post, exploraremos a integração do Power BI com o Jupyter Notebook, combinando a flexibilidade do ambiente de codificação do Python com a riqueza de recursos do Power BI. Descobriremos como utilizar a biblioteca powerbiclient para trazer o poder do Power BI para dentro de um Jupyter Notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "href": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "title": "Power BI no Jupyter!",
    "section": "Biblioteca powerbiclient",
    "text": "Biblioteca powerbiclient\nA biblioteca powerbiclient é uma ferramenta poderosa que permite interagir com o serviço do Power BI diretamente por meio de APIs. Essa biblioteca, desenvolvida pela Microsoft, fornece uma interface de programação fácil de usar para criar, publicar, atualizar e gerenciar relatórios, dashboards e conjuntos de dados no Power BI. Com o powerbiclient, os desenvolvedores podem automatizar tarefas, extrair informações e integrar o Power BI a aplicativos, permitindo a criação de soluções personalizadas e aprimorando a capacidade de visualização e análise de dados. Essa biblioteca é uma excelente opção para aqueles que desejam aproveitar ao máximo o ecossistema do Power BI e incorporar suas funcionalidades em seus próprios fluxos de trabalho e aplicativos.\nDentre todas as possibilidades que esta biblioteca oferece, vamos focar em como carregar gráficos interativos em Power BI dentro do nosso notebook Jupyter. E vamos lá, sem demora!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "href": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "title": "Power BI no Jupyter!",
    "section": "Preparando o ambiente",
    "text": "Preparando o ambiente\nComo sempre, o nosso primeiro passo é instalar as bibliotecas que estão faltando.\n$ pip install powerbiclient\n\nNosso próximo passo é inicializar o ambiente, chamando nossas bibliotecas.\n\n::: {#cell-11 .cell execution_count=4}\n``` {.python .cell-code}\nfrom powerbiclient import QuickVisualize, get_dataset_config, Report\nfrom powerbiclient.authentication import DeviceCodeLoginAuthentication\n\nimport pandas as pd\n:::\nDepois disso, vamos ao código de verdade!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "href": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "title": "Power BI no Jupyter!",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nA primeira tarefa, como em todo o trabalho de um cientista de dados, é carregar os dados em um DataFrame.\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "href": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "title": "Power BI no Jupyter!",
    "section": "Autenticando no Serviço do Power BI",
    "text": "Autenticando no Serviço do Power BI\nEm seguida, temos que fazer a autenticação no serviço do Power BI. O Power BI, como todos os aplicativos do Office 365, requer que estejamos autenticados para utiliza-los. Aqui, o processo é simplificado, mas ainda requerido. Esse modo é o mais simples, se estiver interessado em outras maneiras, dê uma olhada mais a fundo na documentação da Microsoft.\n\ndevice_auth = DeviceCodeLoginAuthentication()\n\nPerforming device flow authentication. Please follow the instructions below.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A8EL2Y8WJ to authenticate.\n\nDevice flow authentication successfully completed.\nYou are now logged in .\n\nThe result should be passed only to trusted code in your notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#visualizando",
    "href": "posts/p0003-powerbiclient/index.html#visualizando",
    "title": "Power BI no Jupyter!",
    "section": "Visualizando!",
    "text": "Visualizando!\nO próximo passo é plotar o gráfico usando o Power BI. Neste post vamos explorar a classe QuickVisualize que nos entregará um tipo de sumário dos nossos dados, como em uma Análise Exploratória de Dados. Para isso, enviamos nosso DataFrame, o objeto de autenticação e chamamos a função PBI_visualize.\n\n# Create a Power BI report from your data\nPBI_visualize = QuickVisualize(get_dataset_config(pokemons), auth=device_auth)\n\n# Render the new report\nPBI_visualize"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#finalizando",
    "href": "posts/p0003-powerbiclient/index.html#finalizando",
    "title": "Power BI no Jupyter!",
    "section": "Finalizando",
    "text": "Finalizando\nE desta forma, conseguimos trazer o Power BI e todo o seu poder para dentro do nosso notebook! E essa é apenas uma das formas que temos para trabalhar com Power BI dentro do notebook! Se você quiser aprender mais, não deixe de acessar a documentação da biblioteca powerbiclient em Power BI - Jupyter."
  },
  {
    "objectID": "posts/data-116/index.html",
    "href": "posts/data-116/index.html",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "",
    "text": "Olá Cientista de Dados!\nPara encerrarmos nosso curso com chave de ouro, iremos deixar dois gráficos prontos para serem utilizados em apresentações, levando em consideração as boas práticas.\nPara isso, vamos aprender a configurar o objeto Figure.\n\n\nO objeto Figure é a base para criar gráficos interativos com o Plotly em Python. Ele contém todas as informações necessárias para desenhar um gráfico completo, incluindo dados, layout e opções de estilo. As propriedades do objeto Figure podem ser divididas em três categorias principais: dados (data), layout e opções de estilo (config).\n\n\n\n\nDados (data): As propriedades do objeto Figure relacionadas aos dados são usadas para especificar os dados que serão plotados no gráfico. Isso inclui o tipo de gráfico, as séries de dados e as opções de estilo para cada série.\nLayout: As propriedades do objeto Figure relacionadas ao layout são usadas para especificar a aparência geral do gráfico, como os títulos, as legendas, as escalas e os eixos.\nOpções de estilo (config): As propriedades do objeto Figure relacionadas às opções de estilo são usadas para especificar as opções de estilo gerais para o gráfico, como o tema e a cor de fundo.\n\nEssas são as principais propriedades do objeto Figure do Plotly. Combinando essas propriedades de acordo com as necessidades do usuário, é possível criar gráficos altamente personalizados e interativos no Python."
  },
  {
    "objectID": "posts/data-116/index.html#introdução",
    "href": "posts/data-116/index.html#introdução",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "",
    "text": "Olá Cientista de Dados!\nPara encerrarmos nosso curso com chave de ouro, iremos deixar dois gráficos prontos para serem utilizados em apresentações, levando em consideração as boas práticas.\nPara isso, vamos aprender a configurar o objeto Figure.\n\n\nO objeto Figure é a base para criar gráficos interativos com o Plotly em Python. Ele contém todas as informações necessárias para desenhar um gráfico completo, incluindo dados, layout e opções de estilo. As propriedades do objeto Figure podem ser divididas em três categorias principais: dados (data), layout e opções de estilo (config).\n\n\n\n\nDados (data): As propriedades do objeto Figure relacionadas aos dados são usadas para especificar os dados que serão plotados no gráfico. Isso inclui o tipo de gráfico, as séries de dados e as opções de estilo para cada série.\nLayout: As propriedades do objeto Figure relacionadas ao layout são usadas para especificar a aparência geral do gráfico, como os títulos, as legendas, as escalas e os eixos.\nOpções de estilo (config): As propriedades do objeto Figure relacionadas às opções de estilo são usadas para especificar as opções de estilo gerais para o gráfico, como o tema e a cor de fundo.\n\nEssas são as principais propriedades do objeto Figure do Plotly. Combinando essas propriedades de acordo com as necessidades do usuário, é possível criar gráficos altamente personalizados e interativos no Python."
  },
  {
    "objectID": "posts/data-116/index.html#preparando-ambiente",
    "href": "posts/data-116/index.html#preparando-ambiente",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Preparando Ambiente",
    "text": "Preparando Ambiente\n\nimport pandas as pd\nimport duckdb as dk\nimport plotly.express as px\n\n# Importando as extensão para utilizar comandos SQL\n%reload_ext sql\n\n# Criando um banco de dados em memória, para otimizar performance\n%sql duckdb:///:memory:"
  },
  {
    "objectID": "posts/data-116/index.html#carregando-dados",
    "href": "posts/data-116/index.html#carregando-dados",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Carregando Dados",
    "text": "Carregando Dados\n\nsalaries = pd.read_csv('https://github.com/labeduc/datasets/blob/main/ds-salaries/ds_salaries.csv?raw=true')\n\n%sql CREATE TABLE IF NOT EXISTS salaries_full AS SELECT * FROM salaries\n\n*  duckdb:///:memory:\nDone.\n\n\n\n\n\nCount"
  },
  {
    "objectID": "posts/data-116/index.html#gerando-um-gráfico-de-barras",
    "href": "posts/data-116/index.html#gerando-um-gráfico-de-barras",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Gerando um Gráfico de Barras",
    "text": "Gerando um Gráfico de Barras\n\n%%sql\nSELECT *\n  FROM salaries_full\n WHERE job_title in ('Data Engineer', 'Data Scientist', 'Data Analyst')\n LIMIT 5\n\n*  duckdb:///:memory:\nDone.\n\n\n\n\n\nid\nwork_year\nexperience_level\nemployment_type\njob_title\nsalary\nsalary_currency\nsalary_in_usd\nemployee_residence\nremote_ratio\ncompany_location\ncompany_size\n\n\n\n\n16\n2020\nEN\nFT\nData Engineer\n4450000\nJPY\n41689\nJP\n100\nJP\nS\n\n\n22\n2020\nSE\nFT\nData Engineer\n42000\nEUR\n47899\nGR\n50\nGR\nL\n\n\n27\n2020\nSE\nFT\nData Engineer\n720000\nMXN\n33511\nMX\n0\nMX\nS\n\n\n35\n2020\nMI\nFT\nData Engineer\n65000\nEUR\n74130\nAT\n50\nAT\nL\n\n\n43\n2020\nMI\nFT\nData Engineer\n106000\nUSD\n106000\nUS\n100\nUS\nL\n\n\n\n\n\nO gráfico de barras deve comparar o salário de três cargos: Data Engineer, Data Scientist, Data Analyst ao longo do tempo.\n\n%%sql \nsal_gb &lt;&lt; select work_year, job_title, avg(salary_in_usd) as avg_salary_in_usd \n            from salaries_full\n           where job_title in ('Data Engineer', 'Data Scientist', 'Data Analyst') \n        group by work_year, job_title\n\n*  duckdb:///:memory:\nDone.\n\n\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title')\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "posts/data-116/index.html#escolhendo-o-tipo-de-gráfico",
    "href": "posts/data-116/index.html#escolhendo-o-tipo-de-gráfico",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Escolhendo o Tipo de Gráfico",
    "text": "Escolhendo o Tipo de Gráfico\nNesse primeiro passo de otimização, temos que refletir se o gráfico proposto realmente entrega de maneira clara a informação que foi solicitada. Olhando a tabela de Gráficos X Objetivos da nossa primeira aula, podemos perceber que sim, o gráfico de barra é o mais indicado.\n\n\n\nVisualização X Objetivo\n\n\nNo entanto, esse formato de barra empilhada (stacked) não permite uma boa comparação ano a ano de cada série de informação. Talvez seja melhor apenas colocar as barras lado a lado.\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title', barmode=\"group\")\n\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#adicionando-título",
    "href": "posts/data-116/index.html#adicionando-título",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Adicionando Título",
    "text": "Adicionando Título\nPara iniciar nossas configurações do gráfico, vamos utilizar o approach utilizar a função update_layout(). Esta função recebe um objeto contendo a configuração para plotar o gráfico.\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title', barmode=\"group\")\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#ajustando-legenda",
    "href": "posts/data-116/index.html#ajustando-legenda",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Ajustando Legenda",
    "text": "Ajustando Legenda\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title', barmode=\"group\")\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n    \"legend\": {\"title\": {\"text\": \"Cargos\"}}\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#ajustando-eixos",
    "href": "posts/data-116/index.html#ajustando-eixos",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Ajustando Eixos",
    "text": "Ajustando Eixos\nAgora, vamos remover o eixo Y, além de corrigir o título do eixo X.\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title', barmode=\"group\")\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n    \"legend\": {\"title\": {\"text\": \"Cargos\"}},\n    \"yaxis\": {\"visible\": False},\n    \"xaxis\": {\"title\": \"Ano\"},\n    \"margin\": {\"l\": 10, \"b\": 10}\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#removendo-background",
    "href": "posts/data-116/index.html#removendo-background",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Removendo Background",
    "text": "Removendo Background\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', color='job_title', barmode=\"group\")\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n    \"legend\": {\"title\": {\"text\": \"Cargos\"}},\n    \"yaxis\": {\"visible\": False},\n    \"xaxis\": {\"title\": \"Ano\"},\n    \"margin\": {\"l\": 10, \"b\": 10},\n    \"plot_bgcolor\": \"#FFFFFF\",\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#adicionando-labels",
    "href": "posts/data-116/index.html#adicionando-labels",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Adicionando Labels",
    "text": "Adicionando Labels\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', \n             text='avg_salary_in_usd', \n             text_auto=\".2s\", \n             color='job_title', \n             barmode=\"group\")\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n    \"legend\": {\"title\": {\"text\": \"Cargos\"}},\n    \"yaxis\": {\"visible\": False},\n    \"xaxis\": {\"title\": \"Ano\"},\n    \"margin\": {\"l\": 10, \"b\": 10},\n    \"plot_bgcolor\": \"#FFFFFF\"\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#ajustando-a-tooltip",
    "href": "posts/data-116/index.html#ajustando-a-tooltip",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Ajustando a Tooltip",
    "text": "Ajustando a Tooltip\n\nfig = px.bar(sal_gb, x='work_year', y='avg_salary_in_usd', \n             text='avg_salary_in_usd', \n             text_auto=\".2s\", \n             color='job_title', \n             barmode=\"group\",\n             labels={ \"work_year\": \"Ano\", \"avg_salary_in_usd\": \"Salário\", \"job_title\": \"Cargo\"})\n\nconfiguracao = {\n    \"title\": {\"text\": \"Comparação dos Salários\"},\n    \"legend\": {\"title\": {\"text\": \"Cargos\"}},\n    \"yaxis\": {\"visible\": False},\n    \"xaxis\": {\"title\": \"Ano\"},\n    \"margin\": {\"l\": 10, \"b\": 10},\n    \"plot_bgcolor\": \"#FFFFFF\",\n}\n\nfig.update_layout(configuracao)\nfig.show(renderer='notebook')"
  },
  {
    "objectID": "posts/data-116/index.html#conclusão",
    "href": "posts/data-116/index.html#conclusão",
    "title": "[VDP] Aula 16 - Criando Visualizações Efetivas",
    "section": "Conclusão",
    "text": "Conclusão\nEntão, chegamos ao final desta aula e ao final do nosso curso!\nSe você quiser saber mais sobre a configuração do plotly, clique aqui.\nE se você quiser aprender mais sobre Ciência de Dados e Visualização, dê uma olhada nos links abaixo:\n\nFerramentas de Visualização\n\nPower BI Community - https://community.powerbi.com/\nPower BI DEV Camp - https://www.powerbidevcamp.net/\nMain Tableau Site - https://www.tableau.com/\nPublic Tableau - https://public.tableau.com/s/\nGrafana Main Portal - https://grafana.com/\nGrafana Cloud - https://grafana.com/products/cloud/?plcmt=nav-products-cta1&cta=cloud\n\nOutros sites\n\nPython Graph Gallery - https://www.python-graph-gallery.com\nCanais no Youtube\n\nMS Power BI - https://www.youtube.com/c/MSPowerBI\nHashtag Treinamentos - https://www.youtube.com/c/HashtagTreinamentos\nInformation Lab - https://www.youtube.com/c/TheInformationLabCoUK\nArt of Visualization - https://www.youtube.com/c/ArtofVisualization\nAndy Kriebel - https://www.youtube.com/c/AndyKriebel\n\nData Viz Project - https://datavizproject.com/\nWTF Viz - https://viz.wtf/\n538 News - https://fivethirtyeight.com/\nStorytelling with data - https://www.storytellingwithdata.com/\n\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-114/index.html",
    "href": "posts/data-114/index.html",
    "title": "[VDP] Aula 14 - Pandas e Bancos de Dados",
    "section": "",
    "text": "Olá Cientista de Dados!\nEstamos chegando quase no fim do nosso curso, então vamos fazer a preparação para o que vem por aí!\nDurante nosso aprendizado de Visualização de Dados, utilizamos conjuntos de dados que são armazenados em arquivos, do tipo CSV ou JSON (os mais populares), ou ainda modelos mais avançados como PARQUET.\nMas quando o volume de dados cresce exponencialmente ou você está em um ambiente corporativo, é necessário saber manipular bancos de dados. Bancos de dados são uma tecnologia incrível, que nos permite armazenar nossos dados de maneira simples e segura, distribuída e que nos permite, quando bem configurado, recuperar essa informação muito rapidamente.\nO que torna os bancos de dados tão interessantes de usar é a linguagem SQL, que nos permite armazenar e recuperar informações de maneira estruturada e eficente. A linguagem SQL é tão importante para o ecossistema de bancos de dados, que ela já está integrada a maior parte das outras linguagens de programação, seja através de bibliotecas que permitem executar instruções SQL a partir de códigos C#, Java, Python e assim por diante, ou através de integrações mais profundas, como alternar entre SQL e Python em um Jupyter notebook.\nE mesmo após esse texto motivacional, você deve estar se perguntando: o que vou fazer com esse conhecimento, se não entendo nada de banco de dados? Então, essa aula pode ser pulada sem problema por agora, mas é aconselhável que você volte assim que aprender mais sobre bancos de dados.\nE se você já conhece o básico, continue aqui com a gente!"
  },
  {
    "objectID": "posts/data-114/index.html#introdução",
    "href": "posts/data-114/index.html#introdução",
    "title": "[VDP] Aula 14 - Pandas e Bancos de Dados",
    "section": "",
    "text": "Olá Cientista de Dados!\nEstamos chegando quase no fim do nosso curso, então vamos fazer a preparação para o que vem por aí!\nDurante nosso aprendizado de Visualização de Dados, utilizamos conjuntos de dados que são armazenados em arquivos, do tipo CSV ou JSON (os mais populares), ou ainda modelos mais avançados como PARQUET.\nMas quando o volume de dados cresce exponencialmente ou você está em um ambiente corporativo, é necessário saber manipular bancos de dados. Bancos de dados são uma tecnologia incrível, que nos permite armazenar nossos dados de maneira simples e segura, distribuída e que nos permite, quando bem configurado, recuperar essa informação muito rapidamente.\nO que torna os bancos de dados tão interessantes de usar é a linguagem SQL, que nos permite armazenar e recuperar informações de maneira estruturada e eficente. A linguagem SQL é tão importante para o ecossistema de bancos de dados, que ela já está integrada a maior parte das outras linguagens de programação, seja através de bibliotecas que permitem executar instruções SQL a partir de códigos C#, Java, Python e assim por diante, ou através de integrações mais profundas, como alternar entre SQL e Python em um Jupyter notebook.\nE mesmo após esse texto motivacional, você deve estar se perguntando: o que vou fazer com esse conhecimento, se não entendo nada de banco de dados? Então, essa aula pode ser pulada sem problema por agora, mas é aconselhável que você volte assim que aprender mais sobre bancos de dados.\nE se você já conhece o básico, continue aqui com a gente!"
  },
  {
    "objectID": "posts/data-114/index.html#problema",
    "href": "posts/data-114/index.html#problema",
    "title": "[VDP] Aula 14 - Pandas e Bancos de Dados",
    "section": "Problema",
    "text": "Problema\nImagine a seguinte situação: você tem um arquivo realmente grande, com vários milhões de linhas, que você precisa carregar em um DataFrame pandas para fazer algumas análises. Ao tentar carregar o arquivo utilizando o método tradicional do pandas, usando a função read_csv(), tudo parece estar funcionando normal, mas após executar algumas operações, seu notebook começa a reclamar de falta de memória para processar os dados.\nPorque isso aconteceu? Isso é uma dos poucos problemas de pandas, cada transformação que fazemos em pandas normalmente gera um novo DataFrame, o que vai consumindo cada vez mais memória. Existe no próprio pandas uma maneira de resolver isso: muitas funções tem um parâmetro inplace que quando setamos o valor para True, ele altera o DataFrame corrente.\nSeguindo o nosso cenário, adicionamos o parâmetro em algumas de nossas transformações e realmente a utilização da memória se reduz significativamente. No entanto, ao conseguirmos rodar toda a rotina, percebemos que ela está com uma performance bem ruim.\nNeste caso, podemos tentar outras alternativas, como trocar pandas por Polars, que é outra biblioteca de manipulação e transformação de dados, ou utilizar bancos de dados."
  },
  {
    "objectID": "posts/data-114/index.html#passo-a-passo",
    "href": "posts/data-114/index.html#passo-a-passo",
    "title": "[VDP] Aula 14 - Pandas e Bancos de Dados",
    "section": "Passo a Passo",
    "text": "Passo a Passo\nExistem duas maneiras de se trabalhar com bancos de dados no nosso cenário: - Carregamos todos os dados em banco de dados, e partir daí: - Fazemos todas as análises utilizando uma ferramenta de SQL ou algo similar - Fazemos as análises misturando SQL e outra linguagem de programação, tanto em um script/programa ou em um notebook.\nNesta última aula, iremos abordar como utilizar SQL em conjunto com Python em nossos notebooks no Google Colab.\n\nPasso 1 - Importar as bibliotecas que iremos utilizar\n\nimport pandas as pd\nimport os\nimport duckdb\n\n%reload_ext sql\n\nTemos duas novidades: estamos importando uma nova biblioteca, chamada duckdb, que nos permitirá criar um banco de dados otimizado para análises. Você pode utilizar qualquer banco de dados.\nA outra novidade é o comando %reload_ext sql. Esse comando carrega no contexto do notebook as bibliotecas jupysql e SqlAlchemy que nos permitem conectar a diversos bancos de dados e escrever SQL direto no notebook.\nTambém temos mais algumas configurações que precisam ser feitas:\n\n%config SqlMagic.autopandas = True\n%config SqlMagic.feedback = False\n%config SqlMagic.displaycon = False\n\n\n\nPasso 2 - Iniciar um novo banco de dados\n\nif os.path.exists('./db.duckdb'):\n  print('Este banco de dados já foi criado, vamos apaga-lo!')\n  os.remove('./db.duckdb')\n\n\n%sql duckdb:///db.duckdb\n\nAqui também temos uma novidade: estamos criando um novo banco de dados, indicando na conexão que é do tipo duckdb. Este banco será criado na pasta onde estou executando, no meu computador local, ou no caso do Google Colab, na pasta padrão de arquivos (content).\n\n\nPasso 3 - Carregar os dados\nPara isso, utilizamos a sintaxe %sql que nos permite utilizar uma linha de comando SQL em meio a código Python, como na situação abaixo:\n\ntable_name = 'test_tbl2'\nfile_name = 'teste.txt'\n\n%sql create table {table_name} as select * from read_csv_auto('{file_name}')\n\n\n\n\n\n\n\n\nCount\n\n\n\n\n0\n2\n\n\n\n\n\n\n\nO código acima cria uma tabela no banco de dados com o conteúdo arquivo que foi referenciado. Ao final, mostra a contagem de linhas que foram carregadas.\nQuando queremos usar apenas SQL na célula, podemos utilizar o %%sql:\n\n%%sql\nselect * \nfrom test_tbl\n\n\n\n\n\n\n\n\nc1\nc2\n\n\n\n\n0\n1\n'test'\n\n\n1\n2\n'test2'\n\n\n\n\n\n\n\nAgora, depois desta pequena demonstração, vamos ao nosso exemplo mais real: vamos carregar os nossos dados em uma tabela no banco de dados, realizar uma SQL query para extrair da tabela apenas as linhas que interessam para nossa análise, e então, fazer a plotagem dos dados.\n\n\nPasso 4 - Vendo um exemplo do início ao fim\n\n# Código para baixar um arquivo da internet\nimport requests as r # importa a biblioteca de manipulação de requests\n\n# faz uma chamada para um arquivo texto que está na internet\nconteudo_arquivo = r.get('https://github.com/labeduc/datasets/blob/main/pokemons/all.csv?raw=true')\n\n# Grava o conteúdo que foi baixado em um arquivo local\nwith open('pokemons.csv', 'w', encoding='utf-8') as fw:\n    fw.write(conteudo_arquivo.text)\n\n\n# Carregando dados no arquivo.\n%sql create table pokemons as select * from read_csv_auto('pokemons.csv')\n\n\n\n\n\n\n\n\nCount\n\n\n\n\n0\n1032\n\n\n\n\n\n\n\n\n# Agora precisamos trazer o resultado da media de ataque por geração de pokemon\n\n%sql pokemons_agg &lt;&lt; SELECT Generation, AVG(Att) as AvgAtt FROM pokemons group by Generation\n\n\npokemons_agg\n\n\n\n\n\n\n\n\nGeneration\nAvgAtt\n\n\n\n\n0\n1.0\n72.913907\n\n\n1\n6.0\n95.879699\n\n\n2\n7.0\n86.112069\n\n\n3\n8.0\n83.417391\n\n\n4\n2.0\n68.260000\n\n\n5\n3.0\n74.021739\n\n\n6\n4.0\n79.991379\n\n\n7\n5.0\n82.447853\n\n\n\n\n\n\n\nE a partir daqui, podemos começar a plotar nosso gráfico.\n\nimport seaborn as sns\n\n\nsns.barplot(pokemons_agg, x='Generation',  y='AvgAtt')\n\n\n\n\n\n\n\n\n\n\nPasso 5 - Fechando a conexão\n\n%sql --conn --close"
  },
  {
    "objectID": "posts/data-114/index.html#conclusão",
    "href": "posts/data-114/index.html#conclusão",
    "title": "[VDP] Aula 14 - Pandas e Bancos de Dados",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula, conseguimos aprender como podemos integrar bancos de dados em nossos notebooks para tirar vantagem de sua grande capacidade de armazenamento e da linguagem SQL para realizar transformações nos dados e gerar nossos DataFrames.\nSeparamos alguns links para você se familiarizar mais com o assunto de bancos de dados: - Documentação DuckDb - Porque usar DuckDb? Leia aqui uma resposta - Rodando SQL em Jupyter notebooks-usando JUPYSQL (com duckdb e mysql)\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-112/index.html",
    "href": "posts/data-112/index.html",
    "title": "[VDP] Aula 12 - Visualizando Sankey Charts",
    "section": "",
    "text": "Olá Cientista de Dados!\nMais uma aula chegando, e hoje vamos apresentar para vocês mais um gráfico extremamente interessante, o Sankey Chart.\nO Sankey Chart ou Diagrama de Sankey é uma forma de visualização de dados desenvolvida durate a revolução industrial. O método de análise foi criado pelo capitão irlandês Matthew Sankey.\nO diagrama de Sankey é uma representação visual da relação entre duas variáveis, que possui um ponto de partida e pelo menos um ponto de chegada. Vamos ao nosso exemplo."
  },
  {
    "objectID": "posts/data-112/index.html#introdução",
    "href": "posts/data-112/index.html#introdução",
    "title": "[VDP] Aula 12 - Visualizando Sankey Charts",
    "section": "",
    "text": "Olá Cientista de Dados!\nMais uma aula chegando, e hoje vamos apresentar para vocês mais um gráfico extremamente interessante, o Sankey Chart.\nO Sankey Chart ou Diagrama de Sankey é uma forma de visualização de dados desenvolvida durate a revolução industrial. O método de análise foi criado pelo capitão irlandês Matthew Sankey.\nO diagrama de Sankey é uma representação visual da relação entre duas variáveis, que possui um ponto de partida e pelo menos um ponto de chegada. Vamos ao nosso exemplo."
  },
  {
    "objectID": "posts/data-112/index.html#problema",
    "href": "posts/data-112/index.html#problema",
    "title": "[VDP] Aula 12 - Visualizando Sankey Charts",
    "section": "Problema",
    "text": "Problema\nVoltando ao nosso conjunto de dados de pokemons, vamos supor que gostaríamos de ver a distribuição de pokemons levando em consideração a geração e o seu tipo. Você prontamente pensou em fazer uma tabela, assim como 90% dos outros analistas. Mas, ao entregar a tabela, você percebe que fica difícil de mostrar visualmente como as gerações contribuem para cada tipo, bem como ter uma idéia do total de pokemons por tipo considerando todas as gerações. A única maneira de fazer isso seria criar outra tabela, que mostra a informação agrupada de outra forma.\nO Diagrama de Sankey serve para esses casos onde desejamos visualizar a relação entre duas categorias em um só lugar, não importando como o dado está organizado."
  },
  {
    "objectID": "posts/data-112/index.html#passo-a-passo",
    "href": "posts/data-112/index.html#passo-a-passo",
    "title": "[VDP] Aula 12 - Visualizando Sankey Charts",
    "section": "Passo a Passo",
    "text": "Passo a Passo\n\nCarregando biblioteca e dados\n\nimport pandas as pd\nimport plotly.graph_objects as go  # biblioteca nova - plotly\n\n# carregando os dados da internet\ndf = pd.read_csv('https://github.com/labeduc/datasets/blob/main/pokemons/all.csv?raw=true')\n\n# filtrando apenas as colunas que nos interessam\ntipos = df[['Generation', 'Type 1', 'Number']]\n\n# agregando os dados para reduzir o número de data points\nagg = tipos.groupby(['Generation', 'Type 1']).count().reset_index()\n\n\n\nPreparando os dados\nAssim como vimos no gráfico de rede, precisamos estabelecer quem são nossos nodos e quais os valores dos vertices.\n\n\nnodes = {}\nidx = 0\n\n# Primeira parte da preparação é pegar todos os possíveis nodos dos nossos dados\n# (que são as gerações e tipos) e salvar em um dicionário, onde também atribuímos\n# um índice numérico\n\nfor item in agg[\"Generation\"]:\n  if item not in nodes:\n    nodes[item] = idx\n    idx += 1\n\nfor item in agg[\"Type 1\"]:\n  if item not in nodes:\n    nodes[item] = idx\n    idx += 1\n\n# Depois criamos a estrutura que será usada para a plotagem\nlink = {\n    \"source\": [nodes[item] for item in agg[\"Generation\"]], # adicionamos todos os nodos de origem, mas em vez da descrição, utilizamos os índices \n    \"target\": [nodes[item] for item in agg[\"Type 1\"]], # adicionamos todos os nodos de destino, mas em vez da descrição, utilizamos os índices  \n    \"value\": agg[\"Number\"].tolist()\n    }\n\n\n\nPlotando o Gráfico\n\n# Próximo passo é agregar os labels dos dados, que são as chaves no nosso dicionário de nodos\nrawdata = {\n  \"node\": {\"label\": list(nodes.keys())},\n  \"link\": link\n}\n\n# Criamos o diagrama\ndata = go.Sankey(**rawdata)\n\n# Fazemos a plotagem\nfig = go.Figure(data=data)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nE aí está o gráfico. Uma das vantagens de se usar a biblioteca plotly é que os gráficos se tornam interativos. Pode ir ali passar o mouse em cima e você vai ver os tooltips, dando informações interessantes sobre os dados. Assim, podemos analisar tanto pelo lado das gerações quando pelo lado dos tipos e ter totalizadores, sem precisar gerar mais gráficos."
  },
  {
    "objectID": "posts/data-112/index.html#conclusão",
    "href": "posts/data-112/index.html#conclusão",
    "title": "[VDP] Aula 12 - Visualizando Sankey Charts",
    "section": "Conclusão",
    "text": "Conclusão\nE este foi mais um gráfico que aprendemos a usar. Lembre-se que ele pode ser usado para descobrir relações entre variáveis categóricas, em múltiplos níveis.\nTambém foi uma oportunidade para aprender uma nova biblioteca de plotagem de gráficos, a plotly. Veremos essa biblioteca em maior detalhe em uma aula futura.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-110/index.html",
    "href": "posts/data-110/index.html",
    "title": "[VDP] Aula 10 - Seaborn - Melhorando seus Visuais",
    "section": "",
    "text": "Olá Cientista de Dados!\nSe você chegou até aqui, você já se familiarizou com o básico das bibliotecas seaborn, matplotlib e pandas! Esse conhecimento já garante a você a capacidade de realizar análises de dados e apresentar resultados de maneira simples e eficiente.\nO próximo passo é ensiná-lo a dar a esses gráficos uma aparência extremamente profissional e que leve em conta as boas práticas da área de Visualização de Dados. Para isso, vamos apresentar um pequeno problema e a versão inicial da visualização com o conhecimento que temos e, depois, apresentamos o passo a passo com as boas práticas e como codifica-las, chegando a nossa versão final da visualização."
  },
  {
    "objectID": "posts/data-110/index.html#introdução",
    "href": "posts/data-110/index.html#introdução",
    "title": "[VDP] Aula 10 - Seaborn - Melhorando seus Visuais",
    "section": "",
    "text": "Olá Cientista de Dados!\nSe você chegou até aqui, você já se familiarizou com o básico das bibliotecas seaborn, matplotlib e pandas! Esse conhecimento já garante a você a capacidade de realizar análises de dados e apresentar resultados de maneira simples e eficiente.\nO próximo passo é ensiná-lo a dar a esses gráficos uma aparência extremamente profissional e que leve em conta as boas práticas da área de Visualização de Dados. Para isso, vamos apresentar um pequeno problema e a versão inicial da visualização com o conhecimento que temos e, depois, apresentamos o passo a passo com as boas práticas e como codifica-las, chegando a nossa versão final da visualização."
  },
  {
    "objectID": "posts/data-110/index.html#problema",
    "href": "posts/data-110/index.html#problema",
    "title": "[VDP] Aula 10 - Seaborn - Melhorando seus Visuais",
    "section": "Problema",
    "text": "Problema\nConsidere o seguinte cenário: Você é um cientista de dados encarregado de fazer uma análise em cima dos dados da população mundial. Os seus gráficos serão incorporados em uma apresentação PowerPoint.\nO gráfico que você deve montar mostra a evolução no tamanho da população dos países do bloco econômico BRICS (Brasil, Russia, India, China e Africa do Sul), fazendo uma comparação com os Estados Unidos. Deve ser um gráfico de barras, onde cada barra irá representar um ano ou década.\nO arquivo com os dados pode ser encontrado aqui. Você pode fazer o download e subir no seu Google Colab ou carregar diretamente do endereço."
  },
  {
    "objectID": "posts/data-110/index.html#solução-passo-a-passo",
    "href": "posts/data-110/index.html#solução-passo-a-passo",
    "title": "[VDP] Aula 10 - Seaborn - Melhorando seus Visuais",
    "section": "Solução Passo a Passo",
    "text": "Solução Passo a Passo\n\nCarregando Bibliotecas\nO primeiro passo é sempre carregar as bibliotecas que vamos utilizar.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n\nCarregando dados\nA próxima etapa é carregar os dados. Durante o curso, utilizamos um arquivo local para fazer isso. Hoje vamos exercitar uma pequena variação. Como explicamos anteriormente, todos os nossos conjuntos de dados estão em um repositório no GitHub -&gt; https://github.com/labeduc/datasets. Ensinamos vocês a baixarem o repositório no seu computador e subir o arquivo que vocês vão trabalhar direto no Google Colab (que é temporário e precisar ser salvo lá cada vez que se abre o notebook) ou colocar no seu Google Drive e mapear o Google Drive no Google Colab.\nAgora, vamos explorar uma capacidade da biblioteca pandas que é ler o arquivo direto da internet. O que fizemos foi ir até o Github e observar qual era a URL de download do arquivo que pretendemos usar. Copiamos e colocamos no primeiro parâmetro da função read_csv().\n\nworldpop = pd.read_csv('https://media.githubusercontent.com/media/labeduc/datasets/main/worldpop/world_population.csv')\n\nPara verificar que temos os dados carregados, vamos pedir um sample de 2 linhas.\n\nworldpop.sample(2)\n\n\n\n\n\n\n\n\nRank\nCCA3\nCountry\nCapital\nContinent\n2022 Population\n2020 Population\n2015 Population\n2010 Population\n2000 Population\n1990 Population\n1980 Population\n1970 Population\nArea (km²)\nDensity (per km²)\nGrowth Rate\nWorld Population Percentage\n\n\n\n\n30\n108\nBGR\nBulgaria\nSofia\nEurope\n6781953\n6979175\n7309253\n7592273\n8097691\n8767778\n8980606\n8582950\n110879\n61.1654\n0.9849\n0.09\n\n\n71\n146\nGAB\nGabon\nLibreville\nAfrica\n2388992\n2292573\n2028517\n1711105\n1272935\n983028\n749078\n597192\n267668\n8.9252\n1.0204\n0.03\n\n\n\n\n\n\n\nPerfeito, temos os dados, e estamos prontos para prosseguir.\n\n\nAnalisando os dados\nA primeira coisa que podemos fazer nesta análise é descobrir quais são todos os campos de conjunto de dados, seus tipos de dados e se temos muitos campos vazios.\n\nworldpop.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 234 entries, 0 to 233\nData columns (total 17 columns):\n #   Column                       Non-Null Count  Dtype  \n---  ------                       --------------  -----  \n 0   Rank                         234 non-null    int64  \n 1   CCA3                         234 non-null    object \n 2   Country                      234 non-null    object \n 3   Capital                      234 non-null    object \n 4   Continent                    234 non-null    object \n 5   2022 Population              234 non-null    int64  \n 6   2020 Population              234 non-null    int64  \n 7   2015 Population              234 non-null    int64  \n 8   2010 Population              234 non-null    int64  \n 9   2000 Population              234 non-null    int64  \n 10  1990 Population              234 non-null    int64  \n 11  1980 Population              234 non-null    int64  \n 12  1970 Population              234 non-null    int64  \n 13  Area (km²)                   234 non-null    int64  \n 14  Density (per km²)            234 non-null    float64\n 15  Growth Rate                  234 non-null    float64\n 16  World Population Percentage  234 non-null    float64\ndtypes: float64(3), int64(10), object(4)\nmemory usage: 31.2+ KB\n\n\nA informação está bem estruturada: todos os campos tem valores, os campos númerico são de um tipo numérico, temos poucas categorias e são do tipo object, que basicamente diz que são texto.\nPodemos perceber que estruturalmente, esse conjunto de dados tem um país por linha, com os anos sendo colunas. Em um cenário ideal, os nossos gráficos devem plotar a partir de uma única coluna de valor, e teríamos algum outro atributo para separa-los se for o caso.\nOutro ponto a ser considerado é que precisamos apenas dos Estados Unidos e dos países do bloco econômico BRICS, então temos mais dados do que o necessário.\nIsso significa que vamos fazer alguns ajustes nos nossos dados.\n\n\nTransformando os dados\nAcompanhem explicações nos comentários.\n\n# Primeira coisa é selecionar apenas as colunas que vamos utilizar\nworldpop_sb = worldpop[[\"Country\", \n                     \"1970 Population\",\n                     \"1980 Population\",\n                     \"1990 Population\",\n                     \"2000 Population\",\n                     \"2010 Population\",\n                     \"2015 Population\",\n                     \"2020 Population\",\n                     \"2022 Population\"]]\n\n# Em seguida, filtramos as linhas para pegar apenas US e os países do BRICS\nworldpop_sb2 = worldpop_sb.query(\"Country in ('United States', 'Brazil', 'Russia', 'India', 'China', 'South Africa')\")\n\n# Fazemos a transformação das colunas de ano em linhas.\nbrics_us = worldpop_sb2.melt(id_vars='Country', var_name='Year', value_name='Population')\n\n# Pedimos uma amostra para ver como nossos dados ficaram.\n# Parece tudo certo, temos apenas paises do BRICS e US,\n# no caso do Brasil, vemos agora duas linhas, uma para a\n# informação do ano de 2022 e outra para 2015.\nbrics_us.sample(5)\n\n\n\n\n\n\n\n\nCountry\nYear\nPopulation\n\n\n\n\n42\nBrazil\n2022 Population\n215313498\n\n\n17\nUnited States\n1990 Population\n248083732\n\n\n14\nIndia\n1990 Population\n870452165\n\n\n30\nBrazil\n2015 Population\n205188205\n\n\n46\nSouth Africa\n2022 Population\n59893885\n\n\n\n\n\n\n\nAí estão nossos dados, devidamente formatados. Vamos agora plotar o gráfico.\n\n\nPrimeira Versão\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\nplt.show()\n\n\n\n\n\n\n\n\nE aí está nosso gráfico. A partir de agora, vamos passo a passo aplicando melhorias sucessivas.\n\n\nPasso 1 - Adicionando Títulos\nOs gráficos precisam de títulos, preferencialmente um título que esclareça o significado do gráfico. Em nossas aulas anteriores, já haviamos adicionado títulos significativos em nossos gráficos e nos eixos também. Então, vamos apenas relembrar.\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('Países')\nplt.ylabel('População')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPasso 2 - Ajustando tamanho da imagem\nAo olharmos nosso gráfico, logo percebemos que os nomes dos países estão se sobrepondo no final. Para este e muitos outros ajustes, vamos introduzir a propriedade rcParams. Esta propriedade é um dicionário que armazena outras configurações. Você pode encontrar mais informaç!oes aqui.\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('Países')\nplt.ylabel('População')\n\nplt.show()\n\n\n\n\n\n\n\n\nEsse tamanho deixou as barras mais separadas, e agora conseguimos ver claramente todos os países.\n\n\nPasso 3 - Ajustando Qualidade da Imagem\nDentro do contexto de visualização online, nosso gráfico parece bom. Mas, se precisarmos exportar esse gráfico como imagem para usar em um powerpoint, por exemplo, veremos que a qualidade da imagem ficará ruim. Isso acontece porque o padrão do matplotlib é gerar imagens com resolução de 100dpi. Para exportar, normalmente é recomendado utilizar 300dpi. Vamos arrumar isso e ver como fica?\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('Países')\nplt.ylabel('População')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPasso 4 - Removendo o “Ruído” do Gráfico\nDe acordo com as boas práticas na área de visualização, uma boa visualização é limpa, ou seja, não possui elementos que não estejam relacionados aos dados. No gráfico acima, o box em torno do gráfico, a legenda com muito texto, aquela informação 1e9 perdida no gráfico são ruídos, que tiram a atenção das barras que são os dados.\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('Países')\nplt.ylabel('População')\n\nplt.show()\n\n\n\n\n\n\n\n\nConseguimos deixar a imagem maior, removemos alguns elementos que adicionavam apenas ruído no gráfico. Mas observem que agora a formatação dos valores no eixo Y está estranho. Vamos corrigir?\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks()\nplt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('Países')\nplt.ylabel('População (bilhões)')\n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/823456077.py:26: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n\n\n\n\n\n\n\n\nPor último, vamos remover o label do eixo X.\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks()\nplt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\nplt.ylabel('População (bilhões)')\n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/1234354454.py:26: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n\n\n\n\n\n\n\n\n\n\nPasso 5 - Colocando foco nos dados\nAgora que trabalhamos na formatação inicial, precisamos realizar melhorias que irão nos ajudar a colocar o foco nos dados. Eis o que vamos fazer: - diminuir a legenda - Alinhar o título a esquerda - o título centralizado faz com que os olhos façam um escaneamento extra do gráfico, dificultando a compreensão - vamos colocar os valores em cima de cada barra. Também para evitar que precisemos olhar no eixo a esquerda para ver o valor de cada barra, ou seja, que fiquemos constantemente escaneando o gráfico - ajustar o tamanho das fontes - ajustar as cores.\n\nDiminuindo a legenda\nA princípio, podemos resolver isso manipulando os dados.\n\nbrics_us['Year'] = brics_us['Year'].apply(lambda x: x.replace(' Population',''))\n\nVamos ver o resultado?\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks()\nplt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\nplt.ylabel('População (bilhões)')\n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/1234354454.py:26: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n\n\n\n\n\n\n\n\n\n\nAlinhar o Titulo e Diminuir fontes\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\n#Fontes\nplt.rcParams[\"legend.fontsize\"] = 5\nplt.rcParams[\"legend.title_fontsize\"] = 6\nplt.rcParams[\"legend.frameon\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\nplt.tick_params(axis='both', which='major', labelsize=6)\n\nsns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks()\nplt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)', fontsize=8, loc='left')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\nplt.ylabel('População (bilhões)')\n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/1419233821.py:32: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n\n\n\n\n\n\n\n\n\n\nRemovendo o eixo Y e adicionando os valores nas barras\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.left\"] = False\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\n#Fontes\nplt.rcParams[\"legend.fontsize\"] = 5\nplt.rcParams[\"legend.title_fontsize\"] = 6\nplt.rcParams[\"legend.frameon\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\nplt.tick_params(axis='both', which='major', labelsize=6)\n\nsx = sns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks()\nplt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)', fontsize=8, loc='left')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\n\n# Removendo todo o eixo Y\nsx.get_yaxis().set_visible(False)\n\n# O Objeto patches contém todos os elementos (neste caso barras) que foram plotados no gráfico\n# Então percorremos eles e fazemos os seguintes calculos:\n# a coordenada x para posicionar o texto = Coordenada X do canto superior da barra + largura da barra / 2\n# a coordenada Y para posicionar o texto = Coordenada Y do canto superior da barra + 1% desta altura\nfor p in sx.patches:\n  _x = (p.get_x() + p.get_width() / 2)\n  _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n  value = '{:.2f}'.format(p.get_height()/1000000000)\n  sx.text(_x, _y, value, ha=\"center\", size=3) \n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/1997790246.py:33: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(['{:,.1f}'.format(x) for x in current_values/1000000000]);\n\n\n\n\n\n\n\n\n\n\n\nAcertando as cores\nA paleta de cores precisa ser ajustada para respeitar as cores da empresa.\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Definindo a paleta de cores\ncores = [\"#0c4f6a\", \"#177498\", \"#0a8faa\", \"#bfdce5\", \"#82bd4a\", \"#b8d67a\", \"#b2b3b6\", \"#58585a\", \"#edb634\", \"#d97933\", \"#f1bdb1\", \"#eca091\", \"#e26c54\", \"#b0391e\"]\nsns.set_palette(sns.color_palette(cores))\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.left\"] = False\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\n#Fontes\nplt.rcParams[\"legend.fontsize\"] = 5\nplt.rcParams[\"legend.title_fontsize\"] = 6\nplt.rcParams[\"legend.frameon\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\nplt.tick_params(axis='both', which='major', labelsize=6)\n\nsx = sns.barplot(brics_us, x='Country', y='Population', hue='Year')\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks().tolo\nformatted_values = ['{:,.1f}'.format(x/1000000000) for x in current_values]\nplt.gca().set_yticklabels(formatted_values)\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)', fontsize=8, loc='left')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\n\n# Removendo todo o eixo Y\nsx.get_yaxis().set_visible(False)\n\n# O Objeto patches contém todos os elementos (neste caso barras) que foram plotados no gráfico\n# Então percorremos eles e fazemos os seguintes calculos:\n# a coordenada x para posicionar o texto = Coordenada X do canto superior da barra + largura da barra / 2\n# a coordenada Y para posicionar o texto = Coordenada Y do canto superior da barra + 1% desta altura\nfor p in sx.patches:\n  _x = (p.get_x() + p.get_width() / 2)\n  _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n  value = '{:.2f}'.format(p.get_height()/1000000000)\n  sx.text(_x, _y, value, ha=\"center\", size=3) \n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/4070811810.py:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(formatted_values)\n\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico, com suas cores modificadas. Para este gráfico ficar realmente bom, faltam apenas duas correções: deixar nossas barras um pouco mais largas para que possamos aumentar a fonte dos valores.\n\n# É aconselhavel mudar o tamanho da imagem antes de plotar\n# Para tanto, o MatPlotLib nos permite modificar entradas \n# em um dicionário de parâmetros chamado rcParams.\n# A nossa modificação será da entrada figure.figsize\n# Este parâmetro recebe uma tupla com largura e altura em polegadas\n# O valor padrão é 6.4 de largura e 4.8 de altura em polegadas\nplt.rcParams[\"figure.figsize\"] = (9,5)\n\n#Definindo a paleta de cores\ncores = [\"#0c4f6a\", \"#177498\", \"#0a8faa\", \"#bfdce5\", \"#82bd4a\", \"#b8d67a\", \"#b2b3b6\", \"#58585a\", \"#edb634\", \"#d97933\", \"#f1bdb1\", \"#eca091\", \"#e26c54\", \"#b0391e\"]\nsns.set_palette(sns.color_palette(cores))\n\n#Ajustando qualidade da imagem\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Para remover parte do box da imagem, fazemos isso:\nplt.rcParams[\"axes.spines.left\"] = False\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\n\n#Fontes\nplt.rcParams[\"legend.fontsize\"] = 5\nplt.rcParams[\"legend.title_fontsize\"] = 6\nplt.rcParams[\"legend.frameon\"] = False\n\nplt.ticklabel_format(style=\"plain\", useLocale=True)\nplt.tick_params(axis='both', which='major', labelsize=6)\n\n# O padrão para tamanho das barras é 0.8. Quando colocamos 1, as barras se encostam. \n# Portanto, aumentamos para 0.95 para que não se encostem, mas fiquem mais largas.\n# A nossa outra alteração foi na rotina que imprime os valores, onde pudemos ajustar\n# o tamanho da fonte de 3 para 4\nsx = sns.barplot(brics_us, x='Country', y='Population', hue='Year', width=0.95)\n\n# Aqui buscamos os valores que foram adicionados no eixo e os modificamos \n# com a formatação adequada\ncurrent_values = plt.gca().get_yticks().tolist()\nformatted_values = ['{:,.1f}'.format(x/1000000000) for x in current_values]\nplt.gca().set_yticklabels(formatted_values)\n\n# Esta função adiciona um título no gráfico\nplt.title('Crescimento Populacional no BRICS (1970 - 2020)', fontsize=8, loc='left')\n\n# Estas funções nos permitem alterar o títulos nos eixos\nplt.xlabel('')\n\n# Removendo todo o eixo Y\nsx.get_yaxis().set_visible(False)\n\n# O Objeto patches contém todos os elementos (neste caso barras) que foram plotados no gráfico\n# Então percorremos eles e fazemos os seguintes calculos:\n# a coordenada x para posicionar o texto = Coordenada X do canto superior da barra + largura da barra / 2\n# a coordenada Y para posicionar o texto = Coordenada Y do canto superior da barra + 1% desta altura\nfor p in sx.patches:\n  _x = (p.get_x() + p.get_width() / 2)\n  _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n  value = '{:.2f}'.format(p.get_height()/1000000000)\n  sx.text(_x, _y, value, ha=\"center\", size=4) \n\n# Essa alteração foi no improviso, pois estava dizendo Year, ou seja,\n# uma parte do gráfico utilizava um idioma diferente.\nplt.legend(title='Ano')\n\nplt.show()\n\n/var/folders/fc/hns7cg2j2xg_05kdl6cbxkw40000gn/T/ipykernel_47418/1546591451.py:42: UserWarning: FixedFormatter should only be used together with FixedLocator\n  plt.gca().set_yticklabels(formatted_values)\n\n\n\n\n\n\n\n\n\nAcho que agora, estamos prontos para enviar esse belo gráfico para quem vai usá-lo!"
  },
  {
    "objectID": "posts/data-110/index.html#conclusão",
    "href": "posts/data-110/index.html#conclusão",
    "title": "[VDP] Aula 10 - Seaborn - Melhorando seus Visuais",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula, aprendemos sobre como configurar nossos gráficos para que fiquem com uma aparência mais profissional e respeitem as boas práticas da área de Visualização de Dados. Vamos deixar também os links para as documentações das bibliotecas que utilizamos: - Seaborn - Matplotlib\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-108/index.html",
    "href": "posts/data-108/index.html",
    "title": "[VDP] Aula 08 - Dispersão e Quadrantes",
    "section": "",
    "text": "Olá Cientista de Dados!\nNas aulas anteriores aprendemos a criar gráficos que nos permitem realizar comparações entre categorias de uma dimensão, e também observar as variações de uma categoria ao longo de uma dimensão contínua (podendo ser uma dimensão numérica ou a mais popular, o tempo). Outra característica que esses gráficos possuem é que eles demonstram valores agregados no nível das categorias que estão sendo comparadas.\nNesta aula, iremos explorar gráficos que nos permitirão: - analisar a distribuição dos valores ao longo de variáveis contínuas de forma individualizada - analisar a correlação entre variáveis - identificar o que chamamos de outliers, que são os pontos que fogem da distribuição observada (aquele ponto fora da curva).\nPara realizar esse tipo de análise, vamos trabalhar com os Gráficos de Dispersão e Pontos."
  },
  {
    "objectID": "posts/data-108/index.html#introdução",
    "href": "posts/data-108/index.html#introdução",
    "title": "[VDP] Aula 08 - Dispersão e Quadrantes",
    "section": "",
    "text": "Olá Cientista de Dados!\nNas aulas anteriores aprendemos a criar gráficos que nos permitem realizar comparações entre categorias de uma dimensão, e também observar as variações de uma categoria ao longo de uma dimensão contínua (podendo ser uma dimensão numérica ou a mais popular, o tempo). Outra característica que esses gráficos possuem é que eles demonstram valores agregados no nível das categorias que estão sendo comparadas.\nNesta aula, iremos explorar gráficos que nos permitirão: - analisar a distribuição dos valores ao longo de variáveis contínuas de forma individualizada - analisar a correlação entre variáveis - identificar o que chamamos de outliers, que são os pontos que fogem da distribuição observada (aquele ponto fora da curva).\nPara realizar esse tipo de análise, vamos trabalhar com os Gráficos de Dispersão e Pontos."
  },
  {
    "objectID": "posts/data-108/index.html#preparação",
    "href": "posts/data-108/index.html#preparação",
    "title": "[VDP] Aula 08 - Dispersão e Quadrantes",
    "section": "Preparação",
    "text": "Preparação\nVamos carregar nossa bibliotecas e os dados.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/data-108/index.html#utilização-básica",
    "href": "posts/data-108/index.html#utilização-básica",
    "title": "[VDP] Aula 08 - Dispersão e Quadrantes",
    "section": "Utilização Básica",
    "text": "Utilização Básica\nComo mencionamos anteriormente, uma das características dos gráficos de dispersão e pontos é que normalmente queremos que cada linha do nosso conjunto de dados esteja representado, com seus valores individualizados, ao contrário dos gráficos de barras, onde as informações estão agregadas através de cálculos de média, soma, …\nOutra notada diferença é que neste tipo de gráfico, os eixos não utilizam categorias discretas. O que vemos é representação do domínio contínuo de variáveis, e os pontos correspondem a uma ocorrência.\nTrazendo para a realidade do nosso conjunto de dados: os gráficos de dispersão não terão em seus eixos valores como Tipo ou Geração - o que iremos colocar nos eixos serão Ataque e Defesa, e os pontos plotados no gráfico representarão cada um dos pokemons no nosso conjunto de dados.\nPara fazer isso, utilizaremos a função scatterplot() do seaborn.\nVamos ver na prática?\n\nsns.scatterplot(pokemons, x='Att', y='Def')\nplt.title('Análise de Pontos de Ataque X Defesa')\nplt.xlabel('Pontos de Ataque')\nplt.ylabel('Pontos de Defesa')\nplt.show()\n\n\n\n\n\n\n\n\nÉ bem simples, não é mesmo? Escolhemos a variável do eixo X e a variável do eixo Y e é isso, vemos cada um dos nossos pokemons plotados no gráfico.\nEsse tipo de gráfico serve para mostrarmos a relação que existe entre as duas variáveis. No gráfico acima, podemos perceber que existe uma maior concentração de pokemons na faixa de 50-100 pontos de ataque e defesa. Também percebemos outras informações, tais como: - pelo menos 1 pokemon tem um alto valor de pontos de defesa, mas quase nada de pontos de ataque - pelo menos 1 pokemon tem um alto valor de pontos de ataque, mas quase nada de pontos de defesa.\nIsso são o que chamamos de outliers, pois fogem da distribuição que percebemos como padrão.\nMas podemos melhorar um pouco nosso gráfico. Por exemplo, podemos colorir nossos pontos de acordo com a geração, assim podemos entender qual é a distribuição de cada geração.\n\nsns.scatterplot(pokemons, x='Att', y='Def', hue='Generation')\nplt.title('Análise de Pontos de Ataque X Defesa')\nplt.xlabel('Pontos de Ataque')\nplt.ylabel('Pontos de Defesa')\nplt.show()\n\n\n\n\n\n\n\n\nMelhorou um pouco, agora temos noção das gerações, mas a distribuição náo é uniforme, pois como o valor é numérico ele criou faixas de valores. Se quisermos ver cada geração individualmente, teremos que trabalhar nossos dados.\n\nAdicionando uma coluna em nossos dados\nAdicionar uma nova coluna em um DataFrame pandas é bem simples:\npokemons['Generation Desc'] = \"\"\nIsso criará uma nova coluna chamada ‘Generation Desc’ que terá cada linha populada com o valor “” (vazio). Isso é um bom início, mas precisamos atribuir um valor a esta coluna, preferencialmente baseado no valor do campo ‘Generation’ original. Para isso, iremos utilizar a função apply() do DataFrame. Vamos ao comando.\n\npokemons['Generation Desc'] = pokemons['Generation'].apply(lambda gen: 'Gen ' + str(int(gen)))\n\nA função apply() nos permite aplicar uma função (aqui utilizamos uma função lambda) que transforma o valor do campo Generation em um valor inteiro sem casas decimais para depois transforma-lo em texto, de forma que consigamos juntar com a string ‘Gen’. Assim, temos uma descrição textual da geração. Com isso, podemos agora, tentar novamente o plot do gráfico.\n\nsns.scatterplot(pokemons, x='Att', y='Def', hue='Generation Desc')\nplt.title('Análise de Pontos de Ataque X Defesa')\nplt.xlabel('Pontos de Ataque')\nplt.ylabel('Pontos de Defesa')\nplt.show()\n\n\n\n\n\n\n\n\nAs cores ficaram bem melhores, mas a posição da legenda ficou bem ruim. Vamos arrumar?\n\nsns.scatterplot(pokemons, x='Att', y='Def', hue='Generation Desc')\nplt.title('Análise de Pontos de Ataque X Defesa')\nplt.xlabel('Pontos de Ataque')\nplt.ylabel('Pontos de Defesa')\nplt.legend(loc='upper right', bbox_to_anchor=(1.21,1.02))\nplt.show()\n\n\n\n\n\n\n\n\nAgora temos nosso gráfico de dispersão pronto. Na próxima seção, vamos discutir um caso específico de gráfico de dispersão, chamado de Gráfico de Quadrantes.\n\n\nGráfico de Quadrantes\nO gráfico de quadrantes é um caso específico de um gráfico de dispersão, onde dividimos a área do gráfico em quadrantes - superior esquerdo, superior direito, inferior esquerdo e inferior direito - e a presença de um ponto nesses quadrantes tem um significado especial. O maior exemplo deste tipo de gráfico é o “Quadrante Mágico” do Grupo Gartner, que publica todos os anos neste formato quais as empresas ou produtos que se posicionam como líderes do mercado em cada setor. Veja o exemplo abaixo, que representa O Quadrante Mágico de 2022 para a área de Business Intelligence.\n\n\n\nQuadrante Mágico 2022 - BI\n\n\nNeste formato do Gartner, os pontos que estiverem no quadrante superior direito são considerados os líderes do mercado, levando em conta as variáveis completude da visão e capacidade de execução, que são dois scores calculados e ficam em uma escala de 1 a 10 pontos.\nEntão, levando em consideração que o nosso gráfico de dispersão utiliza os atributos de Ataque e Defesa, vamos imaginar como transformar esse gráfico em um ‘Quadrante Mágico’ que nos permitirá saber quais são os pokemons mais capazes e que possuem a melhor relação entre pontos de ataque e defesa.\nAs mudanças que iremos aplicar no nosso gráfico original de dispersão são: - deixar os eixos com a mesma faixa de valores. Agora eles estão levemente desencontrados - plotar os eixos que dividem os quadrantes - plotar um texto descritivo para cada quadrante - se possível, poder nomear cada ponto no gráfico, com o nome do pokemon.\nAcompanhe os comentários no código para entender o que foi feito!\n\n# gera o gráfico original\nsns.scatterplot(pokemons, x='Att', y='Def', hue='Generation Desc')\n\n# adiciona os títulos\nplt.title('Análise de Pontos de Ataque X Defesa')\nplt.xlabel('Pontos de Ataque')\nplt.ylabel('Pontos de Defesa')\n\n# adiciona e posiciona a legenda\nplt.legend(loc='upper right', bbox_to_anchor=(1.21,1.02))\n\n# ajusta a faixa de valores para os dois eixos\n# observe que utilizamos valores fixos. O ideal seria utilizar alguma\n# fórmula ou função para dinamizar, mas vamos deixar simples\nplt.xlim(0, 225)\nplt.ylim(0, 225)\n\n# traçamos as linhas de divisão dos quadrantes\n# observe que a posição delas é na exata metade do \n# valor máximo de cada eixo\nplt.axhline(y=112.5, color='blue', linestyle='--', linewidth=1)           \nplt.axvline(x=112.5, color='blue',linestyle='--', linewidth=1) \n\n# criamos o label que identifica cada quadrante e o seu significado\nplt.text(x=40, y=10, s=\"Fracos\", color='blue')\nplt.text(x=145, y=10, s=\"Atacantes\", color='blue')\nplt.text(x=155, y=210, s=\"Fortes\", color='blue')\nplt.text(x=30, y=210, s=\"Defensivos\", color='blue')\n\n# mostra o gráfico\nplt.show()\n\n\n\n\n\n\n\n\nFicou bem bonito o nosso quadrante! A única coisa que não fizemos foi adicionar um “tooltip” a cada ponto para sabermos que pokemon é aquele. Para isso, precisamos que o gráfico seja do tipo interativo, o que requer utilizar outra biblioteca. Em uma das próximas aulas iremos explorar uma biblioteca que permite esse tipo de interação."
  },
  {
    "objectID": "posts/data-108/index.html#conclusão",
    "href": "posts/data-108/index.html#conclusão",
    "title": "[VDP] Aula 08 - Dispersão e Quadrantes",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula exercitamos ainda mais nossa capacidade de criar gráficos, expandido nosso conhecimento para a aplicação de mais uma função, chamada scatterplot() que nos permite criar gráficos de dispersão e os populares quadrantes mágicos. Também aprendemos mais algumas funções que nos ajudam a melhor formatar os nossos gráficos.\nNa próxima aula, vamos aprender a criar o mais polêmico dos gráficos: o gráfico de pizza!!!\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-106/index.html",
    "href": "posts/data-106/index.html",
    "title": "[VDP] Aula 06 - Iniciando com Seaborn",
    "section": "",
    "text": "Olá Cientista de Dados!\nBem-vindo de volta! Na última aula aprendemos como utilizar a biblioteca Pandas para carregar no notebook os dados que pretendemos trabalhar. Também aprendemos a utilizar algumas funções mais avançadas que nos permitem filtrar ou agregar informações em nosso conjunto de dados.\nA linguagem Python possui inúmeras bibliotecas não-nativas para gerar visualizações de dados. A biblioteca mais famosa e que muitas vezes serve de base para as outras se chama matplotlib. Por uma questão de conveniência e facilidade de uso, utilizaremos no curso a biblioteca seaborn.\nAs principais vantagens do seaborn são: - interface alto nível - existe uma função para cada tipo de gráfico, e permite fazer chaining de chamadas - facilidade de configuração - possui objetos de configuração globais e locais (em cada gráfico).\nNesta aula, vamos passar pelo processo de instalação e utilização dos tipos de gráficos mais básicos no seaborn."
  },
  {
    "objectID": "posts/data-106/index.html#introdução",
    "href": "posts/data-106/index.html#introdução",
    "title": "[VDP] Aula 06 - Iniciando com Seaborn",
    "section": "",
    "text": "Olá Cientista de Dados!\nBem-vindo de volta! Na última aula aprendemos como utilizar a biblioteca Pandas para carregar no notebook os dados que pretendemos trabalhar. Também aprendemos a utilizar algumas funções mais avançadas que nos permitem filtrar ou agregar informações em nosso conjunto de dados.\nA linguagem Python possui inúmeras bibliotecas não-nativas para gerar visualizações de dados. A biblioteca mais famosa e que muitas vezes serve de base para as outras se chama matplotlib. Por uma questão de conveniência e facilidade de uso, utilizaremos no curso a biblioteca seaborn.\nAs principais vantagens do seaborn são: - interface alto nível - existe uma função para cada tipo de gráfico, e permite fazer chaining de chamadas - facilidade de configuração - possui objetos de configuração globais e locais (em cada gráfico).\nNesta aula, vamos passar pelo processo de instalação e utilização dos tipos de gráficos mais básicos no seaborn."
  },
  {
    "objectID": "posts/data-106/index.html#instalação",
    "href": "posts/data-106/index.html#instalação",
    "title": "[VDP] Aula 06 - Iniciando com Seaborn",
    "section": "Instalação",
    "text": "Instalação\nAssim como na aula de Pandas, tenho uma boa notícia: no Google Colab o seaborn já vem instalado no nosso ambiente! Mas caso você esteja também se aventurando em fazer este curso no VS Code, PyCharm, Sublime ou até mesmo Notepad, o comando para instalar a biblioteca seaborn é o seguinte:\n(venv) $ pip install seaborn"
  },
  {
    "objectID": "posts/data-106/index.html#visualizando-com-seaborn",
    "href": "posts/data-106/index.html#visualizando-com-seaborn",
    "title": "[VDP] Aula 06 - Iniciando com Seaborn",
    "section": "Visualizando com seaborn",
    "text": "Visualizando com seaborn\nAgora vamos ver na prática como o seaborn funciona. Nesta aula, veremos os tipos de gráficos mais comuns, indicando sua utilização e dando exemplos. Se você quiser mais detalhes, sempre pode consultar a documentação do seaborn em Seaborn Docs.\nNesta aula, vamos aprender a gerar gráficos de barras ou colunas, baseados nas funções: countplot() e barplot(). Nas aulas seguintes, iremos explorar outros tipos de gráficos, que são um pouco mais avançados.\n\nInicializando o seaborn\nComo toda a biblioteca python, precisamos indicar em nosso script quando queremos utilizar a biblioteca seaborn. Fazemos isso através do comando import.\n\nimport seaborn as sns\n\nDa mesma forma que falamos na aula de Pandas, o import do seaborn geralmente utiliza o apelido de sns, que pode ser encontrado em muitos artigos na internet. Vamos manter essa convenção para que vocês se acostumem ao procurar material de apoio.\nPor falar de Pandas, precisamos carregar ele também, afinal, precisamos dos nossos dados!\n\nimport pandas as pd\n\n\n\nCarregando os dados\nE vamos continuar nossas demonstrações com o conjunto de dados de pokemons:\n\npokemons = pd.read_csv('pokemons.csv')\n\n\n\nGráficos de barras ou colunas\nUm gráfico de barras ou colunas é uma representação gráfica de dados em que as informações são exibidas em barras verticais ou horizontais de comprimentos variáveis. Cada barra ou coluna representa uma categoria ou conjunto de dados diferentes, e a altura ou comprimento da barra é proporcional à quantidade ou valor correspondente.\nOs gráficos de barras são frequentemente usados para comparar quantidades ou valores entre diferentes categorias, enquanto os gráficos de colunas são mais adequados para exibir uma série temporal de dados. Ambos os tipos de gráficos podem ser usados para exibir dados discretos ou contínuos, e podem ser personalizados para incluir rótulos, legendas e outras informações relevantes. Os gráficos de barras e colunas são comumente usados em relatórios, apresentações e em análises de dados.\n\ncountplot()\nA primeira função que iremos aprender a utilizar é a função countplot(). Ela é indicada quando queremos realizar a contagem de uma categoria, ou seja, escolhemos um campo categórico em nossos dados e indicamos quantas ocorrências encontramos em nossos dados. Nos próximos blocos de código, veremos vários exemplos de como fazer isso.\n\n# contando o número de pokemons por geração\n\nplot = sns.countplot(pokemons, x=\"Generation\")\n\nplot\n\n\n\n\n\n\n\n\nOlha só, parece bem fácil, não? Está ali o nosso gráfico, com o número de pokemons por geração. No entanto, temos algumas melhorias que podem ser feitas:\n\nadicionar um título\ncorrigir os títulos dos eixos.\n\nPara realizar esses ajustes, vamos precisar de uma nova biblioteca, chamada matplotlib. Na verdade, essa biblioteca é a base de muitas outras bibliotecas de visualização, tais como seaborn, plotly e por aí vai.\nNeste cenário, matplotlib é utilizada para preparar o que chamamos de área de plotagem, que é o retângulo branco onde nosso gráfico será exibido.\n\nimport matplotlib.pyplot as plt\n# contando o número de pokemons por geração\n\nsns.countplot(pokemons, x=\"Generation\")\nplt.title('Pokemons por Geração') # título do gráfico\nplt.xlabel('Geração') # eixo X\nplt.ylabel('Número de Pokemons') # eixo Y\n\nplt.show() # mostra o gráfico\n\n\n\n\n\n\n\n\nAgora sim, temos um gráfico bem desenhado!\nEste gráfico é um Gráfico de Colunas, de acordo com as definições, pois as barras são verticais. Para transformar em um gráfico de barras, na função countplot() precisamos apenas trocar o x pelo y no segundo parâmetro, além de trocar os títulos na funções xlabel e ylabel. Vamos ver como fica:\n\nsns.countplot(pokemons, y=\"Generation\")\nplt.title('Pokemons por Geração') # título do gráfico\nplt.ylabel('Geração') # eixo Y\nplt.xlabel('Número de Pokemons') # eixo X\n\nplt.show() # mostra o gráfico\n\n\n\n\n\n\n\n\n\n\nbarplot()\nNos gráficos utilizando countplot() podemos apenas exibir a contagem de elementos para cada valor categórico da coluna que escolhemos. Não temos como, por exemplo, apresentar a média dos pontos de vida dos pokemons. Para isso, precisamos de mais controle sobre os dados que iremos mostrar. Entra em cena a função barplot():\n\nimport numpy as np\n\nsns.barplot(pokemons, x='Generation', y='HP', estimator=np.mean)\nplt.title('Média dos pontos de vida de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de vida')\n\nText(0, 0.5, 'Média dos pontos de vida')\n\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico. Algumas observações:\n\nPrecisamos trazer mais uma biblioteca para o nosso script, a biblioteca numpy, para podermos especificar que nosso gráfico de barras iria calcular a média do campo especificado\nAlém de definirmos o eixo X, definimos também o eixo Y e qual o tipo de cálculo a ser realizado\nCada barra tem um risco preto. Esse risco se refere a margem de erro. Se você não quiser ver essa informação, apenas adicionamos mais um parâmetro a função e ela desaparece.\n\n\nsns.barplot(pokemons, x='Generation', y='HP', estimator=np.mean, errwidth=0)\nplt.title('Média dos pontos de vida de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de vida')\n\nText(0, 0.5, 'Média dos pontos de vida')\n\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico de colunas. Outra coisa que podemos explorar é ter mais de uma métrica sendo analisada pela categoria selecionada. Por exemplo, vamos analisar a média dos pontos de ataque e defesa através das gerações.\n\n# Precisamos fazer ajustes no conjunto de dados\npokemons_sb = pokemons[['Generation','Att','Def']] # Primeiro selecionamos apenas as colunas que queremos trabalhar\ntidy = pokemons_sb.melt(id_vars='Generation').rename(columns=str.title)\n# A função melt()  recebe como parâmetro a coluna categórica e pega todas as colunas de métricas e transformam em uma \n# única coluna, em uma nova linha para cada coluna. Para identificar cada nova linha, outra coluna é adicionada, com\n# a descrição. Ou seja, realizamos uma transposição do nosso conjunto de dados.\n\n# Gráfico\nsns.barplot(tidy, x='Generation', y='Value', hue='Variable', estimator=np.mean, errwidth=0)\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nNo código acima, a parte que faz a plotagem do gráfico continua a mesma, mas temos as duas linhas iniciais que servem para fazer um ajuste nos dados. Quanto mais complexo os gráficos que queremos plotar, mais necessário se torna entender como formatar os dados. Então, aprenda principalmente Pandas e SQL e mantenha todos os seus gráficos fáceis de plotar!\nAgora, vamos ver mais um subtipo de gráfico de barras ou colunas: o gráfico de colunas “stacked” ou empilhadas.\n\npokemons_gb = pokemons.groupby(['Generation'])[['Generation','Att', 'Def']].mean()\n\nplt.bar(pokemons_gb['Generation'], pokemons_gb['Att'], color='blue', edgecolor='white', width=1)\nplt.bar(pokemons_gb['Generation'], pokemons_gb['Def'], bottom=pokemons_gb['Att'], color='red', edgecolor='white', width=1)\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\n\nplt.show()\n\n\n\n\n\n\n\n\nNesta versão de stacked bar chart, como podemos perceber pelo código, foi necessária uma nova transformação nos dados, desta vez com as funções groupby() e mean(). Além disso, desenhamos as barras com o matplotlib direto, não chegamos a utilizar o seaborn.\nA transformação nos dados foi necessária para agruparmos os valores de ataque e defensa por geração e calcular a média. A opção de utilizar matplotlib direto produziu um gráfico com a aparência bem diferente, e sinceramente, feia se comparada aos outros gráficos que criamos. E existe uma alternativa! Podemos usar o seaborn através do próprio DataFrame, garantindo uma aparência alinhada com o que geramos anteriormente.\n\npokemons_gb.plot(kind='bar', x='Generation', stacked=True)\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "posts/data-106/index.html#concluindo",
    "href": "posts/data-106/index.html#concluindo",
    "title": "[VDP] Aula 06 - Iniciando com Seaborn",
    "section": "Concluindo",
    "text": "Concluindo\nE isso nos leva ao final desta aula! Conseguimos ver como gerar um dos gráficos mais utilizados na área de Visualização de Dados, o gráfico de barras e suas variações utilizando a biblioteca seaborn. Também aprendemos que para gerar certos tipos de gráficos, é necessário fazer algumas transformações nos dados, o que conecta esta aula a aula de Pandas.\nSe você quiser aprender mais sobre seaborn, seguem alguns links: - Documentação oficial do Seaborn em português: A documentação oficial do Seaborn tem uma versão em português que fornece uma visão geral da biblioteca, exemplos de uso, informações sobre os diferentes tipos de gráficos, e muito mais - Tutorial de visualização de dados com Python e Seaborn: Este tutorial do Towards Data Science fornece uma introdução prática à visualização de dados com Seaborn, incluindo exemplos de código e gráficos. O tutorial abrange tópicos como gráficos de barras, gráficos de dispersão, heatmap e muito mais.\nNa próxima aula, iremos continuar vendo outros tipos de gráficos e nos tornando mais familiares com seaborn, matplotilb e pandas.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-104/index.html",
    "href": "posts/data-104/index.html",
    "title": "[VDP] Aula 04 - Prática Aulas 2 e 3",
    "section": "",
    "text": "Olá Cientista de Dados!\nNesta aula vamos por em prática o que aprendemos até aqui:"
  },
  {
    "objectID": "posts/data-104/index.html#criando-um-notebook-no-google-colab",
    "href": "posts/data-104/index.html#criando-um-notebook-no-google-colab",
    "title": "[VDP] Aula 04 - Prática Aulas 2 e 3",
    "section": "Criando um notebook no Google Colab",
    "text": "Criando um notebook no Google Colab\nSiga o passo a passo para criar um novo notebook no Google Colab.\n\n\n\nAcessar o site do Google Colab: https://colab.research.google.com/\n\n\n\n\n\nClicar em “Novo notebook”. Será aberta uma nova página com um notebook em branco\n\n\n\n\n\nPara modificar o nome do notebook para “PrimeiroNotebook”, clicar em “Arquivo &gt; Salvar uma cópia no Drive” no menu superior. Na janela que aparece, modificar o nome para “PrimeiroNotebook” e clicar em “OK”.\n\n\nAgora, vamos aprender como escrever um código em Python e executa-lo no notebook.\n\n\n\nNo notebook aberto, criar uma nova célula clicando no botão “+ Célula” acima do menu superior ou utilizando o atalho “Ctrl+M B” no teclado\n\n\n\n\n\nNa nova célula, digitar o código print('Hello World')\n\n\n\n\n\nClicar em “Executar” na célula, ou utilizar o atalho “Shift+Enter”. O resultado “Hello World” será exibido abaixo da célula\n\n\nDessa forma, o notebook “PrimeiroNotebook” estará pronto para ser utilizado. Lembrando que o Google Colab é uma ferramenta gratuita e muito útil para desenvolvimento de projetos de análise de dados, aprendizado de máquina e outros projetos de programação em Python."
  },
  {
    "objectID": "posts/data-104/index.html#carregando-dados-em-um-notebook",
    "href": "posts/data-104/index.html#carregando-dados-em-um-notebook",
    "title": "[VDP] Aula 04 - Prática Aulas 2 e 3",
    "section": "Carregando dados em um notebook",
    "text": "Carregando dados em um notebook\nAgora que temos nosso notebook inicial, vamos exercitar o princípio mais básico de toda a visualização de dados: a carga dos dados que serão visualizados.\nPara fazer isso, precisamos primeiro de uma fonte de dados. Uma fonte de dados pode ter formatos bem comuns e conhecidos como CSV, Excel e JSON, até outros formatos especializados como Feather, Arrow, Parquet,…Quanto à origem da fonte de dados, elas podem ser um arquivo local no seu computador ou no servidor onde a rotina executará ou até mesmo uma URL. Por questões de performance, o arquivo local tem uma certa preferência.\nQuando utilizamos o Google Colab, o nosso notebook tem duas possibilidades para poder ler arquivos de forma local: - os arquivos podem ser armazenados no sistema de arquivos local do notebook, que é temporário, ou - podemos deixar nossos arquivos no Google Drive e conectamos o Google Drive ao nosso notebook\nVamos ver esses dois cenários em detalhe nas próximas seções.\n\nDisponibilizando arquivos a partir do sistema local do notebook\nO sistema de arquivos local do notebook (session storage) é uma maneira muito conveniente de manter de forma local alguns arquivos de dados que precisamos trabalhar. Em termos de performance, seria a mesma coisa que executar tudo no seu próprio computador. O incoveninente desse método é que o session storage é destruído quando fechamos o notebook ou ele fica inativo por muito tempo. Ele é recriado quando reabrimos o notebook, mas vem vazio.\n\n\n\n\n\n\nTip\n\n\n\nPara o restante das aulas, todos os arquivos de dados que iremos utilizar podem ser encontrados em: LabEduc datasets\nVocê pode fazer o download ou tentar carregar direto da URL (veremos como fazer isso mais adiante).\n\n\nPara utilizar o session storage, siga os passos abaixo:\n\n\n\nClique no botão Arquivos que fica à esquerda\n\n\n\n\n\nClique no botão de fazer upload de arquivos\n\n\n\n\n\nSelecione o arquivo que deseja subir e clique no botão Abrir\n\n\n\n\n\nApós o término do upload, você deve ver o arquivo no seu sistema de arquivos do notebook\n\n\nE pronto, temos um arquivo pronto para ser utilizado!\n\n\nDisponibilizando arquivos a partir do Google Drive\nOutra maneira maneira mais permanente utilizar o session storage é montar nosso Google Drive como uma pasta da session storage.\nPara fazer isso, vamos colocar no inicio do nosso notebook uma célula com o código abaixo:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nVamos executar a célula e o Google Colab deve pedir permissão para se conectar ao Drive e no final emitir a mensagem abaixo. Além disso, na lista de pastas, à esquerda, devemos ver a pasta que indicamos que receberia o mount do Google Drive.\n\n\n\nGoogle Drive mapeado após a execução do código\n\n\nA próxima etapa é realizar a carga de um arquivo com nosso script, para que possamos realizar nossas análises.\n\n\nCarregar um arquivo de dados no notebook\nPara esse etapa, vamos utilizar a função nativa do Python para abrir arquivos open em conjunto com a biblioteca csv para carregar o conteúdo do nosso arquivo em um objeto que será posteriormente utilizado pela biblioteca de visualização. Você pode copiar e colar o código abaixo em seu próprio notebook e testar. Não esqueça que antes, você deve fazer o upload do arquivo pokemons.csv no sistema de arquivos local do notebook.\n\nimport csv                                                   # importa a biblioteca nativa csv\n\npokemons = []                                                # cria a lista de pokemons vazia\nwith open('pokemons.csv', 'r', encoding='utf-8') as arquivo: # abre o arquivo\n  dados = csv.DictReader(arquivo)                            # utiliza a biblioteca csv para ler cada linha do arquivo \n                                                             # e carrega-la em um dicionário de dados\n  for pokemon in dados:                                      # percorre o arquivo linha a linha\n    pokemons.append(pokemon)                                 # adiciona cada linha na nova lista\n\nPara verificar se o conteúdo foi carregado na lista de pokemons, podemos executar o código abaixo:\n\nfor indice in range(0, 2):    # executa um loop dos dois primeiros elementos do array\n  print(pokemons[indice])     # imprime o elemento\n\n{'Number': '1', 'Name': 'Bulbasaur', 'Type 1': 'Grass', 'Type 2': 'Poison', 'Abilities': \"['Chlorophyll', 'Overgrow']\", 'HP': '45', 'Att': '49', 'Def': '49', 'Spa': '65', 'Spd': '65', 'Spe': '45', 'BST': '318', 'Mean': '53.0', 'Standard Deviation': '8.640987597877146', 'Generation': '1.0', 'Experience type': 'Medium Slow', 'Experience to level 100': '1059860', 'Final Evolution': '0.0', 'Catch Rate': '45', 'Legendary': '0.0', 'Mega Evolution': '0.0', 'Alolan Form': '0.0', 'Galarian Form': '0.0', 'Against Normal': '1.0', 'Against Fire': '2.0', 'Against Water': '0.5', 'Against Electric': '0.5', 'Against Grass': '0.25', 'Against Ice': '2.0', 'Against Fighting': '0.5', 'Against Poison': '1.0', 'Against Ground': '1.0', 'Against Flying': '2.0', 'Against Psychic': '2.0', 'Against Bug': '1.0', 'Against Rock': '1.0', 'Against Ghost': '1.0', 'Against Dragon': '1.0', 'Against Dark': '1.0', 'Against Steel': '1.0', 'Against Fairy': '0.5', 'Height': '0.7', 'Weight': '6.9', 'BMI': '14.1'}\n{'Number': '2', 'Name': 'Ivysaur', 'Type 1': 'Grass', 'Type 2': 'Poison', 'Abilities': \"['Chlorophyll', 'Overgrow']\", 'HP': '60', 'Att': '62', 'Def': '63', 'Spa': '80', 'Spd': '80', 'Spe': '60', 'BST': '405', 'Mean': '67.5', 'Standard Deviation': '8.902246907382429', 'Generation': '1.0', 'Experience type': 'Medium Slow', 'Experience to level 100': '1059860', 'Final Evolution': '0.0', 'Catch Rate': '45', 'Legendary': '0.0', 'Mega Evolution': '0.0', 'Alolan Form': '0.0', 'Galarian Form': '0.0', 'Against Normal': '1.0', 'Against Fire': '2.0', 'Against Water': '0.5', 'Against Electric': '0.5', 'Against Grass': '0.25', 'Against Ice': '2.0', 'Against Fighting': '0.5', 'Against Poison': '1.0', 'Against Ground': '1.0', 'Against Flying': '2.0', 'Against Psychic': '2.0', 'Against Bug': '1.0', 'Against Rock': '1.0', 'Against Ghost': '1.0', 'Against Dragon': '1.0', 'Against Dark': '1.0', 'Against Steel': '1.0', 'Against Fairy': '0.5', 'Height': '1.0', 'Weight': '13.0', 'BMI': '13.0'}\n\n\nPodemos ver no resultado da célula de código que aquele for imprimiu o conteúdo de duas linhas do arquivo de pokemons."
  },
  {
    "objectID": "posts/data-104/index.html#transformando-do-formato-largo-para-o-longo",
    "href": "posts/data-104/index.html#transformando-do-formato-largo-para-o-longo",
    "title": "[VDP] Aula 04 - Prática Aulas 2 e 3",
    "section": "Transformando do formato Largo para o Longo",
    "text": "Transformando do formato Largo para o Longo\nCerto, se você chegou até aqui, então: - Criamos um notebook - Demos um nome para ele - Fizemos o upload de um arquivo de dados para o session storage do notebook - Carregamos os dados em uma lista na memória do notebook.\nO que vem a seguir? Vamos começar a utilizar estes dados.\n\nUtilizando os dados na memória\nEm um cenário real, um Cientista de Dados iniciaria agora a etapa de exploração dos dados. Essa etapa envolve trabalhar com a correlação entre as diversas variáveis contidas nos dados, totalizações de quantidade de registros por qualquer uma dessas variáveis, e, também plotando gráficos.\nVamos a um exemplo? Digamos que eu quero totalizar a quantidade pokemons de acordo com seu tipo. Essa totalização poderia ser utilizada para criar um gráfico de barras, mostrando a distribuição dos pokemons entre os tipos, mostrando qual tipo é mais frequente. É importante aqui ressaltar que temos no conjunto de dados duas colunas que especificam o tipo: Type 1 e Type 2.\nO código para fazer isso está logo abaixo.\n\ntipos_dict = {}\nfor item in pokemons:\n  if item['Type 1']:\n      tipos_dict[item['Type 1']] = tipos_dict.get(item['Type 1'], 0) + 1\n  \n  if item['Type 2']:\n      tipos_dict[item['Type 2']] = tipos_dict.get(item['Type 2'], 0) + 1\n\ntipos = []\nfor key, value in tipos_dict.items():\n  tipos.append({\"Tipo\": key, \"Valor\": value})\n\nfor item in tipos:\n   print(item)\n\n{'Tipo': 'Grass', 'Valor': 119}\n{'Tipo': 'Poison', 'Valor': 77}\n{'Tipo': 'Fire', 'Valor': 81}\n{'Tipo': 'Flying', 'Valor': 120}\n{'Tipo': 'Dragon', 'Valor': 72}\n{'Tipo': 'Water', 'Valor': 151}\n{'Tipo': 'Bug', 'Valor': 90}\n{'Tipo': 'Normal', 'Valor': 124}\n{'Tipo': 'Dark', 'Valor': 72}\n{'Tipo': 'Electric', 'Valor': 70}\n{'Tipo': 'Psychic', 'Valor': 119}\n{'Tipo': 'Ground', 'Valor': 80}\n{'Tipo': 'Ice', 'Valor': 56}\n{'Tipo': 'Steel', 'Valor': 71}\n{'Tipo': 'Fairy', 'Valor': 63}\n{'Tipo': 'Fighting', 'Valor': 73}\n{'Tipo': 'Rock', 'Valor': 74}\n{'Tipo': 'Ghost', 'Valor': 68}\n\n\nEsse código tem como objetivo contar a quantidade de ocorrências de cada tipo de Pokémon e imprimir os resultados. Ele faz isso utilizando um dicionário (tipos_dict) para armazenar a contagem de cada tipo e uma lista de dicionários (tipos) para armazenar os resultados finais.\nA primeira parte do código cria um dicionário vazio chamado tipos_dict. Em seguida, itera sobre uma lista de dicionários chamada pokemons. Para cada dicionário na lista, verifica se o valor da chave ‘Type 1’ e ‘Type 2’ é diferente de None. Se pelo menos um desses valores existir, a chave correspondente no dicionário tipos_dict é incrementada em 1.\nA segunda parte do código cria uma lista vazia chamada tipos e itera sobre os pares de chave-valor no dicionário tipos_dict. Para cada par de chave-valor, cria um novo dicionário com as chaves “Tipo” e “Valor”, e adiciona esse dicionário à lista tipos. A última parte é apenas para nosso benefício: ela imprime o conteúdo da lista tipos.\nVoltando ao nosso cenário real, utilizaríamos a lista tipos para plotar um gráfico, por exemplo. Vamos tentar?\n\nimport matplotlib.pyplot as plt\n\n# Cria o gráfico de barras\nfor item in tipos:\n  plt.bar(item['Tipo'], item['Valor'])\n\n# Configura o título do gráfico e dos eixos\nplt.title('Pokemons por Tipo')\nplt.xlabel('Tipos')\nplt.ylabel('Número de Pokemons')\n\n# Exibe o gráfico na tela\nplt.show()\n\n\n\n\n\n\n\n\nOlha só, conseguimos! Temos claramente um problema de formatação ocorrendo (o eixo do X está pequeno e a descrição dos tipos estão se sobrepondo), mas com alguns ajustes é um resultado correto. Mas ainda existem alguns problemas que precisam ser discutidos.\n\n\nTransformando o formato dos dados\nO nosso script, embora correto, sob o ponto de vista de Cientistas de Dados, deixa um pouco a desejar sob o ponto de vista da engenharia de software. Por exemplo, utilizamos muito mais memória que o necessário para realizar a totalização, porque tinhamos que analisar o registro completo que tem mais de 50 colunas, mesmo que precisassemos apenas de duas. Para obter os dados que funcionassem com a visualização, tivemos que fazer duas transformações. E ainda, na parte onde fazemos o plot do gráfico, tivemos que recorrer a um for loop para conseguir adicionar todas a barras no gráfico.\nE esses problema ocorrem porque os dados acima estão no formato largo. Quando estamos iniciando, isso talvez não pareça um grande problema, mas conforme a complexidade das nossas análises aumenta, utilização de memória, redução da quantidade leitura/escrita e a otimização do código se tornarão mais e mais importantes.\nPara resolver isso, podemos transformar os nossos dados para o formato longo. Vamos ver como podemos fazer isso no nosso código.\n\nimport csv\n\npokemons = {}\nwith open('pokemons.csv', 'r', encoding='utf-8') as arquivo:\n  dados = csv.DictReader(arquivo)\n\n  for pokemon in dados:\n    for key, value in pokemon.items():\n      pokemons.setdefault(key,[]).append(value)\n\nEste trecho de código em Python é bem parecido com o nosso código inicial, no sentido em que usamos as mesmas bibliotecas e executamos os mesmos primeiros passos. A diferença começa no primeiro for loop.\nO for loop que segue itera sobre os dados do arquivo CSV, que são retornados como um dicionário. Para cada dicionário de dados, o código itera sobre as chaves do dicionário (que correspondem às colunas do arquivo CSV) e adiciona os valores correspondentes à lista correspondente no dicionário pokemons.\nPor exemplo, se o arquivo CSV tiver uma coluna chamada “Nome” contendo os nomes dos Pokémons, o código adicionará cada nome encontrado à lista pokemons[“Name”]. Essa abordagem permite armazenar os dados dos Pokémons de forma organizada e fácil de manipular.\nAo final da execução desse trecho de código, o dicionário pokemons terá as informações lidas do arquivo CSV. Cada chave do dicionário corresponderá a uma coluna do arquivo CSV, e cada valor corresponderá à lista dos valores encontrados nessa coluna. Por exemplo, se o arquivo CSV tiver uma coluna chamada “Type 1”, a lista pokemons[“Type 1”] conterá os tipos encontrados nessa coluna.\nAgora vamos ver como iremos contabilizar os tipos neste novo formato e plotar o gráfico.\n\ntotal = { \"Tipo\": list(filter(None,pokemons[\"Type 1\"])) + list(filter(None,pokemons[\"Type 2\"]))}\n\nimport seaborn as sns\nsns.countplot(x='Tipo', data=total)\n\n\n\n\n\n\n\n\nFicou bem mais fácil fazer o plot deste gráfico, não? Temos basicamente o mesmo resultado com menos linhas. E se observarmos bem, no momento que fazemos o processo na primeira linha, acessamos apenas as colunas que estão envolvidas no cálculo."
  },
  {
    "objectID": "posts/data-104/index.html#usando-bibliotecas-externas-para-facilitar-o-trabalho",
    "href": "posts/data-104/index.html#usando-bibliotecas-externas-para-facilitar-o-trabalho",
    "title": "[VDP] Aula 04 - Prática Aulas 2 e 3",
    "section": "Usando bibliotecas externas para facilitar o trabalho",
    "text": "Usando bibliotecas externas para facilitar o trabalho\nEstamos chegando ao fim desta aula prática, e o aprendizado obtido acredito ter sido bem relevante. Já sabemos como disponibilizar um arquivo de dados para ser consumido pelo script em nosso notebook, aprendemos a formatar esse arquivo em memória para um processamento mais eficiente, e também mostramos rapidamente como utilizar o dado processado para plotar alguns gráficos.\nSe vocês olharam com atenção ao código que escrevemos, verão que utilizamos muita vezes, no início de cada parte do script o comando import. Esse comando é utilizado para deixarmos explicito no script quais bibliotecas externas ao módulo básico da linguagem Python. O objetivo dessas bibliotecas é justamente nos ajudar com a simplificação do código.\nAo longo do restante das aulas, iremos utilizar várias bibliotecas como Pandas, Seaborn, MatplotLib e muitas outras. Ao final de cada aula, deixaremos alguns links que os ajudarão a começar a entender melhor cada uma dessas biblioteca.\nE nesta aula, vamos deixar o link para a documentação do Python, a partir de onde poderemos nos informar sobre várias bibliotecas que usamos cotidianamente como csv, json, os, sys, logging, ....\n\n\n\n\n\n\nTip\n\n\n\nPython Docs - Library Reference\n\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-102/index.html",
    "href": "posts/data-102/index.html",
    "title": "Aula 02 - Google Colab",
    "section": "",
    "text": "Introdução\nOlá Cientista de Dados!\nNesta aula vamos conhecer o Google Colab, e entender como utiliza-lo em nossas tarefas de Análise e Visualização de Dados.\nVamos lá?\n\n\nO que é o Google Colab?\nO Google Colab é uma plataforma de computação em nuvem gratuita baseada no Jupyter Notebook. Ele permite que os usuários criem e compartilhem documentos que contenham código executável, equações, visualizações e texto explicativo. O Google Colab oferece suporte a várias linguagens de programação populares, incluindo Python, JavaScript e Swift.\nIsto significa que podemos intercalar blocos de texto, imagens e código em um mesmo documento. Como um Cientista de Dados, você vai utilizar muito este recurso tanto nos momentos em que você está trabalhando os dados e construindo o modelo quanto naquele momento em que você precisa comunicar seus achados e resultados para outros cientistas e para o seu público alvo.\n\n\nComo acessamos o Google Colab?\nPara acessar o Google Colab, você precisa se conectar com uma conta do Google e acessar o site colab.research.google.com. Você verá então, a seguinte tela:\n\n\n\nTela Inicial do Colab\n\n\nComo você pode ver, a primeira atividade que ele sugere é abrir exemplos ou, no meu caso, alguns arquivos mais recentes. O Colab é integrado com o Google Drive, então seus arquivos, que terão sempre a extensão .ipynb estarão sempre salvos lá no seu Drive, em uma pasta específica.\n\n\nIniciando um novo notebook!\nVamos iniciar? Clique no link “new notebook”. Você deve ver sua tela assim:\n\n\n\nNovo Notebook\n\n\nNeste momento, vamos destacar três áreas da tela:\n\nOnde fica o nome do notebook. Você pode modificar quando quiser\nSistema de arquivos do notebook. Quando iniciamos um novo notebook, temos um sistema de arquivos virtual, onde podemos subir arquivos que serão utilizados durante a execução do código. Esses arquivos são apagados quando o notebook não está ativo.\nEsta é uma célula. Um notebook é feito de um conjunto de células que são executadas sequencialmente. As células podem ser de dois tipos: células de código ou células de texto. A célula que estamos marcando é especificamente uma célula de código, pois tem o botão de execução bem a esquerda.\n\n\nCélulas de Texto\nAs células de texto nos permitem escrever texto no formato Markdown, que facilita bastante a formatação. Se quiser aprender mais sobre Markdown, clique aqui. Veja alguns exemplos:\n\n\n\nExemplos de célula de texto\n\n\n\n\nCélulas de Código\nCélulas de código, como o próprio nome diz, servem para escrever código que será executado. Podemos usar algumas linguagens, sendo que a mais comum é Python. Cada célula, ao ser executada, pode imprimir o resultado de sua execução logo abaixo. Veja um exemplo abaixo:\n\nimport pandas as pd\nimport json\nimport requests\n\nresponse = requests.get(\"https://dummyjson.com/products\")\njson.dump(json.loads(response.text)['products'], open('products.json','w'))\nraw_data = open('products.json','r')\n# .load(\"https://dummyjson.com/products\")\ndf = pd.read_json(raw_data)\n\ndf\n\n\n\n\n\n\n\n\nid\ntitle\ndescription\nprice\ndiscountPercentage\nrating\nstock\nbrand\ncategory\nthumbnail\nimages\n\n\n\n\n0\n1\niPhone 9\nAn apple mobile which is nothing like apple\n549\n12.96\n4.69\n94\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/1/thumbn...\n[https://i.dummyjson.com/data/products/1/1.jpg...\n\n\n1\n2\niPhone X\nSIM-Free, Model A19211 6.5-inch Super Retina H...\n899\n17.94\n4.44\n34\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/2/thumbn...\n[https://i.dummyjson.com/data/products/2/1.jpg...\n\n\n2\n3\nSamsung Universe 9\nSamsung's new variant which goes beyond Galaxy...\n1249\n15.46\n4.09\n36\nSamsung\nsmartphones\nhttps://i.dummyjson.com/data/products/3/thumbn...\n[https://i.dummyjson.com/data/products/3/1.jpg]\n\n\n3\n4\nOPPOF19\nOPPO F19 is officially announced on April 2021.\n280\n17.91\n4.30\n123\nOPPO\nsmartphones\nhttps://i.dummyjson.com/data/products/4/thumbn...\n[https://i.dummyjson.com/data/products/4/1.jpg...\n\n\n4\n5\nHuawei P30\nHuawei’s re-badged P30 Pro New Edition was off...\n499\n10.58\n4.09\n32\nHuawei\nsmartphones\nhttps://i.dummyjson.com/data/products/5/thumbn...\n[https://i.dummyjson.com/data/products/5/1.jpg...\n\n\n5\n6\nMacBook Pro\nMacBook Pro 2021 with mini-LED display may lau...\n1749\n11.02\n4.57\n83\nApple\nlaptops\nhttps://i.dummyjson.com/data/products/6/thumbn...\n[https://i.dummyjson.com/data/products/6/1.png...\n\n\n6\n7\nSamsung Galaxy Book\nSamsung Galaxy Book S (2020) Laptop With Intel...\n1499\n4.15\n4.25\n50\nSamsung\nlaptops\nhttps://i.dummyjson.com/data/products/7/thumbn...\n[https://i.dummyjson.com/data/products/7/1.jpg...\n\n\n7\n8\nMicrosoft Surface Laptop 4\nStyle and speed. Stand out on HD video calls b...\n1499\n10.23\n4.43\n68\nMicrosoft Surface\nlaptops\nhttps://i.dummyjson.com/data/products/8/thumbn...\n[https://i.dummyjson.com/data/products/8/1.jpg...\n\n\n8\n9\nInfinix INBOOK\nInfinix Inbook X1 Ci3 10th 8GB 256GB 14 Win10 ...\n1099\n11.83\n4.54\n96\nInfinix\nlaptops\nhttps://i.dummyjson.com/data/products/9/thumbn...\n[https://i.dummyjson.com/data/products/9/1.jpg...\n\n\n9\n10\nHP Pavilion 15-DK1056WM\nHP Pavilion 15-DK1056WM Gaming Laptop 10th Gen...\n1099\n6.18\n4.43\n89\nHP Pavilion\nlaptops\nhttps://i.dummyjson.com/data/products/10/thumb...\n[https://i.dummyjson.com/data/products/10/1.jp...\n\n\n10\n11\nperfume Oil\nMega Discount, Impression of Acqua Di Gio by G...\n13\n8.40\n4.26\n65\nImpression of Acqua Di Gio\nfragrances\nhttps://i.dummyjson.com/data/products/11/thumb...\n[https://i.dummyjson.com/data/products/11/1.jp...\n\n\n11\n12\nBrown Perfume\nRoyal_Mirage Sport Brown Perfume for Men & Wom...\n40\n15.66\n4.00\n52\nRoyal_Mirage\nfragrances\nhttps://i.dummyjson.com/data/products/12/thumb...\n[https://i.dummyjson.com/data/products/12/1.jp...\n\n\n12\n13\nFog Scent Xpressio Perfume\nProduct details of Best Fog Scent Xpressio Per...\n13\n8.14\n4.59\n61\nFog Scent Xpressio\nfragrances\nhttps://i.dummyjson.com/data/products/13/thumb...\n[https://i.dummyjson.com/data/products/13/1.jp...\n\n\n13\n14\nNon-Alcoholic Concentrated Perfume Oil\nOriginal Al Munakh® by Mahal Al Musk | Our Imp...\n120\n15.60\n4.21\n114\nAl Munakh\nfragrances\nhttps://i.dummyjson.com/data/products/14/thumb...\n[https://i.dummyjson.com/data/products/14/1.jp...\n\n\n14\n15\nEau De Perfume Spray\nGenuine Al-Rehab spray perfume from UAE/Saudi...\n30\n10.99\n4.70\n105\nLord - Al-Rehab\nfragrances\nhttps://i.dummyjson.com/data/products/15/thumb...\n[https://i.dummyjson.com/data/products/15/1.jp...\n\n\n15\n16\nHyaluronic Acid Serum\nL'OrÃ©al Paris introduces Hyaluron Expert Repl...\n19\n13.31\n4.83\n110\nL'Oreal Paris\nskincare\nhttps://i.dummyjson.com/data/products/16/thumb...\n[https://i.dummyjson.com/data/products/16/1.pn...\n\n\n16\n17\nTree Oil 30ml\nTea tree oil contains a number of compounds, i...\n12\n4.09\n4.52\n78\nHemani Tea\nskincare\nhttps://i.dummyjson.com/data/products/17/thumb...\n[https://i.dummyjson.com/data/products/17/1.jp...\n\n\n17\n18\nOil Free Moisturizer 100ml\nDermive Oil Free Moisturizer with SPF 20 is sp...\n40\n13.10\n4.56\n88\nDermive\nskincare\nhttps://i.dummyjson.com/data/products/18/thumb...\n[https://i.dummyjson.com/data/products/18/1.jp...\n\n\n18\n19\nSkin Beauty Serum.\nProduct name: rorec collagen hyaluronic acid w...\n46\n10.68\n4.42\n54\nROREC White Rice\nskincare\nhttps://i.dummyjson.com/data/products/19/thumb...\n[https://i.dummyjson.com/data/products/19/1.jp...\n\n\n19\n20\nFreckle Treatment Cream- 15gm\nFair & Clear is Pakistan's only pure Freckle c...\n70\n16.99\n4.06\n140\nFair & Clear\nskincare\nhttps://i.dummyjson.com/data/products/20/thumb...\n[https://i.dummyjson.com/data/products/20/1.jp...\n\n\n20\n21\n- Daal Masoor 500 grams\nFine quality Branded Product Keep in a cool an...\n20\n4.81\n4.44\n133\nSaaf & Khaas\ngroceries\nhttps://i.dummyjson.com/data/products/21/thumb...\n[https://i.dummyjson.com/data/products/21/1.pn...\n\n\n21\n22\nElbow Macaroni - 400 gm\nProduct details of Bake Parlor Big Elbow Macar...\n14\n15.58\n4.57\n146\nBake Parlor Big\ngroceries\nhttps://i.dummyjson.com/data/products/22/thumb...\n[https://i.dummyjson.com/data/products/22/1.jp...\n\n\n22\n23\nOrange Essence Food Flavou\nSpecifications of Orange Essence Food Flavour ...\n14\n8.04\n4.85\n26\nBaking Food Items\ngroceries\nhttps://i.dummyjson.com/data/products/23/thumb...\n[https://i.dummyjson.com/data/products/23/1.jp...\n\n\n23\n24\ncereals muesli fruit nuts\noriginal fauji cereal muesli 250gm box pack or...\n46\n16.80\n4.94\n113\nfauji\ngroceries\nhttps://i.dummyjson.com/data/products/24/thumb...\n[https://i.dummyjson.com/data/products/24/1.jp...\n\n\n24\n25\nGulab Powder 50 Gram\nDry Rose Flower Powder Gulab Powder 50 Gram • ...\n70\n13.58\n4.87\n47\nDry Rose\ngroceries\nhttps://i.dummyjson.com/data/products/25/thumb...\n[https://i.dummyjson.com/data/products/25/1.pn...\n\n\n25\n26\nPlant Hanger For Home\nBoho Decor Plant Hanger For Home Wall Decorati...\n41\n17.86\n4.08\n131\nBoho Decor\nhome-decoration\nhttps://i.dummyjson.com/data/products/26/thumb...\n[https://i.dummyjson.com/data/products/26/1.jp...\n\n\n26\n27\nFlying Wooden Bird\nPackage Include 6 Birds with Adhesive Tape Sha...\n51\n15.58\n4.41\n17\nFlying Wooden\nhome-decoration\nhttps://i.dummyjson.com/data/products/27/thumb...\n[https://i.dummyjson.com/data/products/27/1.jp...\n\n\n27\n28\n3D Embellishment Art Lamp\n3D led lamp sticker Wall sticker 3d wall art l...\n20\n16.49\n4.82\n54\nLED Lights\nhome-decoration\nhttps://i.dummyjson.com/data/products/28/thumb...\n[https://i.dummyjson.com/data/products/28/1.jp...\n\n\n28\n29\nHandcraft Chinese style\nHandcraft Chinese style art luxury palace hote...\n60\n15.34\n4.44\n7\nluxury palace\nhome-decoration\nhttps://i.dummyjson.com/data/products/29/thumb...\n[https://i.dummyjson.com/data/products/29/1.jp...\n\n\n29\n30\nKey Holder\nAttractive DesignMetallic materialFour key hoo...\n30\n2.92\n4.92\n54\nGolden\nhome-decoration\nhttps://i.dummyjson.com/data/products/30/thumb...\n[https://i.dummyjson.com/data/products/30/1.jp...\n\n\n\n\n\n\n\nEsta célula, se executada, irá carregar dados de um site, salvar um arquivo e carrega-lo em um DataFrame que depois será impresso na área de resultados.\n\n\n\nUtilizando um notebook\nOs exemplos acima são bons para mostrar cada parte separadamente, mas vamos a um exemplo que irá ilustrar a utilização típica destes blocos.\n\nExemplo\nDigamos que você precisa entregar um relatório para o professor sobre quais são os primeiros 1000 números primos. Ele também solicita que você explique o que são números primos e como descobrir se um número é primo ou não.\nEm um cenário tradicional de programação, provavelmente se faria a entrega de pelo menos dois arquivos: um documento do word, por exemplo, com a parte descritiva e um arquivo de código-fonte com o código. Como o arquivo de código-fonte não guarda o resultado da execução, é muito provável que este resultado fosse adicionado ao documento do word, ou quem sabe, disponibilizado em um terceiro arquivo.\nDá um certo trabalho preparar tudo… Além precisar de um computador com Word e com um editor de código-fonte para fazer todo o relatório. Mas com o Google Colab, você pode fazer tudo em um único lugar: um notebook pode ser editado de qualquer lugar, através do browser!\nVeja o resultado abaixo:\n\n\n\nNotebook completo\n\n\nÉ bem interessante, não é mesmo? Tudo em um único documento, que eu posso compartilhar com outras pessoas, sem nenhuma complicação. E o melhor, quem abre este notebook, pode executar as partes que são código, quando bem quiserem, sem depender de você para atualizar os resultados.\n\n\n\nFinalizando\nEspero que você tenha gostado de aprender um pouco sobre o ambiente de desenvolvimento que iremos utilizar neste curso. Ao longo do curso, utilizaremos recursos mais avançados, então não perca a oportunidade de aprender mais sobre o Google Colab com estes links abaixo:\n\nO que é Google Colab\nGoogle Colaboratory - Hashtag Treinamentos\nVantagens de usar o Google Colab\n\n\n\n\n\n\n\nNote\n\n\n\nOs artigos citado acima e o conteúdo apresentado nesta aula não são de maneira nenhuma uma revisão extensiva do Google Colab, apresentamos apenas o necessário para você andar com seus próprios pés e no seu ritmo!\n\n\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-101/index.html",
    "href": "posts/data-101/index.html",
    "title": "Aula 01 - Teoria de Visualização de Dados",
    "section": "",
    "text": "Introdução\nOlá Cientista de Dados!\nNa primeira aula deste curso, vamos aprender um pouco de teoria sobre Visualização e Ciência de Dados, com o objetivo de compreendermos a importância da Visualização de Dados dentro da Ciência de Dados.\n\n\nO que é Ciência de Dados\nA ciência de dados é uma disciplina que usa habilidades matemáticas e técnicas avançadas de análise de dados para transformar grandes quantidades de informações em insights úteis. Ela é usada em diversos setores para tomada de decisão informada e resolução de problemas complexos.\nCiência de dados é como ser um detetive super nerd que desvenda mistérios escondidos nos dados. Os cientistas de dados mergulham em montanhas de informações, usando suas habilidades matemáticas e de programação para desvendar padrões ocultos e responder a perguntas importantes. Eles são os mestres em transformar dados bagunçados em conhecimento valioso, ajudando empresas e pesquisadores a tomar decisões informadas. É como ter um superpoder de números e algoritmos, só que sem a capa e a máscara.\n\n\nO Fluxo de Trabalho de Ciência de Dados\nO Ciclo de Vida de Ciência de Dados é a formalização das 6 etapas que os cientistas de dados trabalham a cada projeto para chegar ao final com o resultado solicitado pelo cliente, e podemos ver suas fases na imagem abaixo:\n\n\n\n1 - Entendendo o problema - aqui é feito o processo de descoberta, onde o problema que o cliente deseja resolvido é devidamente explicado, quebrado em requisitos e os dados disponíveis (ou a falta deles) são disponibilizados.\n2 - Coleta de dados - nesta fase, os conjuntos de dados iniciais caso existam são validados e se determina que outras fontes podem ser usadas para obter ou enriquecer os dados. Também são escritos os primeiros códigos para realizar a busca e download dos dados.\n3 - Processamento de dados - nesta fase os dados são analisados e transformados para atender ao propósito de negócio. Também é a fase em que começa o processo de criação de modelos de machine learning.\n4 - Exploração de dados - esta fase é caracterizada principalmente por visualização de dados sendo utilizada para compreender os dados gerados pelo modelo. São utilizadas técnicas específicas para essa exploração e todas dependem primariamente do bom entendimento na criação de visualizações de dados.\n5 - Comunicação de resultados - esta fase também reconhecida por fazer uso extensivo de técnicas de visualização de dados aliadas a técnicas de story telling para mostrar ao cliente os resultados obtidos.\n6 - Feedback - na última fase deste ciclo, se coleta as impressões do cliente e se inicia (caso necessário) uma nova iteração do projeto, para o refinamento da solução apresentada e a possibilidade de trabalhar em novos requisitos.\n\n\nO que é Visualização de Dados???\n\n\n\n\n\nTipos de Visualização\nExistem diversos tipos de visualizações disponíveis. Sua utilização está associada ao tipo de informação e ao objetivo que temos ao mostrar os dados.\n\n\n\nQuanto a objetivos, as visualizações são utilizadas com as seguintes finalidades: - Comparar valores - Evidenciar a correlação entre valores (como os dois valores se comportam em conjunto) - Como um valor se distribui em relação a uma dimensão contínua (geralmente o tempo) - Como um valor se distribui especificamente em relação a posicionamento geográfico - Como um valor se distribui entre dimensões não continuas que formam partes de um todo; o quanto cada valor representa em relação a esse todo - Como um valor se comporta em relação tempo.\n\n\nTipos de Visualização X Objetivo de Comunicação\nAbaixo segue um diagrama com uma indicação de quais gráficos podem ser utilizados de acordo com o seu objetivo.\n\n\n\n\n\nComo podemos criar Visualizações???\nAssim como existem diversos tipos de visualizações, existem diversas ferramentas. Abaixo, colocamos uma lista de ferramentas para visualização de dados: - Excel - Tableau - Power BI - Qlik - Looker (antes chamada de Google Data Studio) - Oracle Analytics - SAP Business Objects - Grafana - Kibana\nEstas ferramentas se caracterizam por uma interface de usuário totalmente voltada para a criação de visualizações. Se vocês estivessem em um curso de Análise de Dados, seriam nossa escolha para o curso, pois elas focam na modelagem dos dados e criação das visualizações. Mas vocês estão em um curso para iniciarem na carreira de Cientistas de Dados, certo?\n\nEntão, como um Cientista de Dados cria visualizações???\nUm Cientista de Dados utiliza a Visualização de Dados de duas formas: 1) Como uma ferramenta de exploração dos dados, durante a fase em que estão procurando respostas 2) Como uma ferramenta de comunicação, para divulgar resultados\nConsiderando essas duas necessidades, embora o Cientista de Dados pudesse utilizar ferramentas como as citadas anteriormente, a verdade é que ele precisa de uma ferramenta que consiga combinar o poder da programação, com visualização de dados e também com uma estrutura documental organizada para compartilhamento de informação.\nPor isso, iremos utilizar uma tecnologia diferente para aprender visualização de dados: vamos aprender a criar visualizações de forma programática, ou seja, vamos criar visualizações utilizando programas escritos em Python.\n\n\nPorquê vamos fazer isso?\nPor alguns motivos:\n\nComo cientistas de dados, a maneira mais comum de entregar os resultados do seu trabalho, além de apresentações em powerpoint é através de notebooks interativos, como o Google Colab, ou o Jupyter. São ferramentas que ajudam muito no desenvolvimento de um story telling orientado a divulgação dos resultados\nAtualmente Python é a linguagem a se aprender na carreira de Cientista de Dados. Outras linguagens como R, Julia e até Java também são utilizadas, mas por enquanto, Python é a preferida\nAs bibliotecas de visualização em Python são muito flexíveis e poderosas, inclusive são utilizadas por algumas das ferramentas citadas acima\n\n\n\n\n\n\n\nNote\n\n\n\nEntão, agora que toda a teoria necessária está explicada, bora trabalhar??? Na próxima aula, iremos aprender sobre o Google Colab, a ferramenta que escolhemos para conduzir o restante deste curso! Aula 002 - Google Colab\n\n\n\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-103/index.html",
    "href": "posts/data-103/index.html",
    "title": "[VDP] Aula 03 - Formatos de Dados",
    "section": "",
    "text": "Introdução\nOlá Cientista de Dados!\nNesta aula, vamos aprender um pouco mais sobre os formatos utilizados para armazenar dados que nossas visualizações irão consumir.\n\n\nFontes de dados e seus formatos\nPara realizarmos nossas tarefas como Cientistas de Dados, é necessário que acessemos aquilo que nos é mais caro, o nosso combustível: os dados.\nEstes dados vem das mais diversas fontes: websites, dispositivos IoT, bancos de dados, documentos, … Estas diferentes fontes significam que os dados possuem diferentes formatos, e uma de nossas tarefas é transformar este dado em um formato com o qual seja possível trabalhar e gerar os resultados esperados.\nDentro da área de Ciência da Computação, o formato mais utilizado para servir como base para o processamento de informação é o formato tabular.\n\nFormato Tabular\nO formato tabular é utilizado para descrever uma estrutura de dados organizada em linhas e colunas, formando uma tabela. É um formato muito utilizado em bancos de dados relacionais e em arquivos CSV (Comma-Separated Values), onde cada linha representa um registro ou observação e cada coluna representa uma variável ou campo. Esse formato é muito útil para representar dados estruturados de forma clara e organizada, permitindo a fácil manipulação e análise dos dados.\nAbaixo, temos um exemplo prático de como podemos utilizar Python para carregar um arquivo CSV em nosso notebook.\n\nimport csv\n\n# Abre o arquivo CSV em modo leitura\nwith open('exemplo.csv', 'r') as arquivo_csv:\n    # Cria um objeto para ler o arquivo CSV\n    leitor_csv = csv.reader(arquivo_csv, delimiter=',')\n\n    # Percorre as linhas do arquivo CSV\n    for linha in leitor_csv:\n        print(linha)\n\n['Nome', 'Idade', 'Cidade']\n['Maria', '25', 'São Paulo']\n['João', '30', 'Rio de Janeiro']\n['Ana', '20', 'Belo Horizonte']\n['Andre', '23', 'Porto Alegre']\n\n\nNeste exemplo, utilizamos a função open para abrir o arquivo CSV em modo leitura e, em seguida, criamos um objeto csv.reader para ler o arquivo CSV. Utilizamos o parâmetro delimiter para indicar o caractere separador utilizado no arquivo CSV (no caso, a vírgula). Em seguida, utilizamos um loop for para percorrer as linhas do arquivo CSV e imprimir cada uma delas na tela.\nNote que, neste exemplo, o resultado é uma lista de listas, onde cada lista interna representa uma linha do arquivo CSV. Para manipular os dados, é necessário fazer a conversão manualmente para o formato desejado.\nE, apesar deste formato ser adequado ao processamento dos dados para visualização, ainda precisamos fazer alguns ajustes até chegar ao formato ideal.\n\n\n\nOtimizando o Formato Tabular\nO formato tabular padrão também pode ser referenciado pelo termo ‘Formato Largo’ (Wide format em inglês), por sua característica de organização em linhas e colunas, com a linha sendo uma observação e as colunas sendo as variáveis da observação. Isto pode ser percebido pelo formato que nossos código percorrem os arquivos ou selecionam a informação de um banco de dados: sempre pensando em extrair linhas que depois são usadas em algum tipo de processamento. Isso gera o que chamamos de overhead no processamento, porque por vezes precisamos apenas fazer o processamento de uma coluna de dados, mas somos obrigados a acessar todas as colunas para depois selecionar a coluna que queremos.\nPara resolver essa questão, foi criado um caso especial de formato tabular, o chamado ‘Formato Longo’ (Long format em inglês), onde a orientação da organização dos dados é colunas e linhas, ou seja, podemos acessar uma coluna individualmente, com todas as suas linhas.\n\n\n\nFormato Longo X Formato Largo\n\n\nEm Python e em muitas outras linguagens de programação que são utilizadas para Ciência de Dados, o formato tabular é representado por estruturas de dados especiais, chamadas de DataFrames e Series.\nMas antes de explicar em mais detalhes essas estruturas, vamos conhecer um pouco das suas origens.\n\n\nDicionários e Listas\nSe você já conhece o básico de Python, já aprendeu que temos os tipos de dados conhecidos como listas e dicionário de dados. Com estes tipos, podemos representar dados mais complexos, como uma sequência ou um objeto, que são compostos de vários tipos simples. Se você quiser aprender mais sobre listas e dicionários, vá para o final deste notebook.\nEm Python, a representação de dados no formato tabular, seja longo ou largo, passa pela combinação destes dois tipos de dados.\n\nRepresentação em Python do Formato Largo\nPara criar um objeto em Python que represente um conjunto de dados no Formato Largo, é necessário montar uma lista de dicionários.\n\ndados_largos = [\n    {\"codigo\": 1, \"nome\": \"Jose\"},\n    {\"codigo\": 2, \"nome\": \"Maria\"},\n    {\"codigo\": 3, \"nome\": \"Fernandez\"}\n]\n\nNeste objeto, temos uma lista que contém 3 elementos. Cada elemento é um dicionário com dois campos. Conforme explicamos anteriormente, no formato largo, para acessar o nome de uma pessoa, precisamos identificar em que linha ela está. Para identificar a linha, percorremos nossa lista. Para inspecionar o nome, recuperamos todo o dicionário que está naquela posição da lista.\n\n\nRepresentação em Python do Formato Longo\nPara criar um objeto em Python que represente um conjunto de dados no Formato Longo, é necessário montar um dicionário de listas.\n\ndados_longos = {\n                \"codigo\": [1,2,3], \n                \"nome\": [\"Jose\",\"Maria\",\"Fernandez\"]\n               }\n\nNeste objeto, temos o dicionário com seus campos, e cada campo é uma lista com os valores para cada linha.\n\n\nEntendendo a diferença\nVamos ver um exemplo prático para entender a diferença entre os dois. Acompanhe no código abaixo e leia os comentários.\n\n# Queremos saber o nome do usuário que está na segunda linha do nosso conjunto de dados.\n\n# Formato largo\nprint(dados_largos[1][\"nome\"]) # utilizamos o indice 1 porque em Python listas começam no indice 0\n\n# Formato longo\nprint(dados_longos[\"nome\"][1]) # apenas invertemos a referência - primeiro a coluna, depois a linha\n\nMaria\nMaria\n\n\nA diferença parece pouca, certo? Apenas invertemos como os indices são acessados, onde está a tal otimização?\nA otimização está no fato de que, ao acessar a linha de um dado no formato largo, estamos acessando todas as colunas de informação daquela linha.\n\nprint(dados_largos[1])\n\n{'codigo': 2, 'nome': 'Maria'}\n\n\nJá no formato longo, antes de especificar a linha, eu preciso referenciar a coluna, portanto, sempre terei apenas um valor.\n\nprint(dados_longos[\"nome\"][1])\n\nMaria\n\n\n\n\n\nDataFrames e Series\nO DataFrame e as Series são dois dos principais conceitos utilizados para trabalhar com dados em Python. Ambos estão presentes na biblioteca Pandas, que é uma das ferramentas mais usadas para análise de dados.\nO DataFrame é um objeto que tem como base o conceito de dicionário de listas, onde as listas são representadas por Series. O DataFrame adiciona uma série de funcionalidades ao dicionário de listas, simplificando a manipulação dos mesmos.\nExemplo de código:\n\nimport pandas as pd \ndf = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \nprint(df[2][2])\n\n9\n\n\nA Series é uma lista com superpoderes. Assim como o DataFrame, a Series acrescenta muitas facilidades para manipular a lista. Exemplo de código:\n\nimport pandas as pd \ns = pd.Series([1, 2, 3]) \nprint(s[2])\n\n3\n\n\nAlém do Pandas existem outras bibliotecas que utilizam esses conceitos para trabalhar com dados como NumPy (Numerical Python), SciPy (Scientific Python) e Scikit-learn (Machine Learning).\n\n\nFinalizando\nNesta aula, aprendemos sobre os formatos de dados que podemos utilizar em nossas visualizações e conhecemos mais detalhes dos DataFrames e Series.\nAqui temos alguns links sobre o assunto: - Listas - Dicionários\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-105/index.html",
    "href": "posts/data-105/index.html",
    "title": "[VDP] Aula 05 - Pandas",
    "section": "",
    "text": "Olá Cientista de Dados!\nSe você chegou até aqui, significa que já deve ter aprendido como carregar os dados no Google Colab utilizando as bibliotecas padrão do python. E deve ter percebido que a tarefa não é simples, e requer muitas linhas de código (Rapadura é doce mas não é mole não, diria o Yusuke Urameshi).\nJustamente com a intenção de simplificar o trabalho dos cientistas e engenheiros de dados é que a biblioteca Pandas foi criada. Com a biblioteca Pandas, todo o trabalho de manipulação dos dados fica simplificado, rápido e mais organizado."
  },
  {
    "objectID": "posts/data-105/index.html#introdução",
    "href": "posts/data-105/index.html#introdução",
    "title": "[VDP] Aula 05 - Pandas",
    "section": "",
    "text": "Olá Cientista de Dados!\nSe você chegou até aqui, significa que já deve ter aprendido como carregar os dados no Google Colab utilizando as bibliotecas padrão do python. E deve ter percebido que a tarefa não é simples, e requer muitas linhas de código (Rapadura é doce mas não é mole não, diria o Yusuke Urameshi).\nJustamente com a intenção de simplificar o trabalho dos cientistas e engenheiros de dados é que a biblioteca Pandas foi criada. Com a biblioteca Pandas, todo o trabalho de manipulação dos dados fica simplificado, rápido e mais organizado."
  },
  {
    "objectID": "posts/data-105/index.html#instalando-pandas",
    "href": "posts/data-105/index.html#instalando-pandas",
    "title": "[VDP] Aula 05 - Pandas",
    "section": "Instalando Pandas",
    "text": "Instalando Pandas\nTenho uma boa notícia: como estamos utilizando o Google Colab para nossas aulas, ele já vem instalado no nosso ambiente! Mas caso você esteja também se aventurando em fazer este curso no VS Code, PyCharm, Sublime ou até mesmo Notepad, o comando para instalar a biblioteca Pandas é o seguinte:\n(venv) $ pip install pandas\nEste comando irá instalar a biblioteca Pandas e todos as bibliotecas dependentes."
  },
  {
    "objectID": "posts/data-105/index.html#utilizando-pandas",
    "href": "posts/data-105/index.html#utilizando-pandas",
    "title": "[VDP] Aula 05 - Pandas",
    "section": "Utilizando Pandas",
    "text": "Utilizando Pandas\nIremos ver, passo a passo, como utilizar a biblioteca Pandas em nosso notebook Google Colab, passando pelos seus principais conceitos.\n\nCarregando Pandas no notebook\nA primeira coisa que devemos fazer é carregar a biblioteca em nosso notebook. Fazemos isso com o comando import.\n\nimport pandas as pd\n\n\n\n\n\n\n\nTip\n\n\n\nÉ considerado uma boa prática ao carregar a biblioteca sempre utilizar o alias pd. Observe que todos os artigos na internet se utilizam essa mesma referência.\n\n\n\n\nCarregando os dados\nNa aula 3, aprendemos que uma maneira de carregar os dados em um notebook on Google Colab é a seguinte:\nimport csv\n\npokemons = {}\nwith open('pokemons.csv', 'r', encoding='utf-8') as arquivo:\n  dados = csv.DictReader(arquivo)\n\n  for pokemon in dados:\n    for key, value in pokemon.items():\n      pokemons.setdefault(key,[]).append(value)\nUtilizando pandas, isso será substituído por uma única linha:\n\npokemons = pd.read_csv('pokemons.csv')\n\nFicou bem mais fácil, não é mesmo? Da mesma forma, verificar o conteúdo que foi carregado também se simplifica - vai disso aqui:\nfor indice in range(0, 2):    # executa um loop dos dois primeiros elementos do array\n  print(pokemons[indice])     # imprime o elemento\npara isso aqui:\n\npokemons.head(2)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n45\n49\n49\n65\n65\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.7\n6.9\n14.1\n\n\n1\n2\nIvysaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n60\n62\n63\n80\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n13.0\n13.0\n\n\n\n\n2 rows × 44 columns\n\n\n\n\n\nMas não é só isso…\nOutra grande vantagem de se utilizar pandas é que temos a nossa disposição um grande número de opções para carregar dados. Além do read_csv, temos readers especializados: read_json, read_excel, e por aí vai… Aconselho a dar uma olhada no manual do pandas aqui.\n\n\nInspecionando os dados\nApós termos os dados carregados, a nossa próxima atividade é inspecionar os dados. Além do comando que vimos acima head(), que pode nos mostrar as primeiras linhas do DataFrame, temos outras funções, como:\n\ntail() - mostra as últimas linhas do DataFrame\nsample() - mostra linhas aleatórias do DataFrame\ndescribe() - mostra os valores de diversas medidas\ninfo() - mostra os campos do DataFrame com seus tipos\nshape - dá as dimensões (coluna, linha) do DataFrame\n\nVamos ver em detalhes cada uma destas funções.\n\nhead()\nEsta função lista as primeiras linhas de dados. O pârametro é opcional, o que fará com que a função liste 10 linhas de dados.\n\npokemons.head(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n45\n49\n49\n65\n65\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.7\n6.9\n14.1\n\n\n1\n2\nIvysaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n60\n62\n63\n80\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n13.0\n13.0\n\n\n2\n3\nVenusaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n80\n82\n83\n100\n100\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n2.0\n100.0\n25.0\n\n\n3\n3\nMega Venusaur\nGrass\nPoison\n['Thick Fat']\n80\n100\n123\n122\n120\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n2.4\n155.5\n27.0\n\n\n4\n4\nCharmander\nFire\nNaN\n['Blaze', 'Solar Power']\n39\n52\n43\n60\n50\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n0.5\n0.5\n0.6\n8.5\n23.6\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\ntail()\nEsta função lista as últimas linhas de dados. O pârametro é opcional, o que fará com que a função liste 10 linhas de dados.\n\npokemons.tail(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n1027\n896\nGlastrier\nIce\nNaN\n['Chilling Neigh']\n100\n145\n130\n65\n110\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n2.0\n1.0\n2.2\n800.0\n165.3\n\n\n1028\n897\nSpectrier\nGhost\nNaN\n['Grim Neigh']\n100\n65\n60\n145\n80\n...\n0.5\n1.0\n2.0\n1.0\n2.0\n1.0\n1.0\n2.0\n44.5\n11.1\n\n\n1029\n898\nCalyrex\nPsychic\nGrass\n['Unnerve']\n100\n80\n80\n80\n80\n...\n4.0\n1.0\n2.0\n1.0\n2.0\n1.0\n1.0\n1.1\n7.7\n6.4\n\n\n1030\n898\nCalyrex Ice Rider\nPsychic\nIce\n['As One']\n100\n165\n150\n85\n130\n...\n2.0\n2.0\n2.0\n1.0\n2.0\n2.0\n1.0\n2.4\n809.1\n140.5\n\n\n1031\n898\nCalyrex Shadow Rider\nPsychic\nGhost\n['As One']\n100\n85\n80\n165\n100\n...\n1.0\n1.0\n4.0\n1.0\n4.0\n1.0\n1.0\n2.4\n53.6\n9.3\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\nsample()\nEnquanto head() e tail() mostra o início e o fim do conjunto de dados, o sample() traz linhas aleatórias do conjunto, o que pode ser bem interessante.\n\npokemons.sample(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n327\n271\nLombre\nWater\nGrass\n['Own Tempo', 'Rain Dish', 'Swift Swim']\n60\n50\n50\n60\n70\n...\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.2\n32.5\n22.6\n\n\n514\n433\nChingling\nPsychic\nNaN\n['Levitate']\n45\n30\n50\n65\n50\n...\n2.0\n1.0\n2.0\n1.0\n2.0\n1.0\n1.0\n0.2\n0.6\n15.0\n\n\n230\n186\nPolitoed\nWater\nNaN\n['Damp', 'Drizzle', 'Water Absorb']\n90\n75\n75\n90\n100\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.1\n33.9\n28.0\n\n\n849\n732\nTrumbeak\nNormal\nFlying\n['Keen Eye', 'Pickup', 'Skill Link']\n55\n85\n50\n40\n50\n...\n0.5\n2.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.6\n14.8\n41.1\n\n\n598\n506\nLillipup\nNormal\nNaN\n['Pickup', 'Run Away', 'Vital Spirit']\n45\n60\n45\n25\n45\n...\n1.0\n1.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.4\n4.1\n25.6\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\ndescribe()\nEsta função nos ajuda a ter uma idéia dos valores que temos em nosso conjunto de dados. A função lista todas as colunas numéricas e apresenta os resultados para os seguintes cálculos estatísticos: média, desvio padrão, valor mínimo, percentil 25%, 50%, 75% e valor máximo.\nIsso nos dá uma idéia da variabilidade dos nossos dados, bem como permite uma análise de correlação superficial entre os valores numéricos.\n\npokemons.describe()\n\n\n\n\n\n\n\n\nNumber\nHP\nAtt\nDef\nSpa\nSpd\nSpe\nBST\nMean\nStandard Deviation\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\ncount\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n...\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n\n\nmean\n439.226744\n69.906008\n80.526163\n74.609496\n72.918605\n72.139535\n68.548450\n438.648256\n73.108043\n20.028104\n...\n1.002180\n1.239826\n1.025678\n0.974806\n1.074855\n0.992006\n1.094234\n1.286822\n71.879845\n136.735756\n\n\nstd\n261.871350\n26.189155\n32.542374\n30.905972\n32.773495\n27.625876\n30.219526\n120.675545\n20.112591\n10.830298\n...\n0.613111\n0.699361\n0.577269\n0.378040\n0.475292\n0.511859\n0.535159\n1.391501\n132.872741\n3111.666658\n\n\nmin\n1.000000\n1.000000\n5.000000\n5.000000\n10.000000\n20.000000\n5.000000\n175.000000\n29.166667\n0.000000\n...\n0.250000\n0.250000\n0.000000\n0.000000\n0.250000\n0.250000\n0.250000\n0.100000\n0.100000\n0.000000\n\n\n25%\n211.750000\n50.000000\n55.000000\n50.000000\n50.000000\n50.000000\n45.000000\n330.000000\n55.000000\n12.801910\n...\n0.500000\n1.000000\n1.000000\n1.000000\n1.000000\n0.500000\n1.000000\n0.600000\n9.000000\n18.600000\n\n\n50%\n434.500000\n67.000000\n78.000000\n70.000000\n65.000000\n70.000000\n65.000000\n459.000000\n76.500000\n18.484228\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n29.750000\n28.350000\n\n\n75%\n667.250000\n83.000000\n100.000000\n90.000000\n95.000000\n90.000000\n90.000000\n515.000000\n85.833333\n24.835709\n...\n1.000000\n2.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.600000\n71.275000\n42.200000\n\n\nmax\n898.000000\n255.000000\n190.000000\n230.000000\n194.000000\n230.000000\n200.000000\n780.000000\n130.000000\n103.215659\n...\n4.000000\n4.000000\n4.000000\n2.000000\n4.000000\n4.000000\n4.000000\n20.000000\n999.900000\n99990.000000\n\n\n\n\n8 rows × 39 columns\n\n\n\n\n\ninfo()\nOutra função útil é a função info() que traz a descrição da estrutura do DataFrame. Com esta função, você pode verificar os seguintes dados:\n\nlista colunas do DataFrame\npara cada coluna, quantos elementos não-nulos ela possui\npara cada coluna, seu tipo\nE ainda o número total de linhas e colunas no DataFrame\n\n\npokemons.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1032 entries, 0 to 1031\nData columns (total 44 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   Number                   1032 non-null   int64  \n 1   Name                     1032 non-null   object \n 2   Type 1                   1032 non-null   object \n 3   Type 2                   548 non-null    object \n 4   Abilities                1032 non-null   object \n 5   HP                       1032 non-null   int64  \n 6   Att                      1032 non-null   int64  \n 7   Def                      1032 non-null   int64  \n 8   Spa                      1032 non-null   int64  \n 9   Spd                      1032 non-null   int64  \n 10  Spe                      1032 non-null   int64  \n 11  BST                      1032 non-null   int64  \n 12  Mean                     1032 non-null   float64\n 13  Standard Deviation       1032 non-null   float64\n 14  Generation               1032 non-null   float64\n 15  Experience type          1032 non-null   object \n 16  Experience to level 100  1032 non-null   int64  \n 17  Final Evolution          1032 non-null   float64\n 18  Catch Rate               1032 non-null   int64  \n 19  Legendary                1032 non-null   float64\n 20  Mega Evolution           1032 non-null   float64\n 21  Alolan Form              1032 non-null   float64\n 22  Galarian Form            1032 non-null   float64\n 23  Against Normal           1032 non-null   float64\n 24  Against Fire             1032 non-null   float64\n 25  Against Water            1032 non-null   float64\n 26  Against Electric         1032 non-null   float64\n 27  Against Grass            1032 non-null   float64\n 28  Against Ice              1032 non-null   float64\n 29  Against Fighting         1032 non-null   float64\n 30  Against Poison           1032 non-null   float64\n 31  Against Ground           1032 non-null   float64\n 32  Against Flying           1032 non-null   float64\n 33  Against Psychic          1032 non-null   float64\n 34  Against Bug              1032 non-null   float64\n 35  Against Rock             1032 non-null   float64\n 36  Against Ghost            1032 non-null   float64\n 37  Against Dragon           1032 non-null   float64\n 38  Against Dark             1032 non-null   float64\n 39  Against Steel            1032 non-null   float64\n 40  Against Fairy            1032 non-null   float64\n 41  Height                   1032 non-null   float64\n 42  Weight                   1032 non-null   float64\n 43  BMI                      1032 non-null   float64\ndtypes: float64(29), int64(10), object(5)\nmemory usage: 354.9+ KB\n\n\n\n\nshape\nEsta não é uma função, mas sim uma propriedade, que retorna uma tupla com as dimensões de linha e coluna do DataFrame.\n\npokemons.shape\n\n(1032, 44)\n\n\n\n\n\nFiltrando os dados\nAgora vamos aprender como executar uma das tarefas mais comuns de manipular DataFrames com o objetivo de realizar análises: filtragem dos dados. A versão atual do pandas trouxe algumas funções que nos facilitam enormemente o processo. Mas, com o objetivo de equipa-los com o máximo de informação possível, vamos também aprender os métodos mais conhecidos.\nMas, antes de mostrarmos como realizar os filtros, vamos explicar alguns conceitos básicos, mas bem relevantes para a operação de filtragem dos dados.\n\nAcessando uma coluna do DataFrame\nPode parecer óbvio, mas para acessar a coluna de um DataFrame, basta fazer o seguinte:\n\ntipos = pokemons[\"Type 1\"]\n\nAssim, a variável tipos conterá o que chamamos de uma Series, que é um array numpy (biblioteca especializada para criação de arrays numéricos) que contém todas as linhas daquela coluna. Para comprovar isso, vamos imprimir o conteúdo.\n\ntipos\n\n0         Grass\n1         Grass\n2         Grass\n3         Grass\n4          Fire\n         ...   \n1027        Ice\n1028      Ghost\n1029    Psychic\n1030    Psychic\n1031    Psychic\nName: Type 1, Length: 1032, dtype: object\n\n\nParece interessante. Mas e se quisessemos criar um novo DataFrame apenas com as colunas Number, Name e Type 1? Parece simples, basta enviar ao DataFrame um array com o nome das colunas que quero extrair.\n\nsub_df = pokemons[[\"Number\", \"Name\", \"Type 1\"]]\n\nsub_df\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\n\n\n\n\n0\n1\nBulbasaur\nGrass\n\n\n1\n2\nIvysaur\nGrass\n\n\n2\n3\nVenusaur\nGrass\n\n\n3\n3\nMega Venusaur\nGrass\n\n\n4\n4\nCharmander\nFire\n\n\n...\n...\n...\n...\n\n\n1027\n896\nGlastrier\nIce\n\n\n1028\n897\nSpectrier\nGhost\n\n\n1029\n898\nCalyrex\nPsychic\n\n\n1030\n898\nCalyrex Ice Rider\nPsychic\n\n\n1031\n898\nCalyrex Shadow Rider\nPsychic\n\n\n\n\n1032 rows × 3 columns\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nObserve a questão da sintaxe de array: quando queremos apenas uma coluna a sintaxe de array não é necessária, ela se aplica apenas a múltiplos campos.\n\n\nMas, e como podemos acessar uma linha específica de um DataFrame? Se você está seguindo a linha de raciocínio, já imaginou que não é da maneira tradicional. Na verdade, é exatamente ao contrário do que estamos acostumados. Primeiro acessamos a coluna, e depois a linha, enquanto que em conjuntos de dados em formato tabular largo, primeiro acessamos a linha e depois a coluna.\n\npokemons[\"Name\"][0]\n\n'Bulbasaur'\n\n\n\n\nPercorrendo um DataFrame\nInteressante, certo? Mas isso levanta o seguinte questionamento: quando vou manipular os dados, como filtra-los ou fazer alguma modificação? Nos conjuntos de dados mais tradicionais, eu geralmente percorro o meu conjunto de dados linha a linha e faço os filtros e então altero as colunas. Como fazer isso em pandas?\n\nfor index, pokemon in pokemons.iterrows():\n    if index &lt;= 2:\n        print(pokemon[\"Name\"])\n    else:\n        break\n\nBulbasaur\nIvysaur\nVenusaur\n\n\nComo pode ser visto no código acima, basta usarmos a função iterrows() e iremos manipular o DataFrame como uma estrutura de dados mais tradicional, como um array de dicionário de dados. No código acima, fizemos um filtro que pega apenas as linhas com index menor ou igual 2, e mostra apenas o nome. Se DataFrames fossem estruturas de dados tradicionais, isso seria a maneira mais lógica de executar esse comando. Mas com pandas, podemos fazer isso:\n\npokemons[pokemons[\"Number\"] &lt;= 3][\"Name\"]\n\n0        Bulbasaur\n1          Ivysaur\n2         Venusaur\n3    Mega Venusaur\nName: Name, dtype: object\n\n\nWow, em uma única linha fizemos o filtro de linha e a seleção de coluna, e a principal vantagem sendo que este comando continuou retornando um DataFrame, o que ainda nos permite continuar trabalhando de forma eficiente com os dados que eu escolhi!\n\n\n\n\n\n\nWarning\n\n\n\nEmbora a utilização da função iterrows() pareça ser a forma mais natural e fácil de se trabalhar com Dataframes Pandas, é com a certeza a que apresenta a pior performance. Então, faça um esforço e aprenda muito bem os métodos mais “pandônicos” de manipular Dataframes, Cientista de Dados!\n\n\nEsta linha também nos introduz ao primeiro jeito de realizar filtros de linha: adicionando a expressão lógica nos primeiros parenteses. Parece simples, embora para referenciar ao campo que será utilizado no filtro, eu ainda precise referenciar o próprio DataFrame. E esse foi apenas um filtro simples. Como seria utilizar mais de um campo no filtro? Vamos ver agora mesmo.\n\npokemons[(pokemons[\"Number\"] &lt; 11) & (pokemons[\"Type 1\"] == \"Bug\")][\"Name\"]\n\n13    Caterpie\nName: Name, dtype: object\n\n\nPodemos perceber duas coisas: cada condição de filtro deve estar envolta em parenteses (vá em frente, se remover, teremos um erro), e em vez de usar o conector lógico tradicional AND ou OR, utilizamos & (AND) ou | (OR). E quanto mais condições, pior será para lermos com clareza nosso código.\nUma variação deste tipo de filtragem é a utilização da propriedade loc. Ela nos permite acessar linhas diretamente, e utilizando a notação de manipulação de arrays, filtrar rapidamente o DataFrame. Vamos a um exemplo: gostaria de extrair 10 linhas do DataFrame, iniciando na linha 10.\n\npokemons.loc[10:19]\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n10\n8\nWartortle\nWater\nNaN\n['Rain Dish', 'Torrent']\n59\n63\n80\n65\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.0\n22.5\n22.5\n\n\n11\n9\nBlastoise\nWater\nNaN\n['Rain Dish', 'Torrent']\n79\n83\n100\n85\n105\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.6\n85.5\n33.4\n\n\n12\n9\nMega Blastoise\nWater\nNaN\n['Mega Launcher']\n79\n103\n120\n135\n115\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.6\n101.1\n39.5\n\n\n13\n10\nCaterpie\nBug\nNaN\n['Run Away', 'Shield Dust']\n45\n30\n35\n20\n20\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.3\n2.9\n32.2\n\n\n14\n11\nMetapod\nBug\nNaN\n['Shed Skin']\n50\n20\n55\n25\n25\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.7\n9.9\n20.2\n\n\n15\n12\nButterfree\nBug\nFlying\n['Tinted Lens']\n60\n45\n50\n90\n80\n...\n0.5\n4.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.1\n32.0\n26.4\n\n\n16\n13\nWeedle\nBug\nPoison\n['Run Away', 'Shield Dust']\n40\n35\n30\n20\n20\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.3\n3.2\n35.6\n\n\n17\n14\nKakuna\nBug\nPoison\n['Shed Skin']\n45\n25\n50\n25\n25\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.6\n10.0\n27.8\n\n\n18\n15\nBeedrill\nBug\nPoison\n['Sniper', 'Swarm']\n65\n90\n40\n45\n80\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n29.5\n29.5\n\n\n19\n15\nMega Beedrill\nBug\nPoison\n['Adaptability']\n65\n150\n40\n15\n80\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.4\n40.5\n20.7\n\n\n\n\n10 rows × 44 columns\n\n\n\nBem prático. A propriedade loc também pode entender o filtro anterior.\nE agora, a última maneira pela qual podemos realizar filtros em nossos DataFrames e a mais recomendada devido a legibilidade do código gerado: vamos utilizar a função query(). Esta função permite que escrevamos filtros para o DataFrame como se o mesmo fosse um banco de dados, deixando o código mais limpo, pois eliminamos a necessidade de referenciar o DataFrame a cada filtro, bem como parênteses redundantes. Vamos ver um exemplo:\n\npokemons.query(\"Number &lt; 11 and `Type 1` == 'Bug'\")\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n13\n10\nCaterpie\nBug\nNaN\n['Run Away', 'Shield Dust']\n45\n30\n35\n20\n20\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.3\n2.9\n32.2\n\n\n\n\n1 rows × 44 columns\n\n\n\nAssim ficou bem mais limpo. Uma única observação é quanto ao uso do caracter “`” para campos com nomes compostos.\n\n\n\nAgregando os dados\nEm muitos casos, não queremos apenas filtrar os dados, mas também realizar totalizações, calcular valores médios, ou até mesmo cálculos mais complexos, de dados que devem ser agregados em um ou mais níveis.\nComo exemplo, vamos supor que quisessemos totalizar o número de pokemons de acordo com o seu tipo.\n\npokemons.groupby(['Type 1'])[\"Name\"].count().reset_index(name=\"Pokemons\")\n\n\n\n\n\n\n\n\nType 1\nPokemons\n\n\n\n\n0\nBug\n81\n\n\n1\nDark\n46\n\n\n2\nDragon\n42\n\n\n3\nElectric\n59\n\n\n4\nFairy\n22\n\n\n5\nFighting\n42\n\n\n6\nFire\n64\n\n\n7\nFlying\n8\n\n\n8\nGhost\n41\n\n\n9\nGrass\n91\n\n\n10\nGround\n41\n\n\n11\nIce\n38\n\n\n12\nNormal\n114\n\n\n13\nPoison\n40\n\n\n14\nPsychic\n77\n\n\n15\nRock\n59\n\n\n16\nSteel\n36\n\n\n17\nWater\n131\n\n\n\n\n\n\n\nMas quanta coisa nova naquela linha, não é mesmo? Vamos explicar passo a passo:\n\nA primeira função é o groupby, onde especificamos por qual coluna ou colunas iremos fazer o agrupamento. No nosso exemplo, utilizamos a coluna ‘Type 1’\nEm seguida, especificamos que, além da coluna ‘Type 1’, queremos apenas a coluna ‘Name’ nos nossos resultados\nLogo após, indicamos que o valor original da coluna ‘Name’ será substituído pelo resultado da contagem de quantas linhas do DataFrame tem aquele valor específico da coluna ‘Type 1’\nE por último, utilizamos uma função que irá trocar o nome da coluna ‘Name’ por um nome mais significativo\n\nUfa, e tudo isso em apenas uma linha!\nA fórmula para a agregação é sempre a mesma: groupby() e tipo de calculo (sum, count, mean, …). Por exemplo, no código abaixo, vamos agrupar também pela geração.\n\npokemons.groupby(['Generation', 'Type 1'])['Name'].count().reset_index(name='Pokemons')\n\n\n\n\n\n\n\n\nGeneration\nType 1\nPokemons\n\n\n\n\n0\n1.0\nBug\n12\n\n\n1\n1.0\nDragon\n3\n\n\n2\n1.0\nElectric\n9\n\n\n3\n1.0\nFairy\n2\n\n\n4\n1.0\nFighting\n7\n\n\n...\n...\n...\n...\n\n\n129\n8.0\nPoison\n4\n\n\n130\n8.0\nPsychic\n11\n\n\n131\n8.0\nRock\n4\n\n\n132\n8.0\nSteel\n5\n\n\n133\n8.0\nWater\n9\n\n\n\n\n134 rows × 3 columns\n\n\n\nE se quisermos saber a média de pontos de vida por geração de pokemon? Parece simples…\n\npokemons.groupby(['Generation'])['HP'].mean().reset_index(name='Average HP')\n\n\n\n\n\n\n\n\nGeneration\nAverage HP\n\n\n\n\n0\n1.0\n64.211921\n\n\n1\n2.0\n70.980000\n\n\n2\n3.0\n65.326087\n\n\n3\n4.0\n72.775862\n\n\n4\n5.0\n71.601227\n\n\n5\n6.0\n73.323308\n\n\n6\n7.0\n69.793103\n\n\n7\n8.0\n72.808696"
  },
  {
    "objectID": "posts/data-105/index.html#encerrando",
    "href": "posts/data-105/index.html#encerrando",
    "title": "[VDP] Aula 05 - Pandas",
    "section": "Encerrando",
    "text": "Encerrando\nNesta aula, conhecemos um pouco mais a respeito da biblioteca Pandas e como ela pode nos ajudar a carregar e analisar conjuntos de dados que podem ser utilizados em nossas visualizações, de forma simplificada e eficiente.\nDentro do processo de utilização de Pandas, aprendemos as executar as principais tarefas:\n\naprender sobre os metadados do conjunto de dados, utilizando: describe, info e shape\nlistar conteúdo com head, tail, sample e iterrows\nacessar células diretamente\nrealizar filtros em cima do DataFrame utilizando o método colunar, utilizando loc ou utilizando a função query\nagregar os dados para sumarizar a informação e facilitar a análise.\n\nSe você quiser saber mais sobre Pandas, eis aqui alguns links que podem ajudar:\n\nPandas - Documentação Oficial\nTutorial Pandas - W3 Schools\nTutorial Pandas - Kaggle\nVídeo sobre Pandas - Hashtag Treinamentos\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-107/index.html",
    "href": "posts/data-107/index.html",
    "title": "[VDP] Aula 07 - Linhas e Áreas",
    "section": "",
    "text": "Olá Cientista de Dados!\nNa última aula, começamos de maneira efetiva o nosso aprendizado da biblioteca seaborn, para a criação de gráficos utilizando a linguagem Python, e tecnologias interativas como o Google Colab.\nMais especificamente, aprendemos a criar gráficos de barras e suas variações como o gráfico de colunas, barras agrupadas ou até mesmo empilhadas (stacked). Esses gráficos correspondem com certeza à maior parte da nossa necessidade em termos de gráficos, mas ainda temos outra categoria que é muito importante: os gráficos de Linhas e Áreas.\n\n\nOs gráficos de Linhas e Áreas são utilizados quando precisamos representar a distribuição de métrica ao longo de um eixo de valores categóricos mas contínuos. O exemplo mais clássico é representar a distribuição de valores ao longo da dimensão do tempo. Mas também é possível utilizar qualquer outra dimensão numérica e contínua.\nEntão, estão preparados para mais uma dose de conhecimento?"
  },
  {
    "objectID": "posts/data-107/index.html#introdução",
    "href": "posts/data-107/index.html#introdução",
    "title": "[VDP] Aula 07 - Linhas e Áreas",
    "section": "",
    "text": "Olá Cientista de Dados!\nNa última aula, começamos de maneira efetiva o nosso aprendizado da biblioteca seaborn, para a criação de gráficos utilizando a linguagem Python, e tecnologias interativas como o Google Colab.\nMais especificamente, aprendemos a criar gráficos de barras e suas variações como o gráfico de colunas, barras agrupadas ou até mesmo empilhadas (stacked). Esses gráficos correspondem com certeza à maior parte da nossa necessidade em termos de gráficos, mas ainda temos outra categoria que é muito importante: os gráficos de Linhas e Áreas.\n\n\nOs gráficos de Linhas e Áreas são utilizados quando precisamos representar a distribuição de métrica ao longo de um eixo de valores categóricos mas contínuos. O exemplo mais clássico é representar a distribuição de valores ao longo da dimensão do tempo. Mas também é possível utilizar qualquer outra dimensão numérica e contínua.\nEntão, estão preparados para mais uma dose de conhecimento?"
  },
  {
    "objectID": "posts/data-107/index.html#preparação",
    "href": "posts/data-107/index.html#preparação",
    "title": "[VDP] Aula 07 - Linhas e Áreas",
    "section": "Preparação",
    "text": "Preparação\nA primeira coisa que iremos fazer no nosso notebook é carregar todas as bibliotecas que iremos utilizar e também o nosso conjunto de dados.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/data-107/index.html#utilização-básica",
    "href": "posts/data-107/index.html#utilização-básica",
    "title": "[VDP] Aula 07 - Linhas e Áreas",
    "section": "Utilização Básica",
    "text": "Utilização Básica\nA utilização básica aqui não é muito diferente do que fizemos para os gráficos de barra: temos uma função que deve poder gerar a visualização, através da passagem de alguns parâmetros básicos: fonte de dados, eixo X, Y, …\nNeste caso, a função em questão é a lineplot(). Vamos tentar?\n\nsns.lineplot(pokemons, x='Generation', y='Spe')\nplt.title('Variação de Velocidade de acordo com as Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Velocidade')\nplt.show()\n\n\n\n\n\n\n\n\nPadronização é uma maravilha, não é mesmo? Pegamos o nosso código para gráficos de barras e trocamos a função e tudo funcionou! Podemos perceber, no entanto, que a nossa linha representando está envolta por um delimitador azulado. Para resolver isso, vamos dar uma analisada nos parâmetros específicos da função lineplot().\nPor padrão, o gráfico de linhas também plota o que chamamos de error band, ou margem de erro. Se não for interessante, podemos eliminar essa error band.\n\nsns.lineplot(pokemons, x='Generation', y='Spe', errorbar=None)\nplt.title('Variação de Velocidade de acordo com as Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Velocidade')\nplt.show()\n\n\n\n\n\n\n\n\nE, assim como no gráfico de barras, temos a necessidade de plotar mais de uma série no nosso gráfico de linhas. Como fazemos isso? É simples:\n\npokemons_sb = pokemons[['Generation','Spa','Spd']] # Primeiro selecionamos apenas as colunas que queremos trabalhar\ntidy = pokemons_sb.melt(id_vars='Generation').rename(columns=str.title)\n\nsns.lineplot(tidy, x='Generation', y='Value', hue='Variable', errorbar=None)\nplt.title('Análise das Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Atributos')\nplt.show()\n\n\n\n\n\n\n\n\nBasicamente, tivemos que fazer a mesma operação que fizemos para as múltiplas barras. E o resto do código já é bem conhecido.\nO outro tipo de gráfico baseado em linhas é o popular gráfico de área. Mas somente conseguimos gerar esse gráfico utilizando a função stackplot() do MatplotLib. Veja o exemplo abaixo:\n\npokemons_gb = pokemons.groupby(['Generation'])[['Spa', 'Spd']].mean().reset_index()\n\nplt.stackplot(pokemons_gb['Generation'], pokemons_gb['Spa'], pokemons_gb['Spd'], labels=['Special Attack', 'Special Defense'])\nplt.title('Análise das Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Atributos')\nplt.show()\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico de área! Mais uma vez, recorremos a matplotlib para concluir a plotagem."
  },
  {
    "objectID": "posts/data-107/index.html#conclusão",
    "href": "posts/data-107/index.html#conclusão",
    "title": "[VDP] Aula 07 - Linhas e Áreas",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula, aprendemos a criar mais dois tipos de gráfico: linha e área, revisamos a utilização de pandas para transformar os dados e acrescentamos mais uma ferramenta no nosso cinto de utilidades.\nSe você quiser aprender mais sobre gráficos de linha e área em seaborn, seguem alguns links: - Documentação oficial do Seaborn em português: A documentação oficial do Seaborn tem uma versão em português que fornece uma visão geral da biblioteca, exemplos de uso, informações sobre os diferentes tipos de gráficos, e muito mais - Gráficos de Linha em Seaborn\nNa próxima aula, iremos explorar os gráficos de dispersão e pontos.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-109/index.html",
    "href": "posts/data-109/index.html",
    "title": "[VDP] Aula 09 - Seaborn - Tudo acaba em Pizza",
    "section": "",
    "text": "Olá Cientista de Dados!\nDentro da área de Visualização de Dados existe uma grande polêmica em relação a um tipo de gráfico: o gráfico de pizza ou torta. E a polêmica não é quanto ao nome, mas a quando devemos utilizar este tipo de gráfico.\nNesta aula, iremos aprender um pouco sobre essa polêmica e depois, vamos ver como podemos criar este gráfico usando as bibliotecas python seaborn, matplotlib e pandas!"
  },
  {
    "objectID": "posts/data-109/index.html#introdução",
    "href": "posts/data-109/index.html#introdução",
    "title": "[VDP] Aula 09 - Seaborn - Tudo acaba em Pizza",
    "section": "",
    "text": "Olá Cientista de Dados!\nDentro da área de Visualização de Dados existe uma grande polêmica em relação a um tipo de gráfico: o gráfico de pizza ou torta. E a polêmica não é quanto ao nome, mas a quando devemos utilizar este tipo de gráfico.\nNesta aula, iremos aprender um pouco sobre essa polêmica e depois, vamos ver como podemos criar este gráfico usando as bibliotecas python seaborn, matplotlib e pandas!"
  },
  {
    "objectID": "posts/data-109/index.html#definindo-gráfico-de-pizza-ou-será-torta",
    "href": "posts/data-109/index.html#definindo-gráfico-de-pizza-ou-será-torta",
    "title": "[VDP] Aula 09 - Seaborn - Tudo acaba em Pizza",
    "section": "Definindo Gráfico de Pizza… ou será Torta?",
    "text": "Definindo Gráfico de Pizza… ou será Torta?\nO gráfico de pizza (ou torta) é um gráfico que tem por objetivo representar as categorias ou dimensões como parte de um todo.\n\nExemplo\nConsidere o seguinte cenário: você realizou uma votação sobre qual sabor de pizza é o mais popular. Essa votação foi feita junto aos clientes da pizzaria onde você trabalha, durante o curso de 1 semana. Hoje haverá uma reunião com o dono da pizzaria, onde vocês discutirão quais são os sabores que entrarão na próxima grande promoção da loja. Para isso, você vai apresentar os resultados da votação. E (piada interna) você decidiu que nada melhor que usar um gráfico de pizza para esta tarefa!\n\n\n\nUm gráfico de pizza!\n\n\nComo vocês podem ver pela deliciosa imagem acima, o gráfico de pizza é composto por um círculo, que irá representar a totalidade dos votos que foram coletados. Então, cada sabor que foi votado irá representar uma fatia desta pizza. Se olharmos os valores representados no gráfico (que são porcentagens), conseguimos ter uma idéia do quanto cada fatia representa em relação ao todo.\nE, olhando essa imagem, você pode se perguntar: está tudo tão claro, onde está a polêmica? Para isso, vamos ver outra imagem:\n\n\n\nExemplo de Gráfico Ruim\n\n\nEsse gráfico, que visa demonstrar os tweeters mais ativos, representa o principal problema dos gráficos de pizza: quanto mais categorias você tem, menos cada uma representa do todo, deixando mais díficil para o público entender essa representação. A próxima imagem ilustra o outro problema que geralmente encontramos em gráficos de pizza:\n\nPor algum motivo estranho, gráficos de pizza também tem uma perspectiva diferente. E essa mudança de perspectiva torna ainda pior a capacidade do público de perceber a diferença entre cada ‘fatia’.\n\n\nCaracterísticas de uma boa Pizza (Gráfico de Pizza)\nEntão, devemos usar gráficos de pizza ou não? A resposta mais simples é - depende. Baseado em inúmeros especialistas da área de visualização, você pode usar gráficos de pizza quando tem poucas categorias para serem representados. Outra recomendação é evitar mostrar o gráfico em perspectiva, além de utilizar rótulos informativos e bem simples para cada fatia.\nEntão, antes de ver como montar esse tipo de gráfico, vamos ficar com uma imagem que reforça o aprendizado até aqui:"
  },
  {
    "objectID": "posts/data-109/index.html#utilização-básica",
    "href": "posts/data-109/index.html#utilização-básica",
    "title": "[VDP] Aula 09 - Seaborn - Tudo acaba em Pizza",
    "section": "Utilização básica",
    "text": "Utilização básica\nPara criar o gráfico de pizza teremos que abandonar um pouco o seaborn, e nos concentrarmos em utilizar apenas o matplotlib. Já estamos usando parte do matplotlib para colocarmos títulos no gráfico e nos eixos, acertarmos faixas de valores nos eixos e mais alguns detalhes. Agora, iremos utiliza-lo também para plotar o gráfico. Em primeiro lugar, vamos inicializar o ambiente e carregar os dados.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npokemons = pd.read_csv('pokemons.csv')\n\nDepois, fazemos a agregação dos dados no nível da categoria que vamos plotar. Para criarmos um gráfico de pizza bom, vamos plotar o número de pokemons por geração. Isso nos dará poucas categorias (8), e faz sentido ver a distribuição do número de pokemons. Se quiséssemos plotar qualquer outro atributo, como ataque, defesa, etc…, provavelmente um gráfico de pizza não seria indicado, pois não faz sentido representar a soma dos poderes de ataque dos pokemons como um todo.\n\npokemons['Generation Desc'] = pokemons['Generation'].apply(lambda gen: 'Gen ' + str(int(gen)))\n\npokemons_gen = pokemons.groupby(['Generation Desc'])[['Generation','Number']].count().reset_index()\npokemons_gen.sort_values('Generation Desc', inplace=True)\n\nplt.pie(pokemons_gen['Number'], labels=pokemons_gen['Generation Desc'], autopct=\"%.2f%%\", counterclock=False)\n\nplt.show()\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico de pizza! Importante observar que novamente, fizemos algumas transformações nos dados, incluindo ordenar os dados, porque caso contrário, as fatias ficarão fora de ordem. Vamos adicionar título e legenda, como em todos os nossos outros gráficos.\n\npokemons['Generation Desc'] = pokemons['Generation'].apply(lambda gen: 'Gen ' + str(int(gen)))\n\npokemons_gen = pokemons.groupby(['Generation Desc'])[['Generation','Number']].count().reset_index()\npokemons_gen.sort_values('Generation Desc', inplace=True)\n\nplt.pie(pokemons_gen['Number'], labels=pokemons_gen['Generation Desc'], autopct=\"%.2f%%\", counterclock=False)\n\nplt.title('Pokemons por Geração')\nplt.legend(loc='upper right', bbox_to_anchor=(1.40,1.02))\n\nplt.show()\n\n\n\n\n\n\n\n\nPronto, aí está o polêmico gráfico de pizza!\n\nConclusão\nNesta aula, aprendemos como criar gráficos que nos ajudam a entender como nossas variáveis categóricas se relacionam enquanto partes de um todo. E para isto utilizamos o tão famoso gráfico de Pizza. Também aprendemos em quais casos este tipo de gráfico faz sentido e quando sua utilização prejudica a compreensão dos dados. Se quiser saber mais sobre gráficos de pizza, clique aqui.\n\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-111/index.html",
    "href": "posts/data-111/index.html",
    "title": "[VDP] Aula 11 - Visualizando Mapas de Rede",
    "section": "",
    "text": "Olá Cientista de Dados!\nA partir desta aula, iremos explorar outras bibliotecas para aumentar o seu repertório de visualizações e também, praticar a manipulação de dados com pandas.\nNesta aula, vamos aprender a plotar um mapa de rede, ou network mapping."
  },
  {
    "objectID": "posts/data-111/index.html#introdução",
    "href": "posts/data-111/index.html#introdução",
    "title": "[VDP] Aula 11 - Visualizando Mapas de Rede",
    "section": "",
    "text": "Olá Cientista de Dados!\nA partir desta aula, iremos explorar outras bibliotecas para aumentar o seu repertório de visualizações e também, praticar a manipulação de dados com pandas.\nNesta aula, vamos aprender a plotar um mapa de rede, ou network mapping."
  },
  {
    "objectID": "posts/data-111/index.html#problema",
    "href": "posts/data-111/index.html#problema",
    "title": "[VDP] Aula 11 - Visualizando Mapas de Rede",
    "section": "Problema",
    "text": "Problema\nO gráfico chamado de mapa de rede ou network mapping tem o objetivo de demonstrar relacionamentos entre categorias dos nossos dados. A utilização mais comum é a de demonstrar como pessoas se conectam nas redes sociais. Também podemos utilizar em outras situações onde dois elementos tem algum tipo de relacionamento, como por exemplo, partidas de futebol. O nosso problema gira em torno dessa temática: queremos mostrar em um gráfico quais times tem um histórico de enfrentamento."
  },
  {
    "objectID": "posts/data-111/index.html#passo-a-passo",
    "href": "posts/data-111/index.html#passo-a-passo",
    "title": "[VDP] Aula 11 - Visualizando Mapas de Rede",
    "section": "Passo a Passo",
    "text": "Passo a Passo\n\nCarregando Bibliotecas\nComo sempre, iniciamos carregando nossas bibliotecas. Aqui, utilizaremos uma nova, chamada NetworkX e não carregamos a seaborn, que não será utilizada.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n\n\nCarregando dados\nDepois, carregamos nossos dados. Utilizaremos dados de confrontos de seleções no futebol.\n\n\ndf = pd.read_json('https://raw.githubusercontent.com/labeduc/datasets/main/worldcup/worldcup.json')\n\ndf.sample(5)\n\n\n\n\n\n\n\n\ndate\nhome_team\naway_team\nhome_team_continent\naway_team_continent\nhome_team_fifa_rank\naway_team_fifa_rank\nhome_team_total_fifa_points\naway_team_total_fifa_points\nhome_team_score\n...\nshoot_out\nhome_team_result\nhome_team_goalkeeper_score\naway_team_goalkeeper_score\nhome_team_mean_defense_score\nhome_team_mean_offense_score\nhome_team_mean_midfield_score\naway_team_mean_defense_score\naway_team_mean_offense_score\naway_team_mean_midfield_score\n\n\n\n\n16723\n2014-05-16 00:00:00+00:00\nKuwait\nKyrgyz Republic\nAsia\nAsia\n108\n146\n282\n147\n2\n...\nNo\nDraw\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n441\n1994-07-14 00:00:00+00:00\nJapan\nGhana\nAsia\nAfrica\n52\n26\n0\n0\n2\n...\nNo\nWin\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n10102\n2006-12-01 00:00:00+00:00\nEthiopia\nMalawi\nAfrica\nAfrica\n100\n94\n0\n0\n1\n...\nNo\nWin\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3309\n1998-09-28 00:00:00+00:00\nAustralia\nCook Islands\nOceania\nOceania\n36\n193\n0\n0\n16\n...\nNo\nWin\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n7353\n2003-09-26 00:00:00+00:00\nMalaysia\nIndonesia\nAsia\nAsia\n117\n92\n0\n0\n1\n...\nNo\nDraw\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 25 columns\n\n\n\n\n\nPlotando o gráfico\nAgora, vamos entender como um network mapping funciona. O network mapping precisa de duas coisas: - nodos: os elementos que queremos verificar o relacionamento. No nosso caso, serão os times - vertices: a conexão entre os elementos. No nosso caso são as partidas. Os vértices podem ou não ter um peso, o que pode refletir na largura do vértice, por exemplo. Vamos iniciar sem considerar o peso.\nEntão, nosso primeiro passo será organizar nossos dados nestas duas entidades: nodos e vertices.\n\n# Criando listas vazias para os nodos e para as conexões\nnodes = []\nedges = []\n\n# Popula a lista de nodos com base nos respondentes\nfor item in df[\"home_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Termina de popular a lista de nodos com os targets\nfor item in df[\"away_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Popula a lista de conexões com o respondente e o target\nfor idx, item in enumerate(df[\"home_team\"]):\n  edges.append([item, df[\"away_team\"][idx]])\n\nDepois disso, vamos a plotagem do gráfico. Basicamente, carregamos os nodos e vertices no objeto do gráfico e em seguida, plotamos.\n\n# Cria o objeto que representa o network map\nnet = nx.Graph()\n\n# Adiciona os nodos\nfor item in nodes:\n  net.add_node(item)\n\n# Adiciona as conexões\nfor item in edges:\n  net.add_edge(item[0], item[1], length=1000)\n\n# Cria um objeto para configurar a área de plotagem\npos = nx.spring_layout(net, seed=3068, k=0.8, iterations=50) \n\n# Ajustes de configuração para plotagem\noptions = {\n    \"font_size\": 12,\n    \"node_size\": 300,\n    \"node_color\": \"blue\",\n    \"edgecolors\": \"black\",\n    \"linewidths\": 2,\n    \"width\": 2,\n    \"with_labels\": True\n}\n\n# Plota o gráfico\nplt.rcParams[\"figure.figsize\"] = [12.00, 12.00]\nplt.rcParams[\"figure.autolayout\"] = True\nnx.draw(net, pos=pos, **options)\nplt.show()\n\n\n\n\n\n\n\n\nFicou um gráfico bem poluído, não? Uma das razões são os dados, que apresentam uma repetição, porque cada partida é uma linha. E se fizessemos um agrupamento, contando o número de partidas e eliminamos os confrontos que ocorreram menos de 5 vezes?\n\nsub_df = df[[\"home_team\", \"away_team\", \"home_team_score\"]].groupby([\"home_team\", \"away_team\"]).count().reset_index()\n\nsub_df\n\n\n\n\n\n\n\n\nhome_team\naway_team\nhome_team_score\n\n\n\n\n0\nAfghanistan\nBangladesh\n2\n\n\n1\nAfghanistan\nBhutan\n3\n\n\n2\nAfghanistan\nCambodia\n3\n\n\n3\nAfghanistan\nChinese Taipei\n1\n\n\n4\nAfghanistan\nIndia\n1\n\n\n...\n...\n...\n...\n\n\n9006\nZimbabwe\nTanzania\n4\n\n\n9007\nZimbabwe\nTogo\n1\n\n\n9008\nZimbabwe\nTunisia\n1\n\n\n9009\nZimbabwe\nUganda\n3\n\n\n9010\nZimbabwe\nZambia\n14\n\n\n\n\n9011 rows × 3 columns\n\n\n\nAgora, vamos tentar novamente.\n\n# Criando listas vazias para os nodos e para as conexões\nnodes = []\nedges = []\n\n# Popula a lista de nodos com base nos respondentes\nfor item in sub_df[\"home_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Termina de popular a lista de nodos com os targets\nfor item in sub_df[\"away_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Popula a lista de conexões com o respondente e o target\nfor idx, item in enumerate(sub_df[\"home_team\"]):\n  if sub_df[\"home_team_score\"][idx] &gt; 5:\n    edges.append([item, sub_df[\"away_team\"][idx]])\n\n\n# Cria o objeto que representa o network map\nnet = nx.Graph()\n\nlist_valid_nodes = []\n\n# Adiciona as conexões\nfor item in edges:\n  # se a partida foi listada aqui, \n  # adiciona na lista de nodos válidos\n  if item[0] not in list_valid_nodes:\n    list_valid_nodes.append(item[0])\n  if item[1] not in list_valid_nodes:\n    list_valid_nodes.append(item[1])\n  net.add_edge(item[0], item[1], length=1000)\n\n# Adiciona os nodos\nfor item in nodes:\n  # adiciona um nodo somente se está \n  # na lista de nodos válidos\n  if item in list_valid_nodes:\n    net.add_node(item)\n\n# Cria um objeto para configurar a área de plotagem\npos = nx.spring_layout(net, seed=3068, k=0.8, iterations=50) \n\n# Ajustes de configuração para plotagem\noptions = {\n    \"font_size\": 12,\n    \"node_size\": 300,\n    \"node_color\": \"blue\",\n    \"edgecolors\": \"black\",\n    \"linewidths\": 2,\n    \"width\": 2,\n    \"with_labels\": True\n}\n\n# Plota o gráfico\nplt.rcParams[\"figure.figsize\"] = [12.00, 12.00]\nplt.rcParams[\"figure.autolayout\"] = True\nnx.draw(net, pos=pos, **options)\nplt.show()\n\n/Users/wpcortes/Work/blog/venv/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\nAinda temos muitos dados para mostrar. Então, quem sabe filtramos apenas os confrontos do Brasil, para termos algo mais simples de visualizar? Também vamos introduzir modificações no peso das conexões (número de confrontos) e no tamanho do nodo do Brazil, para diferenciar o nodo inicial.\n\nbrazil_df = sub_df.query(\"home_team == 'Brazil' or away_team == 'Brazil'\").reset_index()\n\nbrazil_df\n\n\n\n\n\n\n\n\nindex\nhome_team\naway_team\nhome_team_score\n\n\n\n\n0\n81\nAlgeria\nBrazil\n1\n\n\n1\n152\nAndorra\nBrazil\n1\n\n\n2\n287\nArgentina\nBrazil\n15\n\n\n3\n400\nAustralia\nBrazil\n3\n\n\n4\n465\nAustria\nBrazil\n2\n\n\n...\n...\n...\n...\n...\n\n\n118\n8591\nUnited Arab Emirates\nBrazil\n1\n\n\n119\n8654\nUruguay\nBrazil\n9\n\n\n120\n8746\nVenezuela\nBrazil\n5\n\n\n121\n8825\nWales\nBrazil\n2\n\n\n122\n8970\nZimbabwe\nBrazil\n1\n\n\n\n\n123 rows × 4 columns\n\n\n\n\n# Criando listas vazias para os nodos e para as conexões\nnodes = []\nedges = []\n\n# Popula a lista de nodos com base nos times da casa\nfor item in brazil_df[\"home_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Termina de popular a lista de nodos com os times visitantes\nfor item in brazil_df[\"away_team\"]:\n  if item not in nodes:\n    nodes.append(item)\n\n# Popula a lista de conexões com os confrontos do Brasil \n# que ocorreram mais de cinco vezes\nfor idx, item in enumerate(brazil_df[\"home_team\"]):\n  if brazil_df['home_team_score'][idx] &gt; 5:\n    edges.append([item, brazil_df[\"away_team\"][idx], brazil_df[\"home_team_score\"][idx]])\n\n\n# Cria o objeto que representa o network map\nnet = nx.Graph()\n\nlist_valid_nodes = []\n\n# Adiciona as conexões\nfor item in edges:\n  # se a partida foi listada aqui, \n  # adiciona na lista de nodos válidos\n  if item[0] not in list_valid_nodes:\n    list_valid_nodes.append(item[0])\n  if item[1] not in list_valid_nodes:\n    list_valid_nodes.append(item[1])\n  net.add_edge(item[0], item[1], length=1000, weight=item[2])\n\n# Adiciona os nodos\nfor item in nodes:\n  # adiciona um nodo somente se está \n  # na lista de nodos válidos\n  if item in list_valid_nodes:\n    # adicionamos uma formula para controlar o tamanho dos nodos.\n    net.add_node(item, size=(2000 if item == 'Brazil' else 900))\n\n# Cria um objeto para configurar a área de plotagem\npos = nx.spring_layout(net, seed=3068, k=0.8, iterations=50) \n\n# Cria o array dos pesos de cada conexão\nwedges = net.edges()\nweights = [net[u][v]['weight'] for u,v in wedges]\n\n# Cria o array de tamanhos de cada nodo\nnodes = net.nodes()\nsizes = [nodes[u]['size'] for u in nodes]\n\n# Ajustes de configuração para plotagem\noptions = {\n    \"font_size\": 12,\n    \"node_size\": sizes, # usa o array de tamanhos\n    \"node_color\": \"blue\",\n    \"edgecolors\": \"black\",\n    \"width\": weights, # usa o array de pesos\n    \"with_labels\": True\n}\n\n# Plota o gráfico\nplt.rcParams[\"figure.figsize\"] = [12.00, 12.00]\nplt.rcParams[\"figure.autolayout\"] = True\nnx.draw(net,pos, **options)\nplt.show()\n\n/Users/wpcortes/Work/blog/venv/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  fig.canvas.print_figure(bytes_io, **kw)"
  },
  {
    "objectID": "posts/data-111/index.html#conclusão",
    "href": "posts/data-111/index.html#conclusão",
    "title": "[VDP] Aula 11 - Visualizando Mapas de Rede",
    "section": "Conclusão",
    "text": "Conclusão\nConseguimos fazer a plotagem do nosso gráfico e, se investirmos um pouco mais de tempo, é possível deixa-lo com uma melhor apresentação. Algumas considerações: - este tipo de gráfico é mais adequado para permitir a interação do usuário, através de filtros, destaque de caminhos, etc. Neste caso, você acabará usando outras bibliotecas (plotly em python) ou até outra linguagem (javascript e sua biblioteca d3.js são bem populares); - Quando pensamos no layout de distribuição dos nodos, existem vários que você pode tentar, dê uma olhada na documentação - Pensando na utilização do gráfico estático, as recomendações de um gráfico de pizza também se aplicam para este gráfico.\nA documentação da biblioteca NetworkX pode ser encontrada aqui.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-113/index.html",
    "href": "posts/data-113/index.html",
    "title": "[VDP] Aula 13 - Visualizando Wordclouds",
    "section": "",
    "text": "Olá Cientista de Dados!\nNesta aula, vamos explorar uma técnica para analisar variáveis qualitativas."
  },
  {
    "objectID": "posts/data-113/index.html#introdução",
    "href": "posts/data-113/index.html#introdução",
    "title": "[VDP] Aula 13 - Visualizando Wordclouds",
    "section": "",
    "text": "Olá Cientista de Dados!\nNesta aula, vamos explorar uma técnica para analisar variáveis qualitativas."
  },
  {
    "objectID": "posts/data-113/index.html#problema",
    "href": "posts/data-113/index.html#problema",
    "title": "[VDP] Aula 13 - Visualizando Wordclouds",
    "section": "Problema",
    "text": "Problema\nFoi solicitado que você faça uma análise comparativa dos pokemons baseados em seu poder de ataque. Naturalmente, pensamos que um simples gráfico de barras ou colunas pode resolver essa situação, mas com o grande número de pokemons que temos (˜1000) o gráfico ficaria muito extenso. Então, como mostrar essa comparação?\nEntra aí a word cloud, ou nuvem de palavras. A nuvem de palavras vai mostrar palavras com tamanho variável, geralmente de acordo com a frequência da ocorrência da palavra no corpo de texto. Então, vamos considerar que o nosso corpo de texto é a lista de nomes de pokemon, e o poder ataque indica a frequência de cada um. Se formatado corretamente, podemos utilizar e garantimos que todos os pokemons aparecerão em uma tela.\nMas o seaborn faz isso? Não, teremos que introduzir mais uma biblioteca, desta vez chamada wordcloud. No código abaixo, acompanhe o passo a passo para gerar a word cloud."
  },
  {
    "objectID": "posts/data-113/index.html#passo-a-passo",
    "href": "posts/data-113/index.html#passo-a-passo",
    "title": "[VDP] Aula 13 - Visualizando Wordclouds",
    "section": "Passo a Passo",
    "text": "Passo a Passo\nVamos compor nossa solução, pedaço por pedaço. Como sempre, o primeiro passo é carregar nossas bibliotecas. Como a biblioteca wordcloud é nova, antes precisamos instala-la. Isso é feito com o seguinte comando:\n$ pip install wordcloud\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# Biblioteca wordcloud - No google colab ela já está disponível. \n# Se for usar em seu computador, instale antes com o seguinte comando:\n# pip install wordcloud\nfrom wordcloud import STOPWORDS, ImageColorGenerator, WordCloud\n\nAgora, vamos a configuração.\n\n# Definindo a nossa paleta de cores - vamos utilizar nossas próprias cores\ncores = [\"#0c4f6a\", \"#177498\", \"#0a8faa\", \"#bfdce5\", \"#82bd4a\", \"#b8d67a\",\n         \"#b2b3b6\", \"#58585a\", \"#edb634\", \"#d97933\", \"#f1bdb1\", \"#eca091\",\n         \"#e26c54\", \"#b0391e\"]\n\n# Tamanho da Imagem\n# Este tamanho é em polegadas\n# O primeiro valor é Largura e o segundo, Altura\nplt.rcParams[\"figure.figsize\"]=(12,12)\n\n# Resolução da Imagem\n# 300 dpi é o padrão mínimo para impressão\n# Aqui vamos usar um pouco menos\nplt.rcParams[\"figure.dpi\"] = 300\nplt.rcParams[\"savefig.dpi\"] = 300\nplt.rcParams[\"savefig.format\"] = \"svg\"\n\n# Removendo Bordas em torno do gráfico\nplt.rcParams[\"axes.spines.right\"] = False\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.bottom\"] = False\nplt.rcParams[\"axes.spines.left\"] = False\n\n# Carregando a paleta de cores\nsns.set_palette(sns.color_palette(cores))\n\nA próxima etapa é carregar os dados.\n\n# carregando os dados da internet\ndf = pd.read_csv('https://github.com/labeduc/datasets/blob/main/pokemons/all.csv?raw=true')\n\ndf.sample(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n730\n631\nHeatmor\nFire\nNaN\n['Flash Fire', 'Gluttony', 'White Smoke']\n85\n97\n66\n105\n66\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n0.5\n0.5\n1.4\n58.0\n29.6\n\n\n13\n10\nCaterpie\nBug\nNaN\n['Run Away', 'Shield Dust']\n45\n30\n35\n20\n20\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.3\n2.9\n32.2\n\n\n1027\n896\nGlastrier\nIce\nNaN\n['Chilling Neigh']\n100\n145\n130\n65\n110\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n2.0\n1.0\n2.2\n800.0\n165.3\n\n\n412\n347\nAnorith\nRock\nBug\n['Battle Armor', 'Swift Swim']\n45\n95\n50\n40\n50\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n2.0\n1.0\n0.7\n12.5\n25.5\n\n\n889\n766\nPassimian\nFighting\nNaN\n['Defiant', 'Receiver']\n100\n120\n90\n40\n60\n...\n0.5\n0.5\n1.0\n1.0\n0.5\n1.0\n2.0\n2.0\n82.8\n20.7\n\n\n\n\n5 rows × 44 columns\n\n\n\nE o último passo antes de plotar o gráfico é transformar os dados. A transformação que iremos fazer é a seguinte: para cada pokemon, temos o poder de ataque. Esta biblioteca wordcloud funciona de dois modos: podemos gerar a imagem a partir de um texto, e ele fará a quebra, removerá stopwords, e calculará a frequencia, ou passamos para ele um dicionário de frequências. Vamos optar por este último, por fazer mais sentido com os dados que temos.\n\nlista = {}\nfor idx, row in df.iterrows():\n  lista[row['Name']] = row['Att']\n\nE finalmente, chamamos a biblioteca e fazemos a plotagem com o auxilio da matplotlib.\n\nwordcloud = WordCloud(max_font_size=50, max_words=df.size, background_color=\"white\").generate_from_frequencies(lista)\nplt.figure()\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\nQue gráfico interessante, não? Mostra muito mais pokemons do que um gráfico de barras mostraria, e deixa bem claro quais pokemons são mais poderosos, pelo menos no que diz respeito ao ataque.\nAntes de encerrar, mais um truque da biblioteca wordcloud: fazer a plotagem do gráfico seguindo o formato de uma imagem.\n\nimport numpy as np\nfrom PIL import Image\n\nmask = np.array(Image.open(\"squirtle.jpg\"))\nwordcloud = WordCloud(max_font_size=50, max_words=df.size, background_color=\"white\", mask=mask).generate_from_frequencies(lista)\nplt.figure()\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\nAgora sim, uma wordcloud de respeito!"
  },
  {
    "objectID": "posts/data-113/index.html#conclusão",
    "href": "posts/data-113/index.html#conclusão",
    "title": "[VDP] Aula 13 - Visualizando Wordclouds",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula aprendemos a plotar mais um tipo de gráfico, utilizando uma nova biblioteca. Se quiser mais detalhes sobre a biblioteca wordcloud, clique aqui.\nEsta também é nossa última aula falando de gráficos e bibliotecas que podemos utilizar. Nas próximas aulas, iremos explorar novamente a biblioteca pandas e também aprofundar nosso conhecimento na biblioteca plotly.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/data-115/index.html",
    "href": "posts/data-115/index.html",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "",
    "text": "Olá Cientista de Dados!\nEsta é nossa última aula, e para encerrar vamos conhecer uma biblioteca que nos permitirá criar gráficos esteticamente refinados e interativos.\nA biblioteca se chama Plotly, e vamos aprender a criar todos os gráficos que criamos com seaborn agora utilizando Plotly!"
  },
  {
    "objectID": "posts/data-115/index.html#introdução",
    "href": "posts/data-115/index.html#introdução",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "",
    "text": "Olá Cientista de Dados!\nEsta é nossa última aula, e para encerrar vamos conhecer uma biblioteca que nos permitirá criar gráficos esteticamente refinados e interativos.\nA biblioteca se chama Plotly, e vamos aprender a criar todos os gráficos que criamos com seaborn agora utilizando Plotly!"
  },
  {
    "objectID": "posts/data-115/index.html#preparando-o-ambiente",
    "href": "posts/data-115/index.html#preparando-o-ambiente",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "Preparando o ambiente",
    "text": "Preparando o ambiente\nAqui, como sempre, vamos carregar as bibliotecas que iremos utilizar no nosso notebook.\n\nimport pandas as pd\nimport plotly.express as px\nimport duckdb\n\n%reload_ext sql\n\nVamos utilizar o duckdb em memória caso seja necessário fazer alguma transformação rápida.\n\n%sql duckdb:///:memory:"
  },
  {
    "objectID": "posts/data-115/index.html#carregando-os-dados",
    "href": "posts/data-115/index.html#carregando-os-dados",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\npokemons = pd.read_csv('https://github.com/labeduc/datasets/blob/main/pokemons/all.csv?raw=true')\n\npokemons.sample(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n829\n716\nXerneas\nFairy\nNaN\n['Fairy Aura']\n126\n131\n95\n131\n98\n...\n0.5\n1.0\n1.0\n0.0\n0.5\n2.0\n1.0\n3.0\n215.0\n23.9\n\n\n104\n80\nSlowbro\nWater\nPsychic\n['Oblivious', 'Own Tempo', 'Regenerator']\n95\n75\n110\n100\n80\n...\n2.0\n1.0\n2.0\n1.0\n2.0\n0.5\n1.0\n1.6\n78.5\n30.7\n\n\n141\n109\nKoffing\nPoison\nNaN\n['Levitate', 'Neutralizing Gas', 'Stench']\n40\n65\n95\n60\n45\n...\n0.5\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.6\n1.0\n2.8\n\n\n38\n28\nAlolan Sandslash\nIce\nSteel\n['Slush Rush', 'Snow Cloak']\n75\n100\n120\n25\n65\n...\n0.5\n1.0\n1.0\n0.5\n1.0\n1.0\n0.5\n1.2\n55.0\n38.2\n\n\n758\n653\nFennekin\nFire\nNaN\n['Blaze', 'Magician']\n40\n45\n40\n62\n60\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n0.5\n0.5\n0.4\n9.4\n58.8\n\n\n\n\n5 rows × 44 columns"
  },
  {
    "objectID": "posts/data-115/index.html#tipos-de-gráficos",
    "href": "posts/data-115/index.html#tipos-de-gráficos",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "Tipos de Gráficos",
    "text": "Tipos de Gráficos\nO Plotly tem diversos tipos de gráficos, exatamente como o Seaborn, e iremos ver aqui os tipos mais básicos, assim como vimos com o seaborn nas aulas anteriores. Também já iremos apresentar desde o início os gráficos com as boas práticas devidamente aplicadas, para gerar uma melhor experiência para o público.\n\nBarra/Colunas\nE lá vamos nós, começando pelo gráfico mais popular de todos, o gráfico de barra/coluna. A princípio, precisamos apenas 2 comandos: o comando que gera o gráfico e armazena em um objeto do tipo Figure; e o comando que plota a figura gerada.\n\n# gera a figura chamando a função bar()\n# o primeiro parâmetro é o DataFrame e os seguintes \n# são as colunas do DataFrame que serão os eixos X e Y.\nfig = px.bar(pokemons, x='Generation', y='Att')\n\n# função para plotar a imagem\nfig.show(renderer='notebook')\n\n                                                \n\n\nEstá aí nosso gráfico, mas ele parece estar com um problema: essa aparência riscada. Por que isso aconteceu? Se passarmos o mouse por cima de uma das barras, veremos que na verdade, ela registra cada um dos valores de ataque dos pokemons, ou seja, ele não está calculando a média dos valores, como seria esperado.\nE como resolvemos isso? De duas maneiras: 1) fazemos a transformação dos dados, com um group by 2) modificamos o tipo de gráfico.\nNesta aula, vamos resolver com a solução 1 - transformar os dados.\n\n%sql pokemons_gb &lt;&lt; select Generation, AVG(Att) as AvgAttack from pokemons group by Generation order by Generation\n\n*  duckdb:///:memory:\nDone.\n\n\n\n# gera a figura chamando a função bar()\n# o primeiro parâmetro é o DataFrame e os seguintes \n# são as colunas do DataFrame que serão os eixos X e Y.\nfig = px.bar(pokemons_gb, x='Generation', y='AvgAttack')\n\n# função para plotar a imagem\nfig.show(renderer='notebook')\n\n                                                \n\n\nEstá aí nosso gráfico, agora com cada barra representando a média do poder de ataque de cada geração. Para transformar em barras horizontais, basta trocar o eixo X com o Y, além de adicionar o parâmetro de orientação.\n\n# gera a figura chamando a função bar()\n# o primeiro parâmetro é o DataFrame e os seguintes \n# são as colunas do DataFrame que serão os eixos X e Y.\nfig = px.bar(pokemons_gb, y='Generation', x='AvgAttack', orientation='h')\n\n# função para plotar a imagem\nfig.show(renderer='notebook')\n\n                                                \n\n\nUma característica do Plotly que é interessante é que ele ocupa toda a largura disponível na tela para plotar o gráfico, e apenas o necessário do ponto de vista de altura. Isto significa que a aparência dos gráficos precisa ser tratada para gerar resultados mais refinados. No seaborn, tinha diversos parâmetros que precisavamos acertar na plotagem do gráfico. Na última seção, veremos o mesmo para o Plotly.\n\n\nLinha/Área\nE vamos ao gráfico de linha! Esse mesmo conjunto de dados nos permite plotar um gráfico neste estilo.\n\nfig = px.line(pokemons_gb, x=\"Generation\", y=\"AvgAttack\")\n\nfig.show(renderer='notebook')\n\n                                                \n\n\nPara criar um gráfico de área, basta trocar a função.\n\nfig = px.area(pokemons_gb, x=\"Generation\", y=\"AvgAttack\")\n\nfig.show(renderer='notebook')\n\n                                                \n\n\nE para os olhos mais treinados, vocês devem ter percebido que o formato do gráfico de linha e do gráfico de área não estão exatamente iguais, o que seria o esperado. O que aconteceu aqui foi uma mudança da escala no eixo do Y, gerando uma discrepância no posicionamento de cada ponto da linha. Por isso conhecer como configurar os gráficos será muito importante.\n\n\nDispersão/Pontos\nEste gráfico, que nos permite entender a correlação entre variáveis (até 3, se considerarmos o tamanho), também pode ser criado de forma bem simples. Lembrando que também temos um caso especial de gráfico de dispersão, que é o Quadrante Mágico do Gartner. Este será visto quando falarmos sobre configuração dos gráficos do Plotly.\n\nfig = px.scatter(pokemons, x=\"Att\", y=\"Def\", color=\"Type 1\",\n                 size='HP')\nfig.show(renderer='notebook')\n\n                                                \n\n\n\n\nPizza\nE por último, o gráfico que todos amam odiar! Quando estávamos aprendendo seaborn, esse gráfico é o que mais exigia a utilização da MatplotLib e o código era um pouco mais extenso. Aqui, a biblioteca Plotly mantém a simplicidade:\n\nfig = px.pie(pokemons_gb, values='AvgAttack', names='Generation')\n\nfig.show(renderer='notebook')\n\n                                                \n\n\nE o Plotly também torna mais simples criar uma variação do gráfico de pizza, conhecido como Donut!\n\nfig = px.pie(pokemons_gb, values='AvgAttack', names='Generation', hole=0.45)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "posts/data-115/index.html#conclusão",
    "href": "posts/data-115/index.html#conclusão",
    "title": "[VDP] Aula 15 - Gráficos Interativos",
    "section": "Conclusão",
    "text": "Conclusão\nE assim, encerramos a parte básica desta aula. Aprendemos como criar os principais tipos de gráficos usando a biblioteca Plotly.\nAprendemos também que a Plotly permite a criação de gráficos interativos, além de ter uma melhor resolução para apresentar os gráficos. Na última aula do nosso curso, iremos abordar a configuração dos gráficos.\nSe você quiser aprender mais sobre Plotly, o link da documentação é este aqui.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html",
    "href": "posts/p0002-pandasai/index.html",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#introdução",
    "href": "posts/p0002-pandasai/index.html#introdução",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "href": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "E o que isso tem a ver com Ciências de Dados?",
    "text": "E o que isso tem a ver com Ciências de Dados?\nOs DataFrames são basicamente textos organizados em tabelas e colunas, que são correlacionados. Portanto, é possível carregar os dados em um modelo LLM (Large Language Model), habilitando a extração da informação destes DataFrames de maneira conversacional, como se estivéssemos dialogando. Mas o que realmente instiga esta nossa área é descobrir se podemos fazer este modelo realizar o trabalho de análise para nós, cientistas e analistas iniciantes (e até mesmo os mais experientes). A resposta mais recente que temos para isso é chamada de Pandas AI."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "href": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que é o Pandas AI?",
    "text": "O que é o Pandas AI?\n\n\n\nPandas e Llamas\n\n\nO Pandas AI é o melhor amigo do seu DataFrame! Com esta nova biblioteca, podemos dar aos nossos DataFrames a capacidade de serem consultados de maneira simples e eficiente, utilizando uma interface conversacional.\nEntão, vamos ver como podemos utilizar Pandas AI?\n\nPreparando o Ambiente\nA primeira coisa é garantir que seu ambiente tenha todas as bibliotecas necessárias instaladas: Pandas, PandasAI, OpenAI.\n$ pip install pandas pandasai openai\nEntão, vamos iniciar o nosso notebook. Temos que fazer o import das bibliotecas que vamos utilizar na nossa demonstração.\n\nimport os\nimport pandas as pd\n\nfrom pandasai import PandasAI\nfrom pandasai.llm.openai import OpenAI\nfrom dotenv import load_dotenv\n\nObserve que carregamos a função load_dotenv, pois iremos precisar carregar a chave de acesso para a API da OpenAI. Para fazer isso, podemos simplesmente executar a função.\n\nload_dotenv()\n\nTrue\n\n\nO próximo passo é carregar os nossos dados no DataFrame. Como sempre, vamos utilizar o dataset de pokemons.\n\npokemons = pd.read_csv('pokemons.csv')\n\nEm seguida, vamos inicializar o LLM para que consigamos conversar com o nosso DataFrame.\n\nllm = OpenAI(api_token=os.environ['OPENAI_API_KEY'])\npandas_ai = PandasAI(llm)\n\nAté agora, tudo correu bem! Agora, podemos executar diversas vezes a função pandas_ai.run, passando nosso DataFrame e um prompt, e ele nos responderá. Vamos testar?\n\npandas_ai.run(pokemons, prompt=\"Quantos pokemons temos no DataFrame?\")\n\n'Unfortunately, I was not able to answer your question. Please try again. If the problem persists, try rephrasing your question.'\n\n\nPara verificar isso, podemos apenas ver o shape do DataFrame e confirmar:\n\npokemons.shape\n\n(1032, 44)\n\n\nDe fato, 1032 pokemons. Vamos continuar?\n\npandas_ai.run(pokemons, prompt=\"Quantos tipos de pokemons existem?\")\n\n'Well, there are actually 18 different types of pokemons out there!'\n\n\nVamos conferir?\n\ntipos = pd.concat([pokemons['Type 1'], pokemons['Type 2']]).unique().tolist()\n\n\nprint(len(tipos))\nprint(tipos)\n\n19\n['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Dark', 'Poison', 'Electric', 'Ground', 'Ice', 'Fairy', 'Steel', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Dragon', 'Flying', nan]\n\n\nParece que funciona mesmo! Note que o nosso vetor tem 19 posições porque está contando o nulo como um valor. Vamos nos aprofundar mais um pouco…\n\npandas_ai.run(pokemons, prompt='Liste os tipos com as quantidades de pokemons')\n\n'Existem diversos tipos de pokemons e suas quantidades variam. O tipo mais comum é o Normal, com 114 pokemons, seguido pelo tipo Água, com 131. Já o tipo Voador é o menos comum, com apenas 8 pokemons. Além disso, existem outros tipos como Fogo, Grama, Elétrico, Psíquico, entre outros, cada um com sua quantidade específica de pokemons. No total, existem mais de 800 espécies diferentes de pokemons.'\n\n\nEle respondeu, mas não exatamente como queríamos - observe que ele listou alguns tipos apenas com suas quantidades. Vamos tentar melhorar, aplicando um pouco de prompt engineering (ou seja, escrever nossa solicitação de forma mais explícita).\n\npandas_ai.run(pokemons, prompt=\"Crie uma tabela que tem duas colunas: tipo de pokemon e quantidade. Liste todos os tipos possíveis e suas quantidades.\")\n\n'Para responder à pergunta, criei uma tabela com duas colunas: tipo de pokemon e quantidade. Nessa tabela, listei todos os tipos possíveis de pokemon e suas respectivas quantidades. Por exemplo, há 81 pokemons do tipo Bug, 46 do tipo Dark, 42 do tipo Dragon, e assim por diante. No total, foram listados 18 tipos diferentes de pokemon e suas quantidades correspondentes.'\n\n\nHumm, ainda não conseguimos listar todos os tipos. Vamos explicar um pouco mais?\n\npandas_ai.run(pokemons, prompt=\"Gerar uma listagem completa da quantidade de pokemons por tipo, em formato markdown.\")\n\n'Para saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo: \\n\\n| Type | Count |\\n|------|-------|\\n| Bug | 81 |\\n| Dark | 46 |\\n| Dragon | 42 |\\n| Electric | 59 |\\n| Fairy | 22 |\\n| Fighting | 42 |\\n| Fire | 64 |\\n| Flying | 8 |\\n| Ghost | 41 |\\n| Grass | 91 |\\n| Ground | 41 |\\n| Ice | 38 |\\n| Normal | 114 |\\n| Poison | 40 |\\n| Psychic | 77 |\\n| Rock | 59 |\\n| Steel | 36 |\\n| Water | 131 |\\n\\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.'\n\n\nOpa,agora foi. Mas como o notebook não formata markdown no output, precisamos fazer um copia e cola do resultado.\nPara saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo:\n\n\n\nType\nCount\n\n\n\n\nBug\n81\n\n\nDark\n46\n\n\nDragon\n42\n\n\nElectric\n59\n\n\nFairy\n22\n\n\nFighting\n42\n\n\nFire\n64\n\n\nFlying\n8\n\n\nGhost\n41\n\n\nGrass\n91\n\n\nGround\n41\n\n\nIce\n38\n\n\nNormal\n114\n\n\nPoison\n40\n\n\nPsychic\n77\n\n\nRock\n59\n\n\nSteel\n36\n\n\nWater\n131\n\n\n\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.’"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "href": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vamos complicar um pouco?",
    "text": "Vamos complicar um pouco?\nNas primeiras perguntas, utilizamos perguntas que pedem respostas quase que diretas das métricas que temos no DataFrame. Contamos o número de pokemons, contamos valores distinto de tipos, agrupamos a contagem por tipos. Mas será que o Pandas AI pode fazer uma análise comparativa simples, tal como analisar uma métrica e retornar o insight solicitado?\n\npandas_ai.run(pokemons, prompt=\"Qual o pokemon mais pesado?\")\n\n'Bem, o pokemon mais pesado é o Snorlax, ele pode chegar a pesar mais de 460 quilos!'\n\n\nOpa, e não é que respondeu? Mas, sem precipitação, vamos conferir: vamos executar uma query em pandas que filtra os pokemons com peso &gt;= ao do Snorlax.\n\npokemons[[\"Name\",\"Weight\"]].sort_values(\"Weight\").query(\"Weight &gt; 459\")\n\n\n\n\n\n\n\n\nName\nWeight\n\n\n\n\n925\nDusk Mane Necrozma\n460.0\n\n\n181\nSnorlax\n460.0\n\n\n837\nHoopa Unbound\n490.0\n\n\n826\nAvalugg\n505.0\n\n\n1001\nStonjourner\n520.0\n\n\n445\nMetagross\n550.0\n\n\n833\nZygarde Complete\n610.0\n\n\n578\nGiratina-Origin\n650.0\n\n\n1007\nCopperajah\n650.0\n\n\n573\nDialga\n683.0\n\n\n254\nMega Steelix\n740.0\n\n\n577\nGiratina\n750.0\n\n\n1019\nZamazenta Crowned Shield\n785.0\n\n\n1027\nGlastrier\n800.0\n\n\n936\nMelmetal\n800.0\n\n\n1030\nCalyrex Ice Rider\n809.1\n\n\n932\nStakataka\n820.0\n\n\n923\nGuzzlord\n888.0\n\n\n873\nMudsdale\n920.0\n\n\n446\nMega Metagross\n942.9\n\n\n1020\nEternatus\n950.0\n\n\n456\nGroudon\n950.0\n\n\n457\nPrimal Groudon\n999.7\n\n\n914\nCosmoem\n999.9\n\n\n921\nCelesteela\n999.9\n\n\n\n\n\n\n\nOps, algo deu errado. Temos vários pokemons mais pesados. Será que ele não analisou todos os pokemons antes de responder? Quem sabe um problema nos dados? Vamos perguntar algo mais direto.\n\npandas_ai.run(pokemons, prompt=\"O pokemon Dialga é mais ou menos pesado que o Snorlax?\")\n\n'Well, it turns out that Snorlax is actually heavier than Dialga.'\n\n\nIsso certamente deve ser um problema. Ele passou a responder em inglês, como se tivesse perdido o contexto. Vamos perguntar de maneira diferente…\n\npandas_ai.run(pokemons, prompt=\"Porque o pokemon Dialga é mais pesado que o Snorlax?\")\n\n'Well, actually, Snorlax weighs more than Dialga.'\n\n\nÉ, ele realmente tem uma implicância com o Snorlax… Caso você não tenha lido nada a respeito do ChatGPT e LLMs em geral, esse tipo de erro é chamado de “alucinação” que ocorre quando o modelo produz resultados incorretos, correlacionando informações de maneira espúria."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "href": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Usando outras funcionalidades do Pandas via conversação",
    "text": "Usando outras funcionalidades do Pandas via conversação\nAgora vamos testar se o pandasAI consegue entender instruções para plotar gráficos. Isso é um DataFrame pandas, correto? Será que eu posso plotar um countplot() por geração?\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de colunas totalizando pokemons por geração.\")\n\n\n\n\n\n\n\n\n'Claro! Vou plotar um gráfico de colunas que mostra a quantidade total de pokemons por geração.'\n\n\nParece que funcionou bem! Vamos tentar mais um?\n\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de pizza totalizando pokemons pelo campo lendário.\")\n\n\n\n\n\n\n\n\n'Sure, I can help you with that! To plot a pie chart showing the total number of legendary Pokémon, we need to gather the data first. Once we have the numbers, we can create a visual representation of the data using a pie chart. Would you like me to proceed with the task?'"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "href": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que aprendemos até aqui",
    "text": "O que aprendemos até aqui\nA biblioteca Pandas AI é uma biblioteca interessante, que nos permite “dialogar”com nossos DataFrames, extraindo informações do mesmo. Através de nossos exemplos, podemos verificar que quase tudo que podemos descobrir através de consultas normais pandas, podemos perguntar ao DataFrame através do Pandas AI.\n\nMas nem tudo são flores…\nApesar dos acertos, observamos que a biblioteca Pandas AI não é imune aos problemas comuns das LLM, e mesmo com uma base de conhecimento mais limitada, é acometida de alucinações. A biblioteca também sofre de um problema de performance: uma resposta que em pandas leva um segundo ou menos para ser mostrada, como podemos ver, pode levar até mais de 1 minuto usando PandasAI.\nPor último, podemos perceber que a biblioteca ainda precisa um pouco mais de trabalho até mesmo em sua usabilidade - notamos que a mesma passa a responder em inglês quando a resposta está errada, deixando o usuário confuso."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "href": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vale a pena utilizar?",
    "text": "Vale a pena utilizar?\nSe você quer fazer explorações simples dos dados, parece ser uma boa idéia utilizar o PandasAI, visto que é mais fácil perguntar em português ou inglês do que lembrar a sintaxe de todos os comandos Pandas que você teria que fazer para isso. No entanto, é preciso tomar muito cuidado com os resultados, que podem estar errados, mas são comunicados com convicção.\nÉ, com certeza, mais uma ferramenta no seu cinto de utilidades de cientista de dados, e como toda ferramenta, devemos conhece-la bem antes de usar. Explore mais, entenda suas limitações e faça o melhor uso possivel!\nAté mais!!!\nWalter."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html",
    "href": "posts/p0004-classif-texto/index.html",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#introdução",
    "href": "posts/p0004-classif-texto/index.html#introdução",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "href": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Classificação de Dados",
    "text": "Classificação de Dados\nClassificação de dados é uma tarefa de aprendizado supervisionado que envolve a categorização de uma determinada amostra de dados em uma das várias classes predefinidas. Cada amostra é atribuída a uma e somente uma classe, baseando-se nas características dessa amostra.\nPor exemplo, imagine que você tem um conjunto de emails e você quer classificá-los como “spam” ou “não spam”. Nesse caso, “spam” e “não spam” são as classes, e cada email é uma amostra que será classificada em uma dessas classes.\nA classificação é geralmente realizada utilizando algoritmos de aprendizado de máquina. Esses algoritmos aprendem a classificar novas amostras baseando-se em um conjunto de treinamento. O conjunto de treinamento é um conjunto de amostras para as quais as classes verdadeiras são conhecidas.\nOs algoritmos de classificação incluem árvores de decisão, regressão logística, máquinas de vetores de suporte, redes neurais e muitos outros. A escolha do algoritmo depende de vários fatores, como a natureza dos dados, o número de classes, a necessidade de interpretabilidade e outros.\n\nMas e se não temos conjuntos de dados de treinamento?\nSe você não tem um conjunto de dados de treinamento rotulado, ainda existem várias abordagens que você pode usar, tais como:\n\nAprendizado não supervisionado\nAprendizado semi-supervisionado\nAprendizado por reforço\nRotulagem manual\nGeração de rótulos sintéticos\nProcessamento de Linguagem Natural\n\nE é nesta última opção que podemos utilizar o GPT para nos ajudar, pois o modelo do GPT é gigantesco, tendo sido treinado com conteúdo de toda a internet.\n\n\nGPT versus métodos mais tradicionais de classificação\nOs modelos de linguagem como o GPT (Generative Pretrained Transformer) têm várias vantagens e desvantagens, especialmente quando comparados a outros métodos de análise de texto. Aqui estão algumas delas:\nVantagens:\n\nCompreensão Profunda da Linguagem: O GPT é treinado em enormes quantidades de texto, o que lhe permite aprender uma rica compreensão da linguagem natural. Isso inclui uma compreensão de sintaxe, semântica, e até mesmo alguns elementos de conhecimento do mundo real.\nVersatilidade: O GPT pode ser usado para uma ampla gama de tarefas de processamento de linguagem natural, incluindo tradução de texto, geração de texto, resumo de texto, análise de sentimento, resposta a perguntas e muito mais.\nAprendizado Transferível: O GPT utiliza o aprendizado transferível, o que significa que o conhecimento aprendido durante o treinamento em um grande conjunto de dados pode ser aplicado a tarefas específicas com relativamente poucos dados de treinamento adicionais. Isso permite ao GPT se adaptar a uma ampla gama de tarefas com um desempenho impressionante.\nModelagem de Contexto: A arquitetura do Transformer, utilizada pelo GPT, é especialmente boa para entender o contexto em uma sequência de texto, o que é crucial para muitas tarefas de processamento de linguagem natural.\n\nDesvantagens:\n\nNecessidade de Grandes Quantidades de Dados de Treinamento: O GPT precisa de grandes quantidades de dados de treinamento para aprender efetivamente. Isso pode tornar o treinamento do modelo do zero proibitivamente caro em termos de tempo e recursos computacionais.\nDificuldade de Interpretação: O GPT, como muitos modelos de aprendizado profundo, pode ser difícil de interpretar. Ele pode produzir resultados impressionantes, mas pode ser difícil entender por que fez uma determinada previsão.\nSensibilidade ao Ruído e Erros: Embora o GPT seja robusto em muitos aspectos, ele pode ser sensível a ruído e erros no texto de entrada. Pequenas mudanças no texto de entrada podem às vezes levar a grandes mudanças nas previsões do modelo.\nPotencial de Viés: O GPT aprende com os dados em que é treinado, e se esses dados contêm viés, o modelo também pode exibir viés. Isso pode ser um problema significativo quando o modelo é usado em contextos sensíveis."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "href": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Ok, o GPT é legal e tudo o mais… Mas e daí?",
    "text": "Ok, o GPT é legal e tudo o mais… Mas e daí?\nE daí que, graças ao modelo GPT, podemos ter um classificador de texto super calibrado para nos ajudar em nossas tarefas, sem o ônus de treinar tal modelo. E podemos utilizar o GPT a partir da API da OpenAI, de maneira muito simples! Outra vantagem que vale ressaltar é que, ao contrário de modelos tradicionais de classificação, podemos atribuir múltiplas categorias ao nosso texto.\nVamos ver um exemplo?"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "href": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Organizando um catálogo de artigos",
    "text": "Organizando um catálogo de artigos\nImagine o seguinte cenário: temos uma lista de todos os artigos que salvamos no site Medium. O problema desta lista é que o Medium não oferece nenhum tipo de categorização dos artigos. A única maneira de fazer isso é separando em várias listas, o que dificulta principalmente o processo de busca dos artigos. Além, é claro, de pressupor a classificação antes de ler o artigo.\nEssa tarefa realmente não é trivial, e seria muito útil poder fazer isso de forma automatizada. E o primeiro problema que temos é que nossa lista tem apenas o título e a url dos artigos. Para que a classificação seja mais precisa, precisamos de pelo menos algum texto que nos ajude a ter mais contexto a respeito do artigo.\nEntão, vamos criar o nosso script classificador? Esse script vai executar as seguintes tarefas:\n\n\n\n\n\nflowchart LR\n  A[Carregar Lista de Arquivos] --&gt; B\n  B[Buscar Título e Resumo&lt;br&gt;dos Artigos] --&gt; C\n  C[Classificar Artigos] --&gt; D[Salvar Lista de Artigos]\n\n\n\n\n\n\n\nInicializando o ambiente\nVamos utilizar as seguintes bibliotecas: - beautifulsoup4 - biblioteca para extrair a informação do HTML que contém a lista de artigos - openai - biblioteca para utilizar a API da openAI - requests - bibliotea para buscar informações da internet\n\nimport os\nimport openai\nimport bs4\nimport json\n\nfrom dotenv import load_dotenv\nfrom requests_html import HTMLSession # importando o objeto de sessão do html requests\n\nA próxima etapa é carregar variáveis de ambiente. Lembrando que é necessário ter uma API key para usar a API da OpenAI.\n\nload_dotenv()\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nAgora, precisamos carregar nossa lista de artigos, que está em um arquivo HTML, que podemos baixar lá no site do Medium. Vamos criar uma função, de forma que poderemos re-utilizar essa parte da rotina sempre que for necessário.\n\ndef retorna_lista(nomearquivo: str):\n  html_artigos = bs4.BeautifulSoup(open(nomearquivo, \"r\"))\n  list_artigos = html_artigos.find_all(\"li\")\n\n  artigos = []\n  for item in list_artigos:\n    record = {}\n    record = {\n        \"titulo\": item.a.text,\n        \"link\": item.a[\"href\"],\n        \"autores\": None,\n        \"resumo\": None,\n        \"categorias\": None\n    }\n    artigos.append(record)\n  return artigos\n\nEste código define uma função chamada “retorna_lista” que recebe um único parâmetro chamado “nomearquivo” do tipo string. A função primeiro abre o arquivo especificado pela string “nomearquivo” usando a função “open”, lê o conteúdo e usa o método “find_all” do Beautiful Soup para procurar todos os elementos de lista no documento HTML e armazená-los na variável “list_artigos”. A função, então, inicializa uma lista vazia chamada “artigos”. Em um loop, ela itera sobre cada item da lista na variável “list_artigos” e cria um dicionário chamado “record” com três chaves: “titulo”, “link”, “autores”, “resumo” e “categorias”. Os valores para “titulo” e “link” são extraídos do texto da tag “a” e do atributo “href”, respectivamente. O valor das chaves “autores”, “resumo” e “categorias” são uma string vazia. O dicionário “record” completo é então adicionado à lista “artigos”. Depois que todos os itens da lista são processados, a função retorna a lista “artigos”.\nEntão, podemos utilizar essa função conforme abaixo:\n\nartigos = retorna_lista(\"reading-list-medium.html\")\n\nprint(f\" Número de Artigos: {len(artigos)}.\")\n\n Número de Artigos: 1865.\n\n\nVamos ver como ficou um registro:\n\nprint(json.dumps(artigos[0], indent=4))\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": null,\n    \"resumo\": null,\n    \"categorias\": null\n}\n\n\nPerfeito! Estamos com os artigos preparados para buscarmos os dados extra que nos darão mais contexto para a categorização.\nPara fazer isso, vamos utilizar a biblioteca requests-html. Novamente, criaremos uma função para reutilizar depois.\n\ndef retorna_campos(registro: dict):\n    # Declaramos variaveis que contem seletores HTML\n    # Esses seletores nos ajudarão a encontrar os elementos HTML que contém o \n    # conteúdo referente ao autor, data publicação, titulo e lead\n    seletor_autor = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(1) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\"\n    ]\n    seletor_titulo_lead = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2)\", \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2)\"\n    ]\n  \n    # Inicializamos o objeto HTMLSession para fazer a coleta da informação dos artigos\n    request = HTMLSession()\n    try:\n      print(registro[\"link\"])\n      conteudo_html = request.get(registro[\"link\"])\n      autor = \"Not available\"\n      \n      for item in seletor_autor:\n        aux_autor = None\n        aux_autor = conteudo_html.html.find(item, first=True)\n        if aux_autor is not None:\n          autor = aux_autor\n          break\n\n      head = \"Not available\"\n      for item in seletor_titulo_lead:\n        aux_head = None\n        aux_head = conteudo_html.html.find(item, first=True)\n        if aux_head:\n          aux_lead = aux_head.find('h2', first=True)\n          if aux_lead is not None:\n            head = aux_lead.text\n          \n      registro[\"autores\"] = autor.text\n      registro[\"resumo\"] = head\n        \n      return registro\n    except:\n      print('URL {0} com erro. Verifique.'.format(registro[\"link\"]))\n      return None\n\nA função retorna_campos faz o scraping de dados de páginas da web, especificamente páginas de notícias ou artigos de blog do Medium. Ele pega um dicionário de “registro” como entrada, que parece conter um “link” para uma página da web.\nPasso-a-Passo:\n\nVariáveis seletor_autor e seletor_titulo_lead são listas de seletores CSS. Seletores CSS são padrões usados para selecionar os elementos que você deseja estilizar. Aqui, eles são usados para identificar os elementos HTML onde as informações de autor e título/lead estão localizadas no HTML da página.\nA função então inicia uma sessão HTML usando o módulo HTMLSession() do pacote requests_html, que é uma biblioteca Python para fazer solicitações HTTP e para parsing de HTML.\nA função tenta fazer uma solicitação GET para a URL que está no campo “link” do dicionário de entrada.\nEm seguida, a função tenta encontrar o autor do artigo. Para isso, itera sobre a lista seletor_autor e, para cada seletor, tenta encontrar um elemento correspondente na página HTML. Se encontrar um autor, interrompe o loop e guarda o autor encontrado.\nDepois disso, a função tenta encontrar o título do artigo da mesma maneira, usando a lista seletor_titulo_lead.\nOs resultados são então adicionados ao dicionário de entrada no campo “autores” para o autor e “resumo” para o título.\nSe houver algum erro durante o processo, como um link quebrado ou se o seletor CSS não corresponder a nenhum elemento, a função exibe uma mensagem de erro e retorna None.\nSe tudo correr bem, a função retorna o dicionário de entrada, agora com informações adicionais sobre o autor e o resumo do artigo.\n\nAgora vamos a execução da função para cada artigo em nossa lista. Observe que colocamos um limitador para fazer isso para 10 registros.\n\nartigos_comp = []\ni = 0\nfor item in artigos:\n    artigos_comp.append(retorna_campos(item))\n    i += 1\n    if i == 10:\n        break\n\nhttps://medium.com/p/e323b2d24987\nhttps://medium.com/p/9e9536ebd839\nhttps://medium.com/p/bb7d31ed2e76\nhttps://medium.com/p/2688e319e2a5\nhttps://medium.com/p/7edae42a20b3\nhttps://medium.com/p/f87419cb14cb\nhttps://medium.com/p/d6169fc81204\nhttps://medium.com/p/74361bc3b92e\nhttps://medium.com/p/9dc1566d960d\nhttps://medium.com/p/3c053357c47f\n\n\nAgora temos os nossos artigos com título, autor e uma lead line, que vai nos ajudar no processo da categorização.\nVamos agora, a nossa rotina de categorização, usando a API do OpenAI.\n\ndef retorna_categorias(titulo, resumo):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=f\"We have these categories: dbt, Python, DataViz, Tableau, PowerBI, and Generative AI. Given those categories, please classify the following text with those categories: {titulo} - {resumo}. You can use only the categories listed. You can classify with multiple categories. If you think that none of the categories applies, you can tag as Other.\",\n        temperature=0.8,\n        max_tokens=20,\n    )\n    return response.choices[0].text.strip()\n\nEste código define uma função chamada “retorna_categorias” que recebe dois parâmetros: “titulo” e “resumo”. A função utiliza a API OpenAI para classificar o título e o resumo com base em um conjunto de categorias previamente determinadas - dbt, Python, DataViz, Tableau, PowerBI e Generative AI. Em seguida, retorna o resultado da classificação como uma string.\nA função retorna então a primeira (e única) escolha da resposta da API OpenAI, que é a string que representa a categoria que foi escolhida como a melhor correspondência para o texto de entrada. O método strip() é usado para remover qualquer espaço em branco inicial ou final da string retornada.\nObservação: Para usar este código, o módulo openai precisa ser importado e uma chave de API OpenAI precisa ser obtida.\n\nlista_final = []\nfor item in artigos_comp:\n  item[\"categorias\"] = retorna_categorias(item['titulo'], item['resumo'])\n  lista_final.append(item)\n\nAgora que executamos a rotina acima, podemos imprimir os três primeiros registros e verificar que agora, temos categorias.\n\nfor idx, item in enumerate(lista_final):\n    print(json.dumps(item, indent=4))\n    if idx == 2:\n        break\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": \"John Loewen\",\n    \"resumo\": \"I\\u2019ve done the prompt engineering research so you don\\u2019t have to\",\n    \"categorias\": \"Python, Generative AI\"\n}\n{\n    \"titulo\": \"Power BI: How I Started Using Python To Automate Tasks\",\n    \"link\": \"https://medium.com/p/9e9536ebd839\",\n    \"autores\": \"Gabe Araujo, M.Sc.\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"PowerBI, Python\"\n}\n{\n    \"titulo\": \"Chat with your databases using LangChain\",\n    \"link\": \"https://medium.com/p/bb7d31ed2e76\",\n    \"autores\": \"Vishnu Sivan\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"Other\"\n}\n\n\nE aí estão os nossos artigos, devidamente categorizados. Inclusive, podemos ver um artigo que foi classificado como “Other”, indicando que o texto que foi enviado não foi suficiente para classificar com as categorias selecionadas.\nObrigado por ler até aqui! Espero que este script seja útil para vocês!!!"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#links-úteis",
    "href": "posts/p0004-classif-texto/index.html#links-úteis",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Links Úteis",
    "text": "Links Úteis\n\nUnderstanding GPT-3: OpenAI’s Language Generation AI: Blog oficial da OpenAI sobre GPT-3 - Apresenta uma explicação detalhada do GPT-3 e seu uso potencial\nData Classification in Machine Learning - Este é um artigo do site GeeksforGeeks que explica o conceito básico de classificação de dados em aprendizado de máquina, os diferentes tipos de algoritmos de classificação e como eles funcionam.\nBibliotecas Python utilizadas no artigo:\n\nrequests-html\nopenai\nBeautifulSoup4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WV Code - Educação e Consultoria",
    "section": "",
    "text": "Todos os posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI\n\n\n\n\n\n\nOpenAI API\n\n\n\nVamos utilizar a API da OpenAI para executar uma das tarefas mais comuns em NLP - a classificação de textos.\n\n\n\n\n\nJun 16, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPower BI no Jupyter!\n\n\n\n\n\n\nPandas\n\n\nPower BI\n\n\nJupyter\n\n\n\nUse o Power BI para plotar gráficos no seu Jupyter Notebook.\n\n\n\n\n\nMay 30, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPandas AI - Converse com seu DataFrame\n\n\n\n\n\n\nCiência de Dados\n\n\nPandas\n\n\nAI\n\n\nGPT\n\n\n\nNova biblioteca se propõe a permitir que você “converse” com o seu DataFrame.\n\n\n\n\n\nMay 29, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 16 - Criando Visualizações Efetivas\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nPlotly\n\n\n\nMelhorando nossas visualizações!\n\n\n\n\n\nFeb 18, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 15 - Gráficos Interativos\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nPlotly\n\n\n\nPrecisa de Interatividade? Plotly é a solução!\n\n\n\n\n\nFeb 17, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 14 - Pandas e Bancos de Dados\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nBancos de Dados\n\n\n\nMaximizando o volume de dados para processar\n\n\n\n\n\nFeb 16, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 13 - Visualizando Wordclouds\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nWordcloud\n\n\n\nExtraindo significado de variáveis de texto\n\n\n\n\n\nFeb 15, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 12 - Visualizando Sankey Charts\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSankey Chart\n\n\n\nMostrando relação entre duas variáveis categóricas\n\n\n\n\n\nFeb 14, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 11 - Visualizando Mapas de Rede\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nNetwork Mapping\n\n\n\nDemonstrando relacionamento entre elementos dos dados\n\n\n\n\n\nFeb 13, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 10 - Seaborn - Melhorando seus Visuais\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\nMatPlotLib\n\n\nBoas Práticas\n\n\n\nCriando gráficos com aparência profissional e que são eficientes ao comunicar resultados\n\n\n\n\n\nFeb 12, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 09 - Seaborn - Tudo acaba em Pizza\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nMatPlotLib\n\n\nGráfico de Pizza\n\n\n\nUtilizando o Gráfico mais Polêmico da Área de Visualização de Dados\n\n\n\n\n\nFeb 11, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 08 - Dispersão e Quadrantes\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\nGráfico de Dispersão\n\n\nQuadrante Mágico\n\n\n\nDistribuição e Correlação entre Variáveis\n\n\n\n\n\nFeb 10, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 07 - Linhas e Áreas\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\nMatPlotLib\n\n\nGráfico de Linhas\n\n\nGráfico de Áreas\n\n\n\nAnálise em dimensão contínua\n\n\n\n\n\nFeb 9, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 06 - Iniciando com Seaborn\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nMatPlotLib\n\n\nSeaborn\n\n\nGráfico de Barras\n\n\nGráfico de Colunas\n\n\n\nApresentando os Gráficos de Barras!\n\n\n\n\n\nFeb 8, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 05 - Pandas\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\n\nPreparando dados como gente grande!\n\n\n\n\n\nFeb 7, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 04 - Prática Aulas 2 e 3\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nNotebooks\n\n\nJupyter\n\n\nPrática\n\n\n\nConsolidando o Aprendizado das Aulas 2 e 3\n\n\n\n\n\nFeb 6, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] Aula 03 - Formatos de Dados\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nDados\n\n\nFormato Longo\n\n\nFormato Largo\n\n\n\nComo o dado precisa ser estruturado para que possamos visualizar de maneira correta?\n\n\n\n\n\nFeb 5, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nAula 02 - Google Colab\n\n\n\n\n\n\nVisualização\n\n\nNotebooks\n\n\nJupyter\n\n\n\nConhecendo nossa ferramenta de trabalho…\n\n\n\n\n\nFeb 4, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nAula 01 - Teoria de Visualização de Dados\n\n\n\n\n\n\nVisualização\n\n\nTeoria\n\n\nCiência de Dados\n\n\n\nUm pouco de teoria antes de iniciar…\n\n\n\n\n\nFeb 3, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] - Introdução\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\n\nEntenda como o curso irá funcionar!\n\n\n\n\n\nFeb 2, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nVisualização de Dados com Python - Sumário\n\n\n\n\n\n\nCursos\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\n\nAcompanhe o curso por aqui.\n\n\n\n\n\nFeb 1, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data-100/index.html",
    "href": "posts/data-100/index.html",
    "title": "Visualização de Dados com Python - Sumário",
    "section": "",
    "text": "Aqui temos o sumário do curso, todas as aulas podem ser acessadas a partir daqui.\n\nIntrodução\n\nTópicos abordados no curso\nMetodologia\nLeia mais…\n\n\n\nAula 01 - Teoria de Visualização de Dados\n\nO Fluxo de Trabalho da Ciência de Dados\nO que é Visualização de Dados\nTipos de Visualização de Dados\nTipos de Visualização X Objetivo de Comunicação\nComo podemos criar Visualizações\nLeia mais…\n\n\n\nAula 02 - Google Colab\n\nO que é o Google Colab\nAcessando\nAprendendo a carregar os dados no Google Colab\nInspecionando os dados\n\nListas\nDicionário de Dados\n\nLeia mais…\n\n\n\nAula 03 - Formato de Dados\n\nFontes de dados e seus formatos\n\nFormato Tabular\n\nOtimizando o Formato Tabular\nDataFrames e Series\nLeia mais…\n\n\n\nAula 04 - Consolidando o Aprendizado das aulas 2 e 3\n\nCriando um notebook no Google Colab\nCarregando Dados de CSV\nTransformando do formato Largo para o Longo\nUsando bibliotecas externas para facilitar o trabalho\nLeia mais…\n\n\n\nAula 05 - Pandas\n\nIntrodução\nInstalando\nCarregando os Dados\nInspecionando os Dados\nFiltrando os Dados\nAgregando os Dados\nLeia mais…\n\n\n\nAula 06 - Seaborn - Primeiros Passos\n\nIntrodução\nInstalação\nUtilização Básica\nLeia mais…\n\n\n\nAula 07 - Seaborn - Linhas e Áreas\n\nIntrodução\nPreparação\nUtilização Básica\nLeia mais…\n\n\n\nAula 08 - Seaborn - Dispersão e Pontos\n\nIntrodução\nPreparação\nUtilização Básica\nLeia mais…\n\n\n\nAula 09 - Seaborn - Tudo acaba em Pizza\n\nIntrodução\nPreparação\nUtilização Básica\nLeia mais…\n\n\n\nAula 10 - Seaborn - Melhorando seus Visuais\n\nIntrodução\nProblema\nPasso a Passo\nConclusão\nLeia mais…\n\n\n\nAula 11 - Visualizando Mapas de Rede\n\nIntrodução\nProblema\nPasso a Passo\nConclusão\nLeia mais…\n\n\n\nAula 12 - Visualizando Sankey Charts\n\nIntrodução\nProblema\nPasso a Passo\nConclusão\nLeia mais…\n\n\n\nAula 13 - Visualizando Wordclouds\n\nIntrodução\nProblema\nPasso a Passo\nConclusão\nLeia mais…\n\n\n\nAula 14 - Pandas e Bancos de Dados\n\nIntrodução\nProblema\nPasso a Passo\nConclusão\nLeia mais…\n\n\n\nAula 15 - Precisa de Interatividade? Plotly é a solução!\n\nIntrodução\nPreparando o ambiente\nCarregando os dados\nTipos de Gráficos\n\nBarra/Colunas\nLinha/Área\nDispersão/Pontos\nPizza\n\nConclusão\nLeia mais…\n\n\n\nAula 16 - Criando Visualizações Efetivas\n\nIntrodução\nPreparando o ambiente\nCarregando os dados\nGerando um Gráfico de Barras\nEscolhendo o Tipo de Gráfico\nAdicionando Título\nAjustando Legenda\nAjustando Eixos\nAdicionando Labels\nConclusão\nLeia mais…"
  },
  {
    "objectID": "vanessa.html",
    "href": "vanessa.html",
    "title": "Vanessa S.M. Paixão-Côrtes",
    "section": "",
    "text": "Vanessa é professora, manda muito bem.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2019\nMestrado em Ciência da Computação - 2015\n\nURI - Santo Ângelo\n\nBacharelado em Sistemas de Informação - 2013\nLicenciatura em Ciências Biológicas - 2004\n\n\n\n\nCertificados\nN/A\n\n\nExperiência\n\nTrybe\n\nPessoa Especialista - 2021 - 2022\n\nCESUCA\n\nProfessora - 2020 - 2021\n\nUFSCPA\n\nProfessora - 2020 - 2021"
  }
]