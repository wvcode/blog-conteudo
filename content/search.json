[
  {
    "objectID": "walter.html",
    "href": "walter.html",
    "title": "Walter R. Paixão-Côrtes",
    "section": "",
    "text": "Walter é um profissional da área de TI com mais de 25 anos de experiência. Atualmente, trabalha como Product Line Manager na Dell Technologies e atua como Engenheiro Analista de Dados em projetos independentes.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2020\nMestrado em Ciência da Computação - 2015\nBacharelado em Ciência da Computação - 2002\n\nCTI - FURG\n\nTecnólogo em Processamento de Dados - 1993\n\n\n\n\nCertificados\n\nAnalista de Requisitos, IIBA - 2016\nScrum Master, ScrumAlliance, 2017\n\n\n\nExperiência\n\nDell Technologies\n\nProduct Line Manager - 2022 - …\nProduct Designer - 2019 - 2022\nPrincipal Soft. Engineer - 2017 - 2019\nLead Senior Software Engineer - 2008 - 2017\nLead Software Engineer - 2005 - 2008\n\nAccenture\n\nConsultor - 2003 - 2005\n\nBankorp Consultores Associados\n\nConsultor - 2001 - 2003\n\nBinário Internet\n\nLead Software Engineer - 1999 - 2001\n\nCSI - Consultoria e Sistemas de Informação\n\nSoftware Engineer - 1996 - 1999\n\nOutras Empresas\n\nEstagiário/Programador - 1993 - 1996"
  },
  {
    "objectID": "posts/data-010/index.html",
    "href": "posts/data-010/index.html",
    "title": "[VDP] - Introdução",
    "section": "",
    "text": "Olá Devs!!!\nA série de Visualização de Dados com Python tem por objetivo habilita-los a utilizar a linguagem Python para:\n\nrealizar análises de dados em grandes volumes e nos mais diferentes formatos\ncriar gráficos que transmitam a informação de maneira agradável e direta\naprender sobre tipos de visualização de dados que vão além dos gráficos de barras, linhas e tortas.\n\nAo longo dos posts você irá aprender a utilizar algumas das bibliotecas Python mais famosas na área de Ciência de Dados: Requests, Pandas, Seaborn, MatplotLib, Plotly e muito mais.\nEntão, não perca mais tempo e comece a leitura agora mesmo!\n\nAVISO!!!\nEssa série de posts é destinada a um público menos experiente, que ainda está aprendendo a programar em Python, bem como aqueles que estão iniciando seu caminho na área de Ciência de Dados. Se você já domina a linguagem, os artigos fora da série de Visualização de Dados com certeza serão mais interessantes!\nUm abraço, Walter."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre o Blog",
    "section": "",
    "text": "O WV Code é um blog de tecnologia criado por dois profissionais da área: Vanessa S.M. Paixão Côrtes e Walter R. Paixão Côrtes. Este blog tem por objetivo realizar a divulgação de conteúdo tecnológico de forma gratuita e em bom Português, tornando o vasto conteúdo de nossa área mais acessível para aqueles que estão iniciando na área e ainda não dominam o Inglês, bem como para quem ainda não consegue pagar por conteúdo on-line. Além de aprender com nossas publicações interativas, você pode ter acesso aos nossos repositórios de código no github.\n \n  \n   \n  \n    \n     Github\n  \n\n\n\n\nQuem faz o Blog?\n\nVanessa S.M. Paixão-Côrtes\nWalter R. Paixão-Côrtes"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html",
    "href": "posts/p0003-powerbiclient/index.html",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#introdução",
    "href": "posts/p0003-powerbiclient/index.html#introdução",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "href": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "title": "Power BI no Jupyter!",
    "section": "PowerBI - Rápida Introdução",
    "text": "PowerBI - Rápida Introdução\nO Power BI é uma poderosa ferramenta de business intelligence desenvolvida pela Microsoft, projetada para ajudar as empresas a visualizar e analisar seus dados de maneira intuitiva e interativa. Com recursos avançados de criação de relatórios, painéis e dashboards personalizados, o Power BI permite que os usuários transformem seus dados em informações acionáveis, facilitando a tomada de decisões informadas em tempo real. E todo esse poder pode ser entregue tanto de forma independente quanto integrada a outros meios, através do que chamamos de embedded reports.\n\nPower BI Embeddings\nAs capacidades de embedding do Power BI permitem que os desenvolvedores incorporem relatórios, painéis e visualizações interativas do Power BI diretamente em seus aplicativos, sites ou portais. Essa funcionalidade de integração oferece uma maneira flexível e personalizada de compartilhar informações e insights com usuários finais, proporcionando uma experiência perfeita e integrada. Com as capacidades de embedding do Power BI, os desenvolvedores podem aproveitar as APIs e SDKs disponíveis para incorporar visualizações interativas em seus aplicativos existentes, personalizar a aparência e a funcionalidade, controlar a segurança e permissões de acesso aos dados e até mesmo habilitar recursos como filtragem dinâmica e interação com os dados subjacentes. Essa flexibilidade permite que as organizações integrem as poderosas capacidades analíticas do Power BI diretamente em seus fluxos de trabalho, fornecendo aos usuários acesso direto a informações relevantes e atualizadas, tudo dentro do contexto de sua própria aplicação.\nEntre outros conhecimentos, para trabalhar com embeddings, é necessário compreender:\n\nLinguagens de programação: Ter conhecimentos básicos de programação é fundamental para interagir com as APIs e SDKs do Power BI. Python, JavaScript e .NET são exemplos de linguagens comumente usadas.\nDesenvolvimento web: Familiaridade com desenvolvimento web é importante para incorporar e personalizar visualizações do Power BI. Isso inclui conhecimentos em HTML, CSS e JavaScript para integrar o código do Power BI em aplicativos e sites.\nAutenticação e segurança: Compreender os conceitos de autenticação e autorização é crucial para garantir a segurança dos dados. Isso envolve entender como autenticar usuários no Power BI e definir permissões de acesso adequadas.\nPower BI Desktop e serviço Power BI: Ter conhecimento sobre o Power BI Desktop e o serviço Power BI é essencial. Isso inclui habilidades em criação de relatórios, painéis e visualizações interativas, além de recursos de filtragem e interação.\nModelagem e transformação de dados: Noções básicas de modelagem e transformação de dados são úteis para preparar os dados antes de incorporá-los. Isso envolve limpeza, filtragem e organização dos dados para criar visualizações eficazes.\n\nNeste post, exploraremos a integração do Power BI com o Jupyter Notebook, combinando a flexibilidade do ambiente de codificação do Python com a riqueza de recursos do Power BI. Descobriremos como utilizar a biblioteca powerbiclient para trazer o poder do Power BI para dentro de um Jupyter Notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "href": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "title": "Power BI no Jupyter!",
    "section": "Biblioteca powerbiclient",
    "text": "Biblioteca powerbiclient\nA biblioteca powerbiclient é uma ferramenta poderosa que permite interagir com o serviço do Power BI diretamente por meio de APIs. Essa biblioteca, desenvolvida pela Microsoft, fornece uma interface de programação fácil de usar para criar, publicar, atualizar e gerenciar relatórios, dashboards e conjuntos de dados no Power BI. Com o powerbiclient, os desenvolvedores podem automatizar tarefas, extrair informações e integrar o Power BI a aplicativos, permitindo a criação de soluções personalizadas e aprimorando a capacidade de visualização e análise de dados. Essa biblioteca é uma excelente opção para aqueles que desejam aproveitar ao máximo o ecossistema do Power BI e incorporar suas funcionalidades em seus próprios fluxos de trabalho e aplicativos.\nDentre todas as possibilidades que esta biblioteca oferece, vamos focar em como carregar gráficos interativos em Power BI dentro do nosso notebook Jupyter. E vamos lá, sem demora!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "href": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "title": "Power BI no Jupyter!",
    "section": "Preparando o ambiente",
    "text": "Preparando o ambiente\nComo sempre, o nosso primeiro passo é instalar as bibliotecas que estão faltando.\n$ pip install powerbiclient\n\nNosso próximo passo é inicializar o ambiente, chamando nossas bibliotecas.\n\n::: {#cell-11 .cell execution_count=4}\n``` {.python .cell-code}\nfrom powerbiclient import QuickVisualize, get_dataset_config, Report\nfrom powerbiclient.authentication import DeviceCodeLoginAuthentication\n\nimport pandas as pd\n:::\nDepois disso, vamos ao código de verdade!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "href": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "title": "Power BI no Jupyter!",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nA primeira tarefa, como em todo o trabalho de um cientista de dados, é carregar os dados em um DataFrame.\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "href": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "title": "Power BI no Jupyter!",
    "section": "Autenticando no Serviço do Power BI",
    "text": "Autenticando no Serviço do Power BI\nEm seguida, temos que fazer a autenticação no serviço do Power BI. O Power BI, como todos os aplicativos do Office 365, requer que estejamos autenticados para utiliza-los. Aqui, o processo é simplificado, mas ainda requerido. Esse modo é o mais simples, se estiver interessado em outras maneiras, dê uma olhada mais a fundo na documentação da Microsoft.\n\ndevice_auth = DeviceCodeLoginAuthentication()\n\nPerforming device flow authentication. Please follow the instructions below.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A8EL2Y8WJ to authenticate.\n\nDevice flow authentication successfully completed.\nYou are now logged in .\n\nThe result should be passed only to trusted code in your notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#visualizando",
    "href": "posts/p0003-powerbiclient/index.html#visualizando",
    "title": "Power BI no Jupyter!",
    "section": "Visualizando!",
    "text": "Visualizando!\nO próximo passo é plotar o gráfico usando o Power BI. Neste post vamos explorar a classe QuickVisualize que nos entregará um tipo de sumário dos nossos dados, como em uma Análise Exploratória de Dados. Para isso, enviamos nosso DataFrame, o objeto de autenticação e chamamos a função PBI_visualize.\n\n# Create a Power BI report from your data\nPBI_visualize = QuickVisualize(get_dataset_config(pokemons), auth=device_auth)\n\n# Render the new report\nPBI_visualize"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#finalizando",
    "href": "posts/p0003-powerbiclient/index.html#finalizando",
    "title": "Power BI no Jupyter!",
    "section": "Finalizando",
    "text": "Finalizando\nE desta forma, conseguimos trazer o Power BI e todo o seu poder para dentro do nosso notebook! E essa é apenas uma das formas que temos para trabalhar com Power BI dentro do notebook! Se você quiser aprender mais, não deixe de acessar a documentação da biblioteca powerbiclient em Power BI - Jupyter."
  },
  {
    "objectID": "posts/data-102/index.html",
    "href": "posts/data-102/index.html",
    "title": "Parte 02 - Google Colab",
    "section": "",
    "text": "Olá Devs!\nHoje iremos conhecer o Google Colab, e entender como utiliza-lo em nossas tarefas de Análise e Visualização de Dados.\nVamos lá?\n\nO que é o Google Colab?\nO Google Colab é uma plataforma de computação em nuvem gratuita baseada no Jupyter Notebook. Ele permite que os usuários criem e compartilhem documentos que contenham código executável, equações, visualizações e texto explicativo. O Google Colab oferece suporte a várias linguagens de programação populares, incluindo Python, JavaScript e Swift.\nIsto significa que podemos intercalar blocos de texto, imagens e código em um mesmo documento. Como um Cientista de Dados, você vai utilizar muito este recurso tanto nos momentos em que você está trabalhando os dados e construindo o modelo quanto naquele momento em que você precisa comunicar seus achados e resultados para outros cientistas e para o seu público alvo.\n\n\nComo acessamos o Google Colab?\nPara acessar o Google Colab, você precisa se conectar com uma conta do Google e acessar o site colab.research.google.com. Você verá então, a seguinte tela:\n\n\n\nTela Inicial do Colab\n\n\nComo você pode ver, a primeira atividade que ele sugere é abrir exemplos ou, no meu caso, alguns arquivos mais recentes. O Colab é integrado com o Google Drive, então seus arquivos, que terão sempre a extensão .ipynb estarão sempre salvos lá no seu Drive, em uma pasta específica.\n\n\nIniciando um novo notebook!\nVamos iniciar? Clique no link “new notebook”. Você deve ver sua tela assim:\n\n\n\nNovo Notebook\n\n\nNeste momento, vamos destacar três áreas da tela:\n\nOnde fica o nome do notebook. Você pode modificar quando quiser\nSistema de arquivos do notebook. Quando iniciamos um novo notebook, temos um sistema de arquivos virtual, onde podemos subir arquivos que serão utilizados durante a execução do código. Esses arquivos são apagados quando o notebook não está ativo.\nEsta é uma célula. Um notebook é feito de um conjunto de células que são executadas sequencialmente. As células podem ser de dois tipos: células de código ou células de texto. A célula que estamos marcando é especificamente uma célula de código, pois tem o botão de execução bem a esquerda.\n\n\nCélulas de Texto\nAs células de texto nos permitem escrever texto no formato Markdown, que facilita bastante a formatação. Se quiser aprender mais sobre Markdown, clique aqui. Veja alguns exemplos:\n\n\n\nExemplos de célula de texto\n\n\n\n\nCélulas de Código\nCélulas de código, como o próprio nome diz, servem para escrever código que será executado. Podemos usar algumas linguagens, sendo que a mais comum é Python. Cada célula, ao ser executada, pode imprimir o resultado de sua execução logo abaixo. Veja um exemplo abaixo:\n\nimport pandas as pd\nimport json\nimport requests\n\nresponse = requests.get(\"https://dummyjson.com/products\")\njson.dump(json.loads(response.text)['products'], open('products.json','w'))\nraw_data = open('products.json','r')\n# .load(\"https://dummyjson.com/products\")\ndf = pd.read_json(raw_data)\n\ndf\n\n\n\n\n\n\n\n\nid\ntitle\ndescription\nprice\ndiscountPercentage\nrating\nstock\nbrand\ncategory\nthumbnail\nimages\n\n\n\n\n0\n1\niPhone 9\nAn apple mobile which is nothing like apple\n549\n12.96\n4.69\n94\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/1/thumbn...\n[https://i.dummyjson.com/data/products/1/1.jpg...\n\n\n1\n2\niPhone X\nSIM-Free, Model A19211 6.5-inch Super Retina H...\n899\n17.94\n4.44\n34\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/2/thumbn...\n[https://i.dummyjson.com/data/products/2/1.jpg...\n\n\n2\n3\nSamsung Universe 9\nSamsung's new variant which goes beyond Galaxy...\n1249\n15.46\n4.09\n36\nSamsung\nsmartphones\nhttps://i.dummyjson.com/data/products/3/thumbn...\n[https://i.dummyjson.com/data/products/3/1.jpg]\n\n\n3\n4\nOPPOF19\nOPPO F19 is officially announced on April 2021.\n280\n17.91\n4.30\n123\nOPPO\nsmartphones\nhttps://i.dummyjson.com/data/products/4/thumbn...\n[https://i.dummyjson.com/data/products/4/1.jpg...\n\n\n4\n5\nHuawei P30\nHuawei’s re-badged P30 Pro New Edition was off...\n499\n10.58\n4.09\n32\nHuawei\nsmartphones\nhttps://i.dummyjson.com/data/products/5/thumbn...\n[https://i.dummyjson.com/data/products/5/1.jpg...\n\n\n5\n6\nMacBook Pro\nMacBook Pro 2021 with mini-LED display may lau...\n1749\n11.02\n4.57\n83\nApple\nlaptops\nhttps://i.dummyjson.com/data/products/6/thumbn...\n[https://i.dummyjson.com/data/products/6/1.png...\n\n\n6\n7\nSamsung Galaxy Book\nSamsung Galaxy Book S (2020) Laptop With Intel...\n1499\n4.15\n4.25\n50\nSamsung\nlaptops\nhttps://i.dummyjson.com/data/products/7/thumbn...\n[https://i.dummyjson.com/data/products/7/1.jpg...\n\n\n7\n8\nMicrosoft Surface Laptop 4\nStyle and speed. Stand out on HD video calls b...\n1499\n10.23\n4.43\n68\nMicrosoft Surface\nlaptops\nhttps://i.dummyjson.com/data/products/8/thumbn...\n[https://i.dummyjson.com/data/products/8/1.jpg...\n\n\n8\n9\nInfinix INBOOK\nInfinix Inbook X1 Ci3 10th 8GB 256GB 14 Win10 ...\n1099\n11.83\n4.54\n96\nInfinix\nlaptops\nhttps://i.dummyjson.com/data/products/9/thumbn...\n[https://i.dummyjson.com/data/products/9/1.jpg...\n\n\n9\n10\nHP Pavilion 15-DK1056WM\nHP Pavilion 15-DK1056WM Gaming Laptop 10th Gen...\n1099\n6.18\n4.43\n89\nHP Pavilion\nlaptops\nhttps://i.dummyjson.com/data/products/10/thumb...\n[https://i.dummyjson.com/data/products/10/1.jp...\n\n\n10\n11\nperfume Oil\nMega Discount, Impression of Acqua Di Gio by G...\n13\n8.40\n4.26\n65\nImpression of Acqua Di Gio\nfragrances\nhttps://i.dummyjson.com/data/products/11/thumb...\n[https://i.dummyjson.com/data/products/11/1.jp...\n\n\n11\n12\nBrown Perfume\nRoyal_Mirage Sport Brown Perfume for Men & Wom...\n40\n15.66\n4.00\n52\nRoyal_Mirage\nfragrances\nhttps://i.dummyjson.com/data/products/12/thumb...\n[https://i.dummyjson.com/data/products/12/1.jp...\n\n\n12\n13\nFog Scent Xpressio Perfume\nProduct details of Best Fog Scent Xpressio Per...\n13\n8.14\n4.59\n61\nFog Scent Xpressio\nfragrances\nhttps://i.dummyjson.com/data/products/13/thumb...\n[https://i.dummyjson.com/data/products/13/1.jp...\n\n\n13\n14\nNon-Alcoholic Concentrated Perfume Oil\nOriginal Al Munakh® by Mahal Al Musk | Our Imp...\n120\n15.60\n4.21\n114\nAl Munakh\nfragrances\nhttps://i.dummyjson.com/data/products/14/thumb...\n[https://i.dummyjson.com/data/products/14/1.jp...\n\n\n14\n15\nEau De Perfume Spray\nGenuine Al-Rehab spray perfume from UAE/Saudi...\n30\n10.99\n4.70\n105\nLord - Al-Rehab\nfragrances\nhttps://i.dummyjson.com/data/products/15/thumb...\n[https://i.dummyjson.com/data/products/15/1.jp...\n\n\n15\n16\nHyaluronic Acid Serum\nL'OrÃ©al Paris introduces Hyaluron Expert Repl...\n19\n13.31\n4.83\n110\nL'Oreal Paris\nskincare\nhttps://i.dummyjson.com/data/products/16/thumb...\n[https://i.dummyjson.com/data/products/16/1.pn...\n\n\n16\n17\nTree Oil 30ml\nTea tree oil contains a number of compounds, i...\n12\n4.09\n4.52\n78\nHemani Tea\nskincare\nhttps://i.dummyjson.com/data/products/17/thumb...\n[https://i.dummyjson.com/data/products/17/1.jp...\n\n\n17\n18\nOil Free Moisturizer 100ml\nDermive Oil Free Moisturizer with SPF 20 is sp...\n40\n13.10\n4.56\n88\nDermive\nskincare\nhttps://i.dummyjson.com/data/products/18/thumb...\n[https://i.dummyjson.com/data/products/18/1.jp...\n\n\n18\n19\nSkin Beauty Serum.\nProduct name: rorec collagen hyaluronic acid w...\n46\n10.68\n4.42\n54\nROREC White Rice\nskincare\nhttps://i.dummyjson.com/data/products/19/thumb...\n[https://i.dummyjson.com/data/products/19/1.jp...\n\n\n19\n20\nFreckle Treatment Cream- 15gm\nFair & Clear is Pakistan's only pure Freckle c...\n70\n16.99\n4.06\n140\nFair & Clear\nskincare\nhttps://i.dummyjson.com/data/products/20/thumb...\n[https://i.dummyjson.com/data/products/20/1.jp...\n\n\n20\n21\n- Daal Masoor 500 grams\nFine quality Branded Product Keep in a cool an...\n20\n4.81\n4.44\n133\nSaaf & Khaas\ngroceries\nhttps://i.dummyjson.com/data/products/21/thumb...\n[https://i.dummyjson.com/data/products/21/1.pn...\n\n\n21\n22\nElbow Macaroni - 400 gm\nProduct details of Bake Parlor Big Elbow Macar...\n14\n15.58\n4.57\n146\nBake Parlor Big\ngroceries\nhttps://i.dummyjson.com/data/products/22/thumb...\n[https://i.dummyjson.com/data/products/22/1.jp...\n\n\n22\n23\nOrange Essence Food Flavou\nSpecifications of Orange Essence Food Flavour ...\n14\n8.04\n4.85\n26\nBaking Food Items\ngroceries\nhttps://i.dummyjson.com/data/products/23/thumb...\n[https://i.dummyjson.com/data/products/23/1.jp...\n\n\n23\n24\ncereals muesli fruit nuts\noriginal fauji cereal muesli 250gm box pack or...\n46\n16.80\n4.94\n113\nfauji\ngroceries\nhttps://i.dummyjson.com/data/products/24/thumb...\n[https://i.dummyjson.com/data/products/24/1.jp...\n\n\n24\n25\nGulab Powder 50 Gram\nDry Rose Flower Powder Gulab Powder 50 Gram • ...\n70\n13.58\n4.87\n47\nDry Rose\ngroceries\nhttps://i.dummyjson.com/data/products/25/thumb...\n[https://i.dummyjson.com/data/products/25/1.pn...\n\n\n25\n26\nPlant Hanger For Home\nBoho Decor Plant Hanger For Home Wall Decorati...\n41\n17.86\n4.08\n131\nBoho Decor\nhome-decoration\nhttps://i.dummyjson.com/data/products/26/thumb...\n[https://i.dummyjson.com/data/products/26/1.jp...\n\n\n26\n27\nFlying Wooden Bird\nPackage Include 6 Birds with Adhesive Tape Sha...\n51\n15.58\n4.41\n17\nFlying Wooden\nhome-decoration\nhttps://i.dummyjson.com/data/products/27/thumb...\n[https://i.dummyjson.com/data/products/27/1.jp...\n\n\n27\n28\n3D Embellishment Art Lamp\n3D led lamp sticker Wall sticker 3d wall art l...\n20\n16.49\n4.82\n54\nLED Lights\nhome-decoration\nhttps://i.dummyjson.com/data/products/28/thumb...\n[https://i.dummyjson.com/data/products/28/1.jp...\n\n\n28\n29\nHandcraft Chinese style\nHandcraft Chinese style art luxury palace hote...\n60\n15.34\n4.44\n7\nluxury palace\nhome-decoration\nhttps://i.dummyjson.com/data/products/29/thumb...\n[https://i.dummyjson.com/data/products/29/1.jp...\n\n\n29\n30\nKey Holder\nAttractive DesignMetallic materialFour key hoo...\n30\n2.92\n4.92\n54\nGolden\nhome-decoration\nhttps://i.dummyjson.com/data/products/30/thumb...\n[https://i.dummyjson.com/data/products/30/1.jp...\n\n\n\n\n\n\n\nEsta célula, se executada, irá carregar dados de um site, salvar um arquivo e carrega-lo em um DataFrame que depois será impresso na área de resultados.\n\n\n\nUtilizando um notebook\nOs exemplos acima são bons para mostrar cada parte separadamente, mas vamos a um exemplo que irá ilustrar a utilização típica destes blocos.\n\nExemplo\nDigamos que você precisa entregar um relatório para o seu chefe sobre quais são os primeiros 1000 números primos. Ele também solicita que você explique o que são números primos e como descobrir se um número é primo ou não.\nEm um cenário tradicional de programação, provavelmente se faria a entrega de pelo menos dois arquivos: um documento do word, por exemplo, com a parte descritiva e um arquivo de código-fonte com o código. Como o arquivo de código-fonte não guarda o resultado da execução, é muito provável que este resultado fosse adicionado ao documento do word, ou quem sabe, disponibilizado em um terceiro arquivo.\nDá um certo trabalho preparar tudo… Além precisar de um computador com Word e com um editor de código-fonte para fazer todo o relatório. Mas com o Google Colab, você pode fazer tudo em um único lugar: um notebook pode ser editado de qualquer lugar, através do browser!\nVeja o resultado abaixo:\n\n\n\nNotebook completo\n\n\nÉ bem interessante, não é mesmo? Tudo em um único documento, que eu posso compartilhar com outras pessoas, sem nenhuma complicação. E o melhor, quem abre este notebook, pode executar as partes que são código, quando bem quiserem, sem depender de você para atualizar os resultados.\n\n\n\nFinalizando\nEspero que você tenha gostado de aprender um pouco sobre o ambiente de desenvolvimento que iremos utilizar neste curso. Ao longo do curso, utilizaremos recursos mais avançados, então não perca a oportunidade de aprender mais sobre o Google Colab com estes links abaixo:\n\nO que é Google Colab\nGoogle Colaboratory - Hashtag Treinamentos\nVantagens de usar o Google Colab\n\n\n\n\n\n\n\nNote\n\n\n\nOs artigos citado acima e o conteúdo apresentado neste artigo não são de maneira nenhuma uma revisão extensiva do Google Colab, apresentamos apenas o necessário para você andar com seus próprios pés e no seu ritmo!\n\n\nUm abraço, e até a próxima!\nWalter."
  },
  {
    "objectID": "posts/data-101/index.html",
    "href": "posts/data-101/index.html",
    "title": "Parte 01 - Teoria de Visualização de Dados",
    "section": "",
    "text": "Olá Devs!\nNa primeira parte desta série, vamos aprender um pouco de teoria sobre Visualização e Ciência de Dados, com o objetivo de compreendermos a importância da Visualização de Dados dentro da Ciência de Dados.\n\nO que é Ciência de Dados\nA ciência de dados é uma disciplina que usa habilidades matemáticas e técnicas avançadas de análise de dados para transformar grandes quantidades de informações em insights úteis. Ela é usada em diversos setores para tomada de decisão informada e resolução de problemas complexos.\nCiência de dados é como ser um detetive super nerd que desvenda mistérios escondidos nos dados. Os cientistas de dados mergulham em montanhas de informações, usando suas habilidades matemáticas e de programação para desvendar padrões ocultos e responder a perguntas importantes. Eles são os mestres em transformar dados bagunçados em conhecimento valioso, ajudando empresas e pesquisadores a tomar decisões informadas. É como ter um superpoder de números e algoritmos, só que sem a capa e a máscara.\n\n\nO Fluxo de Trabalho de Ciência de Dados\nO Ciclo de Vida de Ciência de Dados é a formalização das 6 etapas que os cientistas de dados trabalham a cada projeto para chegar ao final com o resultado solicitado pelo cliente, e podemos ver suas fases na imagem abaixo:\n\n\nFonte: blog.betrybe.com.br\n\n1 - Entendendo o problema - aqui é feito o processo de descoberta, onde o problema que o cliente deseja resolvido é devidamente explicado, quebrado em requisitos e os dados disponíveis (ou a falta deles) são disponibilizados.\n2 - Coleta de dados - nesta fase, os conjuntos de dados iniciais caso existam são validados e se determina que outras fontes podem ser usadas para obter ou enriquecer os dados. Também são escritos os primeiros códigos para realizar a busca e download dos dados.\n3 - Processamento de dados - nesta fase os dados são analisados e transformados para atender ao propósito de negócio. Também é a fase em que começa o processo de criação de modelos de machine learning.\n4 - Exploração de dados - esta fase é caracterizada principalmente por visualização de dados sendo utilizada para compreender os dados gerados pelo modelo. São utilizadas técnicas específicas para essa exploração e todas dependem primariamente do bom entendimento na criação de visualizações de dados.\n5 - Comunicação de resultados - esta fase também reconhecida por fazer uso extensivo de técnicas de visualização de dados aliadas a técnicas de story telling para mostrar ao cliente os resultados obtidos.\n6 - Feedback - na última fase deste ciclo, se coleta as impressões do cliente e se inicia (caso necessário) uma nova iteração do projeto, para o refinamento da solução apresentada e a possibilidade de trabalhar em novos requisitos.\n\n\nO que é Visualização de Dados???\n\n\nFonte: o autor\n\n\n\nTipos de Visualização\nExistem diversos tipos de visualizações disponíveis. Sua utilização está associada ao tipo de informação e ao objetivo que temos ao mostrar os dados.\n\n\nFonte: o autor\n\nQuanto a objetivos, as visualizações são utilizadas com as seguintes finalidades: - Comparar valores - Evidenciar a correlação entre valores (como os dois valores se comportam em conjunto) - Como um valor se distribui em relação a uma dimensão contínua (geralmente o tempo) - Como um valor se distribui especificamente em relação a posicionamento geográfico - Como um valor se distribui entre dimensões não continuas que formam partes de um todo; o quanto cada valor representa em relação a esse todo - Como um valor se comporta em relação tempo.\n\n\nTipos de Visualização X Objetivo de Comunicação\nAbaixo segue um diagrama com uma indicação de quais gráficos podem ser utilizados de acordo com o seu objetivo.\n\n\nFonte: o autor\n\n\n\nComo podemos criar Visualizações???\nAssim como existem diversos tipos de visualizações, existem diversas ferramentas. Abaixo, colocamos uma lista de ferramentas para visualização de dados: - Excel - Tableau - Power BI - Qlik - Looker (antes chamada de Google Data Studio) - Oracle Analytics - SAP Business Objects - Grafana - Kibana\nEstas ferramentas se caracterizam por uma interface de usuário totalmente voltada para a criação de visualizações. Se vocês estivessem em um curso de Análise de Dados, seriam nossa escolha para o curso, pois elas focam na modelagem dos dados e criação das visualizações. Mas vocês estão em um curso para iniciarem na carreira de Cientistas de Dados, certo?\n\nEntão, como um Cientista de Dados cria visualizações???\nUm Cientista de Dados utiliza a Visualização de Dados de duas formas: 1) Como uma ferramenta de exploração dos dados, durante a fase em que estão procurando respostas 2) Como uma ferramenta de comunicação, para divulgar resultados\nConsiderando essas duas necessidades, embora o Cientista de Dados pudesse utilizar ferramentas como as citadas anteriormente, a verdade é que ele precisa de uma ferramenta que consiga combinar o poder da programação, com visualização de dados e também com uma estrutura documental organizada para compartilhamento de informação.\nPor isso, iremos utilizar uma tecnologia diferente para aprender visualização de dados: vamos aprender a criar visualizações de forma programática, ou seja, vamos criar visualizações utilizando programas escritos em Python.\n\n\nPorquê vamos fazer isso?\nPor alguns motivos:\n\nComo cientistas de dados, a maneira mais comum de entregar os resultados do seu trabalho, além de apresentações em powerpoint é através de notebooks interativos, como o Google Colab, ou o Jupyter. São ferramentas que ajudam muito no desenvolvimento de um story telling orientado a divulgação dos resultados\nAtualmente Python é a linguagem a se aprender na carreira de Cientista de Dados. Outras linguagens como R, Julia e até Java também são utilizadas, mas por enquanto, Python é a preferida\nAs bibliotecas de visualização em Python são muito flexíveis e poderosas, inclusive são utilizadas por algumas das ferramentas citadas acima\n\n\n\n\n\n\n\nNote\n\n\n\nEntão, agora que toda a teoria necessária está explicada, bora trabalhar??? Na Parte 02, iremos aprender sobre o Google Colab, a ferramenta que escolhemos para conduzir o restante desta série!\n\n\nUm abraço, e até a próxima!\nWalter."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html",
    "href": "posts/p0002-pandasai/index.html",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#introdução",
    "href": "posts/p0002-pandasai/index.html#introdução",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "href": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "E o que isso tem a ver com Ciências de Dados?",
    "text": "E o que isso tem a ver com Ciências de Dados?\nOs DataFrames são basicamente textos organizados em tabelas e colunas, que são correlacionados. Portanto, é possível carregar os dados em um modelo LLM (Large Language Model), habilitando a extração da informação destes DataFrames de maneira conversacional, como se estivéssemos dialogando. Mas o que realmente instiga esta nossa área é descobrir se podemos fazer este modelo realizar o trabalho de análise para nós, cientistas e analistas iniciantes (e até mesmo os mais experientes). A resposta mais recente que temos para isso é chamada de Pandas AI."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "href": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que é o Pandas AI?",
    "text": "O que é o Pandas AI?\n\n\n\nPandas e Llamas\n\n\nO Pandas AI é o melhor amigo do seu DataFrame! Com esta nova biblioteca, podemos dar aos nossos DataFrames a capacidade de serem consultados de maneira simples e eficiente, utilizando uma interface conversacional.\nEntão, vamos ver como podemos utilizar Pandas AI?\n\nPreparando o Ambiente\nA primeira coisa é garantir que seu ambiente tenha todas as bibliotecas necessárias instaladas: Pandas, PandasAI, OpenAI.\n$ pip install pandas pandasai openai\nEntão, vamos iniciar o nosso notebook. Temos que fazer o import das bibliotecas que vamos utilizar na nossa demonstração.\n\nimport os\nimport pandas as pd\n\nfrom pandasai import PandasAI\nfrom pandasai.llm.openai import OpenAI\nfrom dotenv import load_dotenv\n\nObserve que carregamos a função load_dotenv, pois iremos precisar carregar a chave de acesso para a API da OpenAI. Para fazer isso, podemos simplesmente executar a função.\n\nload_dotenv()\n\nTrue\n\n\nO próximo passo é carregar os nossos dados no DataFrame. Como sempre, vamos utilizar o dataset de pokemons.\n\npokemons = pd.read_csv('pokemons.csv')\n\nEm seguida, vamos inicializar o LLM para que consigamos conversar com o nosso DataFrame.\n\nllm = OpenAI(api_token=os.environ['OPENAI_API_KEY'])\npandas_ai = PandasAI(llm)\n\nAté agora, tudo correu bem! Agora, podemos executar diversas vezes a função pandas_ai.run, passando nosso DataFrame e um prompt, e ele nos responderá. Vamos testar?\n\npandas_ai.run(pokemons, prompt=\"Quantos pokemons temos no DataFrame?\")\n\n'Unfortunately, I was not able to answer your question. Please try again. If the problem persists, try rephrasing your question.'\n\n\nPara verificar isso, podemos apenas ver o shape do DataFrame e confirmar:\n\npokemons.shape\n\n(1032, 44)\n\n\nDe fato, 1032 pokemons. Vamos continuar?\n\npandas_ai.run(pokemons, prompt=\"Quantos tipos de pokemons existem?\")\n\n'Well, there are actually 18 different types of pokemons out there!'\n\n\nVamos conferir?\n\ntipos = pd.concat([pokemons['Type 1'], pokemons['Type 2']]).unique().tolist()\n\n\nprint(len(tipos))\nprint(tipos)\n\n19\n['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Dark', 'Poison', 'Electric', 'Ground', 'Ice', 'Fairy', 'Steel', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Dragon', 'Flying', nan]\n\n\nParece que funciona mesmo! Note que o nosso vetor tem 19 posições porque está contando o nulo como um valor. Vamos nos aprofundar mais um pouco…\n\npandas_ai.run(pokemons, prompt='Liste os tipos com as quantidades de pokemons')\n\n'Existem diversos tipos de pokemons e suas quantidades variam. O tipo mais comum é o Normal, com 114 pokemons, seguido pelo tipo Água, com 131. Já o tipo Voador é o menos comum, com apenas 8 pokemons. Além disso, existem outros tipos como Fogo, Grama, Elétrico, Psíquico, entre outros, cada um com sua quantidade específica de pokemons. No total, existem mais de 800 espécies diferentes de pokemons.'\n\n\nEle respondeu, mas não exatamente como queríamos - observe que ele listou alguns tipos apenas com suas quantidades. Vamos tentar melhorar, aplicando um pouco de prompt engineering (ou seja, escrever nossa solicitação de forma mais explícita).\n\npandas_ai.run(pokemons, prompt=\"Crie uma tabela que tem duas colunas: tipo de pokemon e quantidade. Liste todos os tipos possíveis e suas quantidades.\")\n\n'Para responder à pergunta, criei uma tabela com duas colunas: tipo de pokemon e quantidade. Nessa tabela, listei todos os tipos possíveis de pokemon e suas respectivas quantidades. Por exemplo, há 81 pokemons do tipo Bug, 46 do tipo Dark, 42 do tipo Dragon, e assim por diante. No total, foram listados 18 tipos diferentes de pokemon e suas quantidades correspondentes.'\n\n\nHumm, ainda não conseguimos listar todos os tipos. Vamos explicar um pouco mais?\n\npandas_ai.run(pokemons, prompt=\"Gerar uma listagem completa da quantidade de pokemons por tipo, em formato markdown.\")\n\n'Para saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo: \\n\\n| Type | Count |\\n|------|-------|\\n| Bug | 81 |\\n| Dark | 46 |\\n| Dragon | 42 |\\n| Electric | 59 |\\n| Fairy | 22 |\\n| Fighting | 42 |\\n| Fire | 64 |\\n| Flying | 8 |\\n| Ghost | 41 |\\n| Grass | 91 |\\n| Ground | 41 |\\n| Ice | 38 |\\n| Normal | 114 |\\n| Poison | 40 |\\n| Psychic | 77 |\\n| Rock | 59 |\\n| Steel | 36 |\\n| Water | 131 |\\n\\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.'\n\n\nOpa,agora foi. Mas como o notebook não formata markdown no output, precisamos fazer um copia e cola do resultado.\nPara saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo:\n\n\n\nType\nCount\n\n\n\n\nBug\n81\n\n\nDark\n46\n\n\nDragon\n42\n\n\nElectric\n59\n\n\nFairy\n22\n\n\nFighting\n42\n\n\nFire\n64\n\n\nFlying\n8\n\n\nGhost\n41\n\n\nGrass\n91\n\n\nGround\n41\n\n\nIce\n38\n\n\nNormal\n114\n\n\nPoison\n40\n\n\nPsychic\n77\n\n\nRock\n59\n\n\nSteel\n36\n\n\nWater\n131\n\n\n\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.’"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "href": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vamos complicar um pouco?",
    "text": "Vamos complicar um pouco?\nNas primeiras perguntas, utilizamos perguntas que pedem respostas quase que diretas das métricas que temos no DataFrame. Contamos o número de pokemons, contamos valores distinto de tipos, agrupamos a contagem por tipos. Mas será que o Pandas AI pode fazer uma análise comparativa simples, tal como analisar uma métrica e retornar o insight solicitado?\n\npandas_ai.run(pokemons, prompt=\"Qual o pokemon mais pesado?\")\n\n'Bem, o pokemon mais pesado é o Snorlax, ele pode chegar a pesar mais de 460 quilos!'\n\n\nOpa, e não é que respondeu? Mas, sem precipitação, vamos conferir: vamos executar uma query em pandas que filtra os pokemons com peso &gt;= ao do Snorlax.\n\npokemons[[\"Name\",\"Weight\"]].sort_values(\"Weight\").query(\"Weight &gt; 459\")\n\n\n\n\n\n\n\n\nName\nWeight\n\n\n\n\n925\nDusk Mane Necrozma\n460.0\n\n\n181\nSnorlax\n460.0\n\n\n837\nHoopa Unbound\n490.0\n\n\n826\nAvalugg\n505.0\n\n\n1001\nStonjourner\n520.0\n\n\n445\nMetagross\n550.0\n\n\n833\nZygarde Complete\n610.0\n\n\n578\nGiratina-Origin\n650.0\n\n\n1007\nCopperajah\n650.0\n\n\n573\nDialga\n683.0\n\n\n254\nMega Steelix\n740.0\n\n\n577\nGiratina\n750.0\n\n\n1019\nZamazenta Crowned Shield\n785.0\n\n\n1027\nGlastrier\n800.0\n\n\n936\nMelmetal\n800.0\n\n\n1030\nCalyrex Ice Rider\n809.1\n\n\n932\nStakataka\n820.0\n\n\n923\nGuzzlord\n888.0\n\n\n873\nMudsdale\n920.0\n\n\n446\nMega Metagross\n942.9\n\n\n1020\nEternatus\n950.0\n\n\n456\nGroudon\n950.0\n\n\n457\nPrimal Groudon\n999.7\n\n\n914\nCosmoem\n999.9\n\n\n921\nCelesteela\n999.9\n\n\n\n\n\n\n\nOps, algo deu errado. Temos vários pokemons mais pesados. Será que ele não analisou todos os pokemons antes de responder? Quem sabe um problema nos dados? Vamos perguntar algo mais direto.\n\npandas_ai.run(pokemons, prompt=\"O pokemon Dialga é mais ou menos pesado que o Snorlax?\")\n\n'Well, it turns out that Snorlax is actually heavier than Dialga.'\n\n\nIsso certamente deve ser um problema. Ele passou a responder em inglês, como se tivesse perdido o contexto. Vamos perguntar de maneira diferente…\n\npandas_ai.run(pokemons, prompt=\"Porque o pokemon Dialga é mais pesado que o Snorlax?\")\n\n'Well, actually, Snorlax weighs more than Dialga.'\n\n\nÉ, ele realmente tem uma implicância com o Snorlax… Caso você não tenha lido nada a respeito do ChatGPT e LLMs em geral, esse tipo de erro é chamado de “alucinação” que ocorre quando o modelo produz resultados incorretos, correlacionando informações de maneira espúria."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "href": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Usando outras funcionalidades do Pandas via conversação",
    "text": "Usando outras funcionalidades do Pandas via conversação\nAgora vamos testar se o pandasAI consegue entender instruções para plotar gráficos. Isso é um DataFrame pandas, correto? Será que eu posso plotar um countplot() por geração?\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de colunas totalizando pokemons por geração.\")\n\n\n\n\n\n\n\n\n'Claro! Vou plotar um gráfico de colunas que mostra a quantidade total de pokemons por geração.'\n\n\nParece que funcionou bem! Vamos tentar mais um?\n\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de pizza totalizando pokemons pelo campo lendário.\")\n\n\n\n\n\n\n\n\n'Sure, I can help you with that! To plot a pie chart showing the total number of legendary Pokémon, we need to gather the data first. Once we have the numbers, we can create a visual representation of the data using a pie chart. Would you like me to proceed with the task?'"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "href": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que aprendemos até aqui",
    "text": "O que aprendemos até aqui\nA biblioteca Pandas AI é uma biblioteca interessante, que nos permite “dialogar”com nossos DataFrames, extraindo informações do mesmo. Através de nossos exemplos, podemos verificar que quase tudo que podemos descobrir através de consultas normais pandas, podemos perguntar ao DataFrame através do Pandas AI.\n\nMas nem tudo são flores…\nApesar dos acertos, observamos que a biblioteca Pandas AI não é imune aos problemas comuns das LLM, e mesmo com uma base de conhecimento mais limitada, é acometida de alucinações. A biblioteca também sofre de um problema de performance: uma resposta que em pandas leva um segundo ou menos para ser mostrada, como podemos ver, pode levar até mais de 1 minuto usando PandasAI.\nPor último, podemos perceber que a biblioteca ainda precisa um pouco mais de trabalho até mesmo em sua usabilidade - notamos que a mesma passa a responder em inglês quando a resposta está errada, deixando o usuário confuso."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "href": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vale a pena utilizar?",
    "text": "Vale a pena utilizar?\nSe você quer fazer explorações simples dos dados, parece ser uma boa idéia utilizar o PandasAI, visto que é mais fácil perguntar em português ou inglês do que lembrar a sintaxe de todos os comandos Pandas que você teria que fazer para isso. No entanto, é preciso tomar muito cuidado com os resultados, que podem estar errados, mas são comunicados com convicção.\nÉ, com certeza, mais uma ferramenta no seu cinto de utilidades de cientista de dados, e como toda ferramenta, devemos conhece-la bem antes de usar. Explore mais, entenda suas limitações e faça o melhor uso possivel!\nAté mais!!!\nWalter."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html",
    "href": "posts/p0004-classif-texto/index.html",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#introdução",
    "href": "posts/p0004-classif-texto/index.html#introdução",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "href": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Classificação de Dados",
    "text": "Classificação de Dados\nClassificação de dados é uma tarefa de aprendizado supervisionado que envolve a categorização de uma determinada amostra de dados em uma das várias classes predefinidas. Cada amostra é atribuída a uma e somente uma classe, baseando-se nas características dessa amostra.\nPor exemplo, imagine que você tem um conjunto de emails e você quer classificá-los como “spam” ou “não spam”. Nesse caso, “spam” e “não spam” são as classes, e cada email é uma amostra que será classificada em uma dessas classes.\nA classificação é geralmente realizada utilizando algoritmos de aprendizado de máquina. Esses algoritmos aprendem a classificar novas amostras baseando-se em um conjunto de treinamento. O conjunto de treinamento é um conjunto de amostras para as quais as classes verdadeiras são conhecidas.\nOs algoritmos de classificação incluem árvores de decisão, regressão logística, máquinas de vetores de suporte, redes neurais e muitos outros. A escolha do algoritmo depende de vários fatores, como a natureza dos dados, o número de classes, a necessidade de interpretabilidade e outros.\n\nMas e se não temos conjuntos de dados de treinamento?\nSe você não tem um conjunto de dados de treinamento rotulado, ainda existem várias abordagens que você pode usar, tais como:\n\nAprendizado não supervisionado\nAprendizado semi-supervisionado\nAprendizado por reforço\nRotulagem manual\nGeração de rótulos sintéticos\nProcessamento de Linguagem Natural\n\nE é nesta última opção que podemos utilizar o GPT para nos ajudar, pois o modelo do GPT é gigantesco, tendo sido treinado com conteúdo de toda a internet.\n\n\nGPT versus métodos mais tradicionais de classificação\nOs modelos de linguagem como o GPT (Generative Pretrained Transformer) têm várias vantagens e desvantagens, especialmente quando comparados a outros métodos de análise de texto. Aqui estão algumas delas:\nVantagens:\n\nCompreensão Profunda da Linguagem: O GPT é treinado em enormes quantidades de texto, o que lhe permite aprender uma rica compreensão da linguagem natural. Isso inclui uma compreensão de sintaxe, semântica, e até mesmo alguns elementos de conhecimento do mundo real.\nVersatilidade: O GPT pode ser usado para uma ampla gama de tarefas de processamento de linguagem natural, incluindo tradução de texto, geração de texto, resumo de texto, análise de sentimento, resposta a perguntas e muito mais.\nAprendizado Transferível: O GPT utiliza o aprendizado transferível, o que significa que o conhecimento aprendido durante o treinamento em um grande conjunto de dados pode ser aplicado a tarefas específicas com relativamente poucos dados de treinamento adicionais. Isso permite ao GPT se adaptar a uma ampla gama de tarefas com um desempenho impressionante.\nModelagem de Contexto: A arquitetura do Transformer, utilizada pelo GPT, é especialmente boa para entender o contexto em uma sequência de texto, o que é crucial para muitas tarefas de processamento de linguagem natural.\n\nDesvantagens:\n\nNecessidade de Grandes Quantidades de Dados de Treinamento: O GPT precisa de grandes quantidades de dados de treinamento para aprender efetivamente. Isso pode tornar o treinamento do modelo do zero proibitivamente caro em termos de tempo e recursos computacionais.\nDificuldade de Interpretação: O GPT, como muitos modelos de aprendizado profundo, pode ser difícil de interpretar. Ele pode produzir resultados impressionantes, mas pode ser difícil entender por que fez uma determinada previsão.\nSensibilidade ao Ruído e Erros: Embora o GPT seja robusto em muitos aspectos, ele pode ser sensível a ruído e erros no texto de entrada. Pequenas mudanças no texto de entrada podem às vezes levar a grandes mudanças nas previsões do modelo.\nPotencial de Viés: O GPT aprende com os dados em que é treinado, e se esses dados contêm viés, o modelo também pode exibir viés. Isso pode ser um problema significativo quando o modelo é usado em contextos sensíveis."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "href": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Ok, o GPT é legal e tudo o mais… Mas e daí?",
    "text": "Ok, o GPT é legal e tudo o mais… Mas e daí?\nE daí que, graças ao modelo GPT, podemos ter um classificador de texto super calibrado para nos ajudar em nossas tarefas, sem o ônus de treinar tal modelo. E podemos utilizar o GPT a partir da API da OpenAI, de maneira muito simples! Outra vantagem que vale ressaltar é que, ao contrário de modelos tradicionais de classificação, podemos atribuir múltiplas categorias ao nosso texto.\nVamos ver um exemplo?"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "href": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Organizando um catálogo de artigos",
    "text": "Organizando um catálogo de artigos\nImagine o seguinte cenário: temos uma lista de todos os artigos que salvamos no site Medium. O problema desta lista é que o Medium não oferece nenhum tipo de categorização dos artigos. A única maneira de fazer isso é separando em várias listas, o que dificulta principalmente o processo de busca dos artigos. Além, é claro, de pressupor a classificação antes de ler o artigo.\nEssa tarefa realmente não é trivial, e seria muito útil poder fazer isso de forma automatizada. E o primeiro problema que temos é que nossa lista tem apenas o título e a url dos artigos. Para que a classificação seja mais precisa, precisamos de pelo menos algum texto que nos ajude a ter mais contexto a respeito do artigo.\nEntão, vamos criar o nosso script classificador? Esse script vai executar as seguintes tarefas:\n\n\n\n\n\nflowchart LR\n  A[Carregar Lista de Arquivos] --&gt; B\n  B[Buscar Título e Resumo&lt;br&gt;dos Artigos] --&gt; C\n  C[Classificar Artigos] --&gt; D[Salvar Lista de Artigos]\n\n\n\n\n\n\n\nInicializando o ambiente\nVamos utilizar as seguintes bibliotecas: - beautifulsoup4 - biblioteca para extrair a informação do HTML que contém a lista de artigos - openai - biblioteca para utilizar a API da openAI - requests - bibliotea para buscar informações da internet\n\nimport os\nimport openai\nimport bs4\nimport json\n\nfrom dotenv import load_dotenv\nfrom requests_html import HTMLSession # importando o objeto de sessão do html requests\n\nA próxima etapa é carregar variáveis de ambiente. Lembrando que é necessário ter uma API key para usar a API da OpenAI.\n\nload_dotenv()\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nAgora, precisamos carregar nossa lista de artigos, que está em um arquivo HTML, que podemos baixar lá no site do Medium. Vamos criar uma função, de forma que poderemos re-utilizar essa parte da rotina sempre que for necessário.\n\ndef retorna_lista(nomearquivo: str):\n  html_artigos = bs4.BeautifulSoup(open(nomearquivo, \"r\"))\n  list_artigos = html_artigos.find_all(\"li\")\n\n  artigos = []\n  for item in list_artigos:\n    record = {}\n    record = {\n        \"titulo\": item.a.text,\n        \"link\": item.a[\"href\"],\n        \"autores\": None,\n        \"resumo\": None,\n        \"categorias\": None\n    }\n    artigos.append(record)\n  return artigos\n\nEste código define uma função chamada “retorna_lista” que recebe um único parâmetro chamado “nomearquivo” do tipo string. A função primeiro abre o arquivo especificado pela string “nomearquivo” usando a função “open”, lê o conteúdo e usa o método “find_all” do Beautiful Soup para procurar todos os elementos de lista no documento HTML e armazená-los na variável “list_artigos”. A função, então, inicializa uma lista vazia chamada “artigos”. Em um loop, ela itera sobre cada item da lista na variável “list_artigos” e cria um dicionário chamado “record” com três chaves: “titulo”, “link”, “autores”, “resumo” e “categorias”. Os valores para “titulo” e “link” são extraídos do texto da tag “a” e do atributo “href”, respectivamente. O valor das chaves “autores”, “resumo” e “categorias” são uma string vazia. O dicionário “record” completo é então adicionado à lista “artigos”. Depois que todos os itens da lista são processados, a função retorna a lista “artigos”.\nEntão, podemos utilizar essa função conforme abaixo:\n\nartigos = retorna_lista(\"reading-list-medium.html\")\n\nprint(f\" Número de Artigos: {len(artigos)}.\")\n\n Número de Artigos: 1865.\n\n\nVamos ver como ficou um registro:\n\nprint(json.dumps(artigos[0], indent=4))\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": null,\n    \"resumo\": null,\n    \"categorias\": null\n}\n\n\nPerfeito! Estamos com os artigos preparados para buscarmos os dados extra que nos darão mais contexto para a categorização.\nPara fazer isso, vamos utilizar a biblioteca requests-html. Novamente, criaremos uma função para reutilizar depois.\n\ndef retorna_campos(registro: dict):\n    # Declaramos variaveis que contem seletores HTML\n    # Esses seletores nos ajudarão a encontrar os elementos HTML que contém o \n    # conteúdo referente ao autor, data publicação, titulo e lead\n    seletor_autor = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(1) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\"\n    ]\n    seletor_titulo_lead = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2)\", \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2)\"\n    ]\n  \n    # Inicializamos o objeto HTMLSession para fazer a coleta da informação dos artigos\n    request = HTMLSession()\n    try:\n      print(registro[\"link\"])\n      conteudo_html = request.get(registro[\"link\"])\n      autor = \"Not available\"\n      \n      for item in seletor_autor:\n        aux_autor = None\n        aux_autor = conteudo_html.html.find(item, first=True)\n        if aux_autor is not None:\n          autor = aux_autor\n          break\n\n      head = \"Not available\"\n      for item in seletor_titulo_lead:\n        aux_head = None\n        aux_head = conteudo_html.html.find(item, first=True)\n        if aux_head:\n          aux_lead = aux_head.find('h2', first=True)\n          if aux_lead is not None:\n            head = aux_lead.text\n          \n      registro[\"autores\"] = autor.text\n      registro[\"resumo\"] = head\n        \n      return registro\n    except:\n      print('URL {0} com erro. Verifique.'.format(registro[\"link\"]))\n      return None\n\nA função retorna_campos faz o scraping de dados de páginas da web, especificamente páginas de notícias ou artigos de blog do Medium. Ele pega um dicionário de “registro” como entrada, que parece conter um “link” para uma página da web.\nPasso-a-Passo:\n\nVariáveis seletor_autor e seletor_titulo_lead são listas de seletores CSS. Seletores CSS são padrões usados para selecionar os elementos que você deseja estilizar. Aqui, eles são usados para identificar os elementos HTML onde as informações de autor e título/lead estão localizadas no HTML da página.\nA função então inicia uma sessão HTML usando o módulo HTMLSession() do pacote requests_html, que é uma biblioteca Python para fazer solicitações HTTP e para parsing de HTML.\nA função tenta fazer uma solicitação GET para a URL que está no campo “link” do dicionário de entrada.\nEm seguida, a função tenta encontrar o autor do artigo. Para isso, itera sobre a lista seletor_autor e, para cada seletor, tenta encontrar um elemento correspondente na página HTML. Se encontrar um autor, interrompe o loop e guarda o autor encontrado.\nDepois disso, a função tenta encontrar o título do artigo da mesma maneira, usando a lista seletor_titulo_lead.\nOs resultados são então adicionados ao dicionário de entrada no campo “autores” para o autor e “resumo” para o título.\nSe houver algum erro durante o processo, como um link quebrado ou se o seletor CSS não corresponder a nenhum elemento, a função exibe uma mensagem de erro e retorna None.\nSe tudo correr bem, a função retorna o dicionário de entrada, agora com informações adicionais sobre o autor e o resumo do artigo.\n\nAgora vamos a execução da função para cada artigo em nossa lista. Observe que colocamos um limitador para fazer isso para 10 registros.\n\nartigos_comp = []\ni = 0\nfor item in artigos:\n    artigos_comp.append(retorna_campos(item))\n    i += 1\n    if i == 10:\n        break\n\nhttps://medium.com/p/e323b2d24987\nhttps://medium.com/p/9e9536ebd839\nhttps://medium.com/p/bb7d31ed2e76\nhttps://medium.com/p/2688e319e2a5\nhttps://medium.com/p/7edae42a20b3\nhttps://medium.com/p/f87419cb14cb\nhttps://medium.com/p/d6169fc81204\nhttps://medium.com/p/74361bc3b92e\nhttps://medium.com/p/9dc1566d960d\nhttps://medium.com/p/3c053357c47f\n\n\nAgora temos os nossos artigos com título, autor e uma lead line, que vai nos ajudar no processo da categorização.\nVamos agora, a nossa rotina de categorização, usando a API do OpenAI.\n\ndef retorna_categorias(titulo, resumo):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=f\"We have these categories: dbt, Python, DataViz, Tableau, PowerBI, and Generative AI. Given those categories, please classify the following text with those categories: {titulo} - {resumo}. You can use only the categories listed. You can classify with multiple categories. If you think that none of the categories applies, you can tag as Other.\",\n        temperature=0.8,\n        max_tokens=20,\n    )\n    return response.choices[0].text.strip()\n\nEste código define uma função chamada “retorna_categorias” que recebe dois parâmetros: “titulo” e “resumo”. A função utiliza a API OpenAI para classificar o título e o resumo com base em um conjunto de categorias previamente determinadas - dbt, Python, DataViz, Tableau, PowerBI e Generative AI. Em seguida, retorna o resultado da classificação como uma string.\nA função retorna então a primeira (e única) escolha da resposta da API OpenAI, que é a string que representa a categoria que foi escolhida como a melhor correspondência para o texto de entrada. O método strip() é usado para remover qualquer espaço em branco inicial ou final da string retornada.\nObservação: Para usar este código, o módulo openai precisa ser importado e uma chave de API OpenAI precisa ser obtida.\n\nlista_final = []\nfor item in artigos_comp:\n  item[\"categorias\"] = retorna_categorias(item['titulo'], item['resumo'])\n  lista_final.append(item)\n\nAgora que executamos a rotina acima, podemos imprimir os três primeiros registros e verificar que agora, temos categorias.\n\nfor idx, item in enumerate(lista_final):\n    print(json.dumps(item, indent=4))\n    if idx == 2:\n        break\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": \"John Loewen\",\n    \"resumo\": \"I\\u2019ve done the prompt engineering research so you don\\u2019t have to\",\n    \"categorias\": \"Python, Generative AI\"\n}\n{\n    \"titulo\": \"Power BI: How I Started Using Python To Automate Tasks\",\n    \"link\": \"https://medium.com/p/9e9536ebd839\",\n    \"autores\": \"Gabe Araujo, M.Sc.\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"PowerBI, Python\"\n}\n{\n    \"titulo\": \"Chat with your databases using LangChain\",\n    \"link\": \"https://medium.com/p/bb7d31ed2e76\",\n    \"autores\": \"Vishnu Sivan\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"Other\"\n}\n\n\nE aí estão os nossos artigos, devidamente categorizados. Inclusive, podemos ver um artigo que foi classificado como “Other”, indicando que o texto que foi enviado não foi suficiente para classificar com as categorias selecionadas.\nObrigado por ler até aqui! Espero que este script seja útil para vocês!!!"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#links-úteis",
    "href": "posts/p0004-classif-texto/index.html#links-úteis",
    "title": "AI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI",
    "section": "Links Úteis",
    "text": "Links Úteis\n\nUnderstanding GPT-3: OpenAI’s Language Generation AI: Blog oficial da OpenAI sobre GPT-3 - Apresenta uma explicação detalhada do GPT-3 e seu uso potencial\nData Classification in Machine Learning - Este é um artigo do site GeeksforGeeks que explica o conceito básico de classificação de dados em aprendizado de máquina, os diferentes tipos de algoritmos de classificação e como eles funcionam.\nBibliotecas Python utilizadas no artigo:\n\nrequests-html\nopenai\nBeautifulSoup4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WV Code - Educação e Consultoria",
    "section": "",
    "text": "Todos os posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAI na Análise de Dados - 1 - Classificação de Texto com a API da OpenAI\n\n\n\n\n\n\nOpenAI API\n\n\n\nVamos utilizar a API da OpenAI para executar uma das tarefas mais comuns em NLP - a classificação de textos.\n\n\n\n\n\nJun 16, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPower BI no Jupyter!\n\n\n\n\n\n\nPandas\n\n\nPower BI\n\n\nJupyter\n\n\n\nUse o Power BI para plotar gráficos no seu Jupyter Notebook.\n\n\n\n\n\nMay 30, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPandas AI - Converse com seu DataFrame\n\n\n\n\n\n\nCiência de Dados\n\n\nPandas\n\n\nAI\n\n\nGPT\n\n\n\nNova biblioteca se propõe a permitir que você “converse” com o seu DataFrame.\n\n\n\n\n\nMay 29, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 02 - Google Colab\n\n\n\n\n\n\nVisualização\n\n\nNotebooks\n\n\nJupyter\n\n\n\nConhecendo nossa ferramenta de trabalho…\n\n\n\n\n\nFeb 4, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 01 - Teoria de Visualização de Dados\n\n\n\n\n\n\nVisualização\n\n\nTeoria\n\n\nCiência de Dados\n\n\n\nUm pouco de teoria antes de iniciar…\n\n\n\n\n\nFeb 3, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\n[VDP] - Introdução\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\n\nIniciando com tudo!\n\n\n\n\n\nFeb 2, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "vanessa.html",
    "href": "vanessa.html",
    "title": "Vanessa S.M. Paixão-Côrtes",
    "section": "",
    "text": "Vanessa é professora, manda muito bem.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2019\nMestrado em Ciência da Computação - 2015\n\nURI - Santo Ângelo\n\nBacharelado em Sistemas de Informação - 2013\nLicenciatura em Ciências Biológicas - 2004\n\n\n\n\nCertificados\nN/A\n\n\nExperiência\n\nTrybe\n\nPessoa Especialista - 2021 - 2022\n\nCESUCA\n\nProfessora - 2020 - 2021\n\nUFSCPA\n\nProfessora - 2020 - 2021"
  }
]