[
  {
    "objectID": "walter.html",
    "href": "walter.html",
    "title": "Walter R. Paixão-Côrtes",
    "section": "",
    "text": "Walter é um profissional da área de TI com mais de 25 anos de experiência. Atualmente, trabalha como Product Line Manager na Dell Technologies e atua como Engenheiro Analista de Dados em projetos independentes.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2020\nMestrado em Ciência da Computação - 2015\nBacharelado em Ciência da Computação - 2002\n\nCTI - FURG\n\nTecnólogo em Processamento de Dados - 1993\n\n\n\n\nCertificados\n\nAnalista de Requisitos, IIBA - 2016\nScrum Master, ScrumAlliance, 2017\n\n\n\nExperiência\n\nDell Technologies\n\nProduct Line Manager - 2022 - …\nProduct Designer - 2019 - 2022\nPrincipal Soft. Engineer - 2017 - 2019\nLead Senior Software Engineer - 2008 - 2017\nLead Software Engineer - 2005 - 2008\n\nAccenture\n\nConsultor - 2003 - 2005\n\nBankorp Consultores Associados\n\nConsultor - 2001 - 2003\n\nBinário Internet\n\nLead Software Engineer - 1999 - 2001\n\nCSI - Consultoria e Sistemas de Informação\n\nSoftware Engineer - 1996 - 1999\n\nOutras Empresas\n\nEstagiário/Programador - 1993 - 1996"
  },
  {
    "objectID": "posts/data-010/index.html",
    "href": "posts/data-010/index.html",
    "title": "Introdução",
    "section": "",
    "text": "Olá Devs!!!\nA série de Visualização de Dados com Python tem por objetivo habilita-los a utilizar a linguagem Python para:\n\nrealizar análises de dados em grandes volumes e nos mais diferentes formatos\ncriar gráficos que transmitam a informação de maneira agradável e direta\naprender sobre tipos de visualização de dados que vão além dos gráficos de barras, linhas e tortas.\n\nAo longo dos posts você irá aprender a utilizar algumas das bibliotecas Python mais famosas na área de Ciência de Dados: Requests, Pandas, Seaborn, MatplotLib, Plotly e muito mais.\nEntão, não perca mais tempo e comece a leitura agora mesmo!\n\nAVISO!!!\nEssa série de posts é destinada a um público menos experiente, que ainda está aprendendo a programar em Python, bem como aqueles que estão iniciando seu caminho na área de Ciência de Dados. Se você já domina a linguagem, os artigos fora da série de Visualização de Dados com certeza serão mais interessantes!\nUm abraço, Walter."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre o Blog",
    "section": "",
    "text": "O WV Code é um blog de tecnologia criado por dois profissionais da área: Vanessa S.M. Paixão Côrtes e Walter R. Paixão Côrtes. Este blog tem por objetivo realizar a divulgação de conteúdo tecnológico de forma gratuita e em bom Português, tornando o vasto conteúdo de nossa área mais acessível para aqueles que estão iniciando na área e ainda não dominam o Inglês, bem como para quem ainda não consegue pagar por conteúdo on-line. Além de aprender com nossas publicações interativas, você pode ter acesso aos nossos repositórios de código no github.\n \n  \n   \n  \n    \n     Github\n  \n\n\n\n\nQuem faz o Blog?\n\nVanessa S.M. Paixão-Côrtes\nWalter R. Paixão-Côrtes"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html",
    "href": "posts/p0003-powerbiclient/index.html",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#introdução",
    "href": "posts/p0003-powerbiclient/index.html#introdução",
    "title": "Power BI no Jupyter!",
    "section": "",
    "text": "Se você é um entusiasta de visualização de dados, cientista de dados ou analista de negócios em busca de novas maneiras de explorar e compartilhar seus dados, este post é para você. Prepare-se para descobrir como o poder do Power BI pode ser desbloqueado dentro do Jupyter Notebook, ampliando suas possibilidades de análise e proporcionando uma experiência envolvente e interativa."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "href": "posts/p0003-powerbiclient/index.html#powerbi---rápida-introdução",
    "title": "Power BI no Jupyter!",
    "section": "PowerBI - Rápida Introdução",
    "text": "PowerBI - Rápida Introdução\nO Power BI é uma poderosa ferramenta de business intelligence desenvolvida pela Microsoft, projetada para ajudar as empresas a visualizar e analisar seus dados de maneira intuitiva e interativa. Com recursos avançados de criação de relatórios, painéis e dashboards personalizados, o Power BI permite que os usuários transformem seus dados em informações acionáveis, facilitando a tomada de decisões informadas em tempo real. E todo esse poder pode ser entregue tanto de forma independente quanto integrada a outros meios, através do que chamamos de embedded reports.\n\nPower BI Embeddings\nAs capacidades de embedding do Power BI permitem que os desenvolvedores incorporem relatórios, painéis e visualizações interativas do Power BI diretamente em seus aplicativos, sites ou portais. Essa funcionalidade de integração oferece uma maneira flexível e personalizada de compartilhar informações e insights com usuários finais, proporcionando uma experiência perfeita e integrada. Com as capacidades de embedding do Power BI, os desenvolvedores podem aproveitar as APIs e SDKs disponíveis para incorporar visualizações interativas em seus aplicativos existentes, personalizar a aparência e a funcionalidade, controlar a segurança e permissões de acesso aos dados e até mesmo habilitar recursos como filtragem dinâmica e interação com os dados subjacentes. Essa flexibilidade permite que as organizações integrem as poderosas capacidades analíticas do Power BI diretamente em seus fluxos de trabalho, fornecendo aos usuários acesso direto a informações relevantes e atualizadas, tudo dentro do contexto de sua própria aplicação.\nEntre outros conhecimentos, para trabalhar com embeddings, é necessário compreender:\n\nLinguagens de programação: Ter conhecimentos básicos de programação é fundamental para interagir com as APIs e SDKs do Power BI. Python, JavaScript e .NET são exemplos de linguagens comumente usadas.\nDesenvolvimento web: Familiaridade com desenvolvimento web é importante para incorporar e personalizar visualizações do Power BI. Isso inclui conhecimentos em HTML, CSS e JavaScript para integrar o código do Power BI em aplicativos e sites.\nAutenticação e segurança: Compreender os conceitos de autenticação e autorização é crucial para garantir a segurança dos dados. Isso envolve entender como autenticar usuários no Power BI e definir permissões de acesso adequadas.\nPower BI Desktop e serviço Power BI: Ter conhecimento sobre o Power BI Desktop e o serviço Power BI é essencial. Isso inclui habilidades em criação de relatórios, painéis e visualizações interativas, além de recursos de filtragem e interação.\nModelagem e transformação de dados: Noções básicas de modelagem e transformação de dados são úteis para preparar os dados antes de incorporá-los. Isso envolve limpeza, filtragem e organização dos dados para criar visualizações eficazes.\n\nNeste post, exploraremos a integração do Power BI com o Jupyter Notebook, combinando a flexibilidade do ambiente de codificação do Python com a riqueza de recursos do Power BI. Descobriremos como utilizar a biblioteca powerbiclient para trazer o poder do Power BI para dentro de um Jupyter Notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "href": "posts/p0003-powerbiclient/index.html#biblioteca-powerbiclient",
    "title": "Power BI no Jupyter!",
    "section": "Biblioteca powerbiclient",
    "text": "Biblioteca powerbiclient\nA biblioteca powerbiclient é uma ferramenta poderosa que permite interagir com o serviço do Power BI diretamente por meio de APIs. Essa biblioteca, desenvolvida pela Microsoft, fornece uma interface de programação fácil de usar para criar, publicar, atualizar e gerenciar relatórios, dashboards e conjuntos de dados no Power BI. Com o powerbiclient, os desenvolvedores podem automatizar tarefas, extrair informações e integrar o Power BI a aplicativos, permitindo a criação de soluções personalizadas e aprimorando a capacidade de visualização e análise de dados. Essa biblioteca é uma excelente opção para aqueles que desejam aproveitar ao máximo o ecossistema do Power BI e incorporar suas funcionalidades em seus próprios fluxos de trabalho e aplicativos.\nDentre todas as possibilidades que esta biblioteca oferece, vamos focar em como carregar gráficos interativos em Power BI dentro do nosso notebook Jupyter. E vamos lá, sem demora!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "href": "posts/p0003-powerbiclient/index.html#preparando-o-ambiente",
    "title": "Power BI no Jupyter!",
    "section": "Preparando o ambiente",
    "text": "Preparando o ambiente\nComo sempre, o nosso primeiro passo é instalar as bibliotecas que estão faltando.\n$ pip install powerbiclient\n\nNosso próximo passo é inicializar o ambiente, chamando nossas bibliotecas.\n\n::: {#cell-11 .cell execution_count=4}\n``` {.python .cell-code}\nfrom powerbiclient import QuickVisualize, get_dataset_config, Report\nfrom powerbiclient.authentication import DeviceCodeLoginAuthentication\n\nimport pandas as pd\n:::\nDepois disso, vamos ao código de verdade!"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "href": "posts/p0003-powerbiclient/index.html#carregando-os-dados",
    "title": "Power BI no Jupyter!",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nA primeira tarefa, como em todo o trabalho de um cientista de dados, é carregar os dados em um DataFrame.\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "href": "posts/p0003-powerbiclient/index.html#autenticando-no-serviço-do-power-bi",
    "title": "Power BI no Jupyter!",
    "section": "Autenticando no Serviço do Power BI",
    "text": "Autenticando no Serviço do Power BI\nEm seguida, temos que fazer a autenticação no serviço do Power BI. O Power BI, como todos os aplicativos do Office 365, requer que estejamos autenticados para utiliza-los. Aqui, o processo é simplificado, mas ainda requerido. Esse modo é o mais simples, se estiver interessado em outras maneiras, dê uma olhada mais a fundo na documentação da Microsoft.\n\ndevice_auth = DeviceCodeLoginAuthentication()\n\nPerforming device flow authentication. Please follow the instructions below.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A8EL2Y8WJ to authenticate.\n\nDevice flow authentication successfully completed.\nYou are now logged in .\n\nThe result should be passed only to trusted code in your notebook."
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#visualizando",
    "href": "posts/p0003-powerbiclient/index.html#visualizando",
    "title": "Power BI no Jupyter!",
    "section": "Visualizando!",
    "text": "Visualizando!\nO próximo passo é plotar o gráfico usando o Power BI. Neste post vamos explorar a classe QuickVisualize que nos entregará um tipo de sumário dos nossos dados, como em uma Análise Exploratória de Dados. Para isso, enviamos nosso DataFrame, o objeto de autenticação e chamamos a função PBI_visualize.\n\n# Create a Power BI report from your data\nPBI_visualize = QuickVisualize(get_dataset_config(pokemons), auth=device_auth)\n\n# Render the new report\nPBI_visualize"
  },
  {
    "objectID": "posts/p0003-powerbiclient/index.html#finalizando",
    "href": "posts/p0003-powerbiclient/index.html#finalizando",
    "title": "Power BI no Jupyter!",
    "section": "Finalizando",
    "text": "Finalizando\nE desta forma, conseguimos trazer o Power BI e todo o seu poder para dentro do nosso notebook! E essa é apenas uma das formas que temos para trabalhar com Power BI dentro do notebook! Se você quiser aprender mais, não deixe de acessar a documentação da biblioteca powerbiclient em Power BI - Jupyter."
  },
  {
    "objectID": "posts/data-106/index.html",
    "href": "posts/data-106/index.html",
    "title": "Parte 05 - Iniciando com Seaborn",
    "section": "",
    "text": "Olá Devs!\nBem-vindo de volta! Na Parte 04 aprendemos como utilizar a biblioteca Pandas para carregar no notebook os dados que pretendemos trabalhar. Também aprendemos a utilizar algumas funções mais avançadas que nos permitem filtrar ou agregar informações em nosso conjunto de dados.\nA linguagem Python possui inúmeras bibliotecas não-nativas para gerar visualizações de dados. A biblioteca mais famosa e que muitas vezes serve de base para as outras se chama matplotlib. Por uma questão de conveniência e facilidade de uso, utilizaremos no curso a biblioteca seaborn.\nAs principais vantagens do seaborn são: - interface alto nível - existe uma função para cada tipo de gráfico, e permite fazer chaining de chamadas - facilidade de configuração - possui objetos de configuração globais e locais (em cada gráfico).\nNesta aula, vamos passar pelo processo de instalação e utilização dos tipos de gráficos mais básicos no seaborn."
  },
  {
    "objectID": "posts/data-106/index.html#instalação",
    "href": "posts/data-106/index.html#instalação",
    "title": "Parte 05 - Iniciando com Seaborn",
    "section": "Instalação",
    "text": "Instalação\nAssim como no artigo de Pandas, tenho uma boa notícia: no Google Colab o seaborn já vem instalado no nosso ambiente! Mas caso você esteja também se aventurando em fazer este curso no VS Code, PyCharm, Sublime ou até mesmo Notepad, o comando para instalar a biblioteca seaborn é o seguinte:\n(venv) $ pip install seaborn"
  },
  {
    "objectID": "posts/data-106/index.html#visualizando-com-seaborn",
    "href": "posts/data-106/index.html#visualizando-com-seaborn",
    "title": "Parte 05 - Iniciando com Seaborn",
    "section": "Visualizando com seaborn",
    "text": "Visualizando com seaborn\nAgora vamos ver na prática como o seaborn funciona. Neste artigo, veremos os tipos de gráficos mais comuns, indicando sua utilização e dando exemplos. Se você quiser mais detalhes, sempre pode consultar a documentação do seaborn em Seaborn Docs.\nHoje vamos gerar gráficos de barras ou colunas, baseados nas funções: countplot() e barplot(). Nas partes seguintes do artigo, iremos explorar outros tipos de gráficos, que são um pouco mais avançados.\n\nInicializando o seaborn\nComo toda a biblioteca python, precisamos indicar em nosso script quando queremos utilizar a biblioteca seaborn. Fazemos isso através do comando import.\n\nimport seaborn as sns\n\nDa mesma forma que falamos na aula de Pandas, o import do seaborn geralmente utiliza o apelido de sns, que pode ser encontrado em muitos artigos na internet. Vamos manter essa convenção para que vocês se acostumem ao procurar material de apoio.\nPor falar de Pandas, precisamos carregar ele também, afinal, precisamos dos nossos dados!\n\nimport pandas as pd\n\n\n\nCarregando os dados\nE vamos continuar nossas demonstrações com o conjunto de dados de pokemons:\n\npokemons = pd.read_csv('pokemons.csv')\n\n\n\nGráficos de barras ou colunas\nUm gráfico de barras ou colunas é uma representação gráfica de dados em que as informações são exibidas em barras verticais ou horizontais de comprimentos variáveis. Cada barra ou coluna representa uma categoria ou conjunto de dados diferentes, e a altura ou comprimento da barra é proporcional à quantidade ou valor correspondente.\nOs gráficos de barras são frequentemente usados para comparar quantidades ou valores entre diferentes categorias, enquanto os gráficos de colunas são mais adequados para exibir uma série temporal de dados. Ambos os tipos de gráficos podem ser usados para exibir dados discretos ou contínuos, e podem ser personalizados para incluir rótulos, legendas e outras informações relevantes. Os gráficos de barras e colunas são comumente usados em relatórios, apresentações e em análises de dados.\n\ncountplot()\nA primeira função que iremos aprender a utilizar é a função countplot(). Ela é indicada quando queremos realizar a contagem de uma categoria, ou seja, escolhemos um campo categórico em nossos dados e indicamos quantas ocorrências encontramos em nossos dados. Nos próximos blocos de código, veremos vários exemplos de como fazer isso.\n\n# contando o número de pokemons por geração\n\nplot = sns.countplot(pokemons, x=\"Generation\")\n\nplot\n\n\n\n\n\n\n\n\nOlha só, parece bem fácil, não? Está ali o nosso gráfico, com o número de pokemons por geração. No entanto, temos algumas melhorias que podem ser feitas:\n\nadicionar um título\ncorrigir os títulos dos eixos.\n\nPara realizar esses ajustes, vamos precisar de uma nova biblioteca, chamada matplotlib. Na verdade, essa biblioteca é a base de muitas outras bibliotecas de visualização, tais como seaborn, plotly e por aí vai.\nNeste cenário, matplotlib é utilizada para preparar o que chamamos de área de plotagem, que é o retângulo branco onde nosso gráfico será exibido.\n\nimport matplotlib.pyplot as plt\n# contando o número de pokemons por geração\n\nsns.countplot(pokemons, x=\"Generation\")\nplt.title('Pokemons por Geração') # título do gráfico\nplt.xlabel('Geração') # eixo X\nplt.ylabel('Número de Pokemons') # eixo Y\n\nplt.show() # mostra o gráfico\n\n\n\n\n\n\n\n\nAgora sim, temos um gráfico bem desenhado!\nEste gráfico é um Gráfico de Colunas, de acordo com as definições, pois as barras são verticais. Para transformar em um gráfico de barras, na função countplot() precisamos apenas trocar o x pelo y no segundo parâmetro, além de trocar os títulos na funções xlabel e ylabel. Vamos ver como fica:\n\nsns.countplot(pokemons, y=\"Generation\")\nplt.title('Pokemons por Geração') # título do gráfico\nplt.ylabel('Geração') # eixo Y\nplt.xlabel('Número de Pokemons') # eixo X\n\nplt.show() # mostra o gráfico\n\n\n\n\n\n\n\n\n\n\nbarplot()\nNos gráficos utilizando countplot() podemos apenas exibir a contagem de elementos para cada valor categórico da coluna que escolhemos. Não temos como, por exemplo, apresentar a média dos pontos de vida dos pokemons. Para isso, precisamos de mais controle sobre os dados que iremos mostrar. Entra em cena a função barplot():\n\nimport numpy as np\n\nsns.barplot(pokemons, x='Generation', y='HP', estimator=np.mean)\nplt.title('Média dos pontos de vida de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de vida')\n\nText(0, 0.5, 'Média dos pontos de vida')\n\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico. Algumas observações:\n\nPrecisamos trazer mais uma biblioteca para o nosso script, a biblioteca numpy, para podermos especificar que nosso gráfico de barras iria calcular a média do campo especificado\nAlém de definirmos o eixo X, definimos também o eixo Y e qual o tipo de cálculo a ser realizado\nCada barra tem um risco preto. Esse risco se refere a margem de erro. Se você não quiser ver essa informação, apenas adicionamos mais um parâmetro a função e ela desaparece.\n\n\nsns.barplot(pokemons, x='Generation', y='HP', estimator=np.mean, errwidth=0)\nplt.title('Média dos pontos de vida de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de vida')\n\n/tmp/ipykernel_227049/3891424301.py:1: FutureWarning: \n\nThe `errwidth` parameter is deprecated. And will be removed in v0.15.0. Pass `err_kws={'linewidth': 0}` instead.\n\n  sns.barplot(pokemons, x='Generation', y='HP', estimator=np.mean, errwidth=0)\n\n\nText(0, 0.5, 'Média dos pontos de vida')\n\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico de colunas. Outra coisa que podemos explorar é ter mais de uma métrica sendo analisada pela categoria selecionada. Por exemplo, vamos analisar a média dos pontos de ataque e defesa através das gerações.\n\n# Precisamos fazer ajustes no conjunto de dados\npokemons_sb = pokemons[['Generation','Att','Def']] # Primeiro selecionamos apenas as colunas que queremos trabalhar\ntidy = pokemons_sb.melt(id_vars='Generation').rename(columns=str.title)\n# A função melt()  recebe como parâmetro a coluna categórica e pega todas as colunas de métricas e transformam em uma \n# única coluna, em uma nova linha para cada coluna. Para identificar cada nova linha, outra coluna é adicionada, com\n# a descrição. Ou seja, realizamos uma transposição do nosso conjunto de dados.\n\n# Gráfico\nsns.barplot(tidy, x='Generation', y='Value', hue='Variable', estimator=np.mean, err_kws={\"linewidth\": 0})\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nNo código acima, a parte que faz a plotagem do gráfico continua a mesma, mas temos as duas linhas iniciais que servem para fazer um ajuste nos dados. Quanto mais complexo os gráficos que queremos plotar, mais necessário se torna entender como formatar os dados. Então, aprenda principalmente Pandas e SQL e mantenha todos os seus gráficos fáceis de plotar!\nAgora, vamos ver mais um subtipo de gráfico de barras ou colunas: o gráfico de colunas “stacked” ou empilhadas.\n\npokemons_gb = pokemons.groupby(['Generation'])[['Generation','Att', 'Def']].mean()\n\nplt.bar(pokemons_gb['Generation'], pokemons_gb['Att'], color='blue', edgecolor='white', width=1)\nplt.bar(pokemons_gb['Generation'], pokemons_gb['Def'], bottom=pokemons_gb['Att'], color='red', edgecolor='white', width=1)\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\n\nplt.show()\n\n\n\n\n\n\n\n\nNesta versão de stacked bar chart, como podemos perceber pelo código, foi necessária uma nova transformação nos dados, desta vez com as funções groupby() e mean(). Além disso, desenhamos as barras com o matplotlib direto, não chegamos a utilizar o seaborn.\nA transformação nos dados foi necessária para agruparmos os valores de ataque e defensa por geração e calcular a média. A opção de utilizar matplotlib direto produziu um gráfico com a aparência bem diferente, e sinceramente, feia se comparada aos outros gráficos que criamos. E existe uma alternativa! Podemos usar o seaborn através do próprio DataFrame, garantindo uma aparência alinhada com o que geramos anteriormente.\n\npokemons_gb.plot(kind='bar', x='Generation', stacked=True)\nplt.title('Média dos pontos de ataque e defesa de Pokemons por Geração')\nplt.xlabel('Geração')\nplt.ylabel('Média dos pontos de ataque e defesa')\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "posts/data-106/index.html#concluindo",
    "href": "posts/data-106/index.html#concluindo",
    "title": "Parte 05 - Iniciando com Seaborn",
    "section": "Concluindo",
    "text": "Concluindo\nConseguimos ver como gerar um dos gráficos mais utilizados na área de Visualização de Dados, o gráfico de barras e suas variações utilizando a biblioteca seaborn. Também aprendemos que para gerar certos tipos de gráficos, é necessário fazer algumas transformações nos dados, o que conecta este artigo ao de Pandas.\nSe você quiser aprender mais sobre seaborn, seguem alguns links: - Documentação oficial do Seaborn em português: A documentação oficial do Seaborn tem uma versão em português que fornece uma visão geral da biblioteca, exemplos de uso, informações sobre os diferentes tipos de gráficos, e muito mais - Tutorial de visualização de dados com Python e Seaborn: Este tutorial do Towards Data Science fornece uma introdução prática à visualização de dados com Seaborn, incluindo exemplos de código e gráficos. O tutorial abrange tópicos como gráficos de barras, gráficos de dispersão, heatmap e muito mais.\nUm abraço e até mais,\nWalter."
  },
  {
    "objectID": "posts/data-102/index.html",
    "href": "posts/data-102/index.html",
    "title": "Parte 02 - Google Colab",
    "section": "",
    "text": "Olá Devs!\nHoje iremos conhecer o Google Colab, e entender como utiliza-lo em nossas tarefas de Análise e Visualização de Dados.\nVamos lá?\n\nO que é o Google Colab?\nO Google Colab é uma plataforma de computação em nuvem gratuita baseada no Jupyter Notebook. Ele permite que os usuários criem e compartilhem documentos que contenham código executável, equações, visualizações e texto explicativo. O Google Colab oferece suporte a várias linguagens de programação populares, incluindo Python, JavaScript e Swift.\nIsto significa que podemos intercalar blocos de texto, imagens e código em um mesmo documento. Como um Cientista de Dados, você vai utilizar muito este recurso tanto nos momentos em que você está trabalhando os dados e construindo o modelo quanto naquele momento em que você precisa comunicar seus achados e resultados para outros cientistas e para o seu público alvo.\n\n\nComo acessamos o Google Colab?\nPara acessar o Google Colab, você precisa se conectar com uma conta do Google e acessar o site colab.research.google.com. Você verá então, a seguinte tela:\n\n\n\nTela Inicial do Colab\n\n\nComo você pode ver, a primeira atividade que ele sugere é abrir exemplos ou, no meu caso, alguns arquivos mais recentes. O Colab é integrado com o Google Drive, então seus arquivos, que terão sempre a extensão .ipynb estarão sempre salvos lá no seu Drive, em uma pasta específica.\n\n\nIniciando um novo notebook!\nVamos iniciar? Clique no link “new notebook”. Você deve ver sua tela assim:\n\n\n\nNovo Notebook\n\n\nNeste momento, vamos destacar três áreas da tela:\n\nOnde fica o nome do notebook. Você pode modificar quando quiser\nSistema de arquivos do notebook. Quando iniciamos um novo notebook, temos um sistema de arquivos virtual, onde podemos subir arquivos que serão utilizados durante a execução do código. Esses arquivos são apagados quando o notebook não está ativo.\nEsta é uma célula. Um notebook é feito de um conjunto de células que são executadas sequencialmente. As células podem ser de dois tipos: células de código ou células de texto. A célula que estamos marcando é especificamente uma célula de código, pois tem o botão de execução bem a esquerda.\n\n\nCélulas de Texto\nAs células de texto nos permitem escrever texto no formato Markdown, que facilita bastante a formatação. Se quiser aprender mais sobre Markdown, clique aqui. Veja alguns exemplos:\n\n\n\nExemplos de célula de texto\n\n\n\n\nCélulas de Código\nCélulas de código, como o próprio nome diz, servem para escrever código que será executado. Podemos usar algumas linguagens, sendo que a mais comum é Python. Cada célula, ao ser executada, pode imprimir o resultado de sua execução logo abaixo. Veja um exemplo abaixo:\n\nimport pandas as pd\nimport json\nimport requests\n\nresponse = requests.get(\"https://dummyjson.com/products\")\njson.dump(json.loads(response.text)['products'], open('products.json','w'))\nraw_data = open('products.json','r')\n# .load(\"https://dummyjson.com/products\")\ndf = pd.read_json(raw_data)\n\ndf\n\n\n\n\n\n\n\n\nid\ntitle\ndescription\nprice\ndiscountPercentage\nrating\nstock\nbrand\ncategory\nthumbnail\nimages\n\n\n\n\n0\n1\niPhone 9\nAn apple mobile which is nothing like apple\n549\n12.96\n4.69\n94\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/1/thumbn...\n[https://i.dummyjson.com/data/products/1/1.jpg...\n\n\n1\n2\niPhone X\nSIM-Free, Model A19211 6.5-inch Super Retina H...\n899\n17.94\n4.44\n34\nApple\nsmartphones\nhttps://i.dummyjson.com/data/products/2/thumbn...\n[https://i.dummyjson.com/data/products/2/1.jpg...\n\n\n2\n3\nSamsung Universe 9\nSamsung's new variant which goes beyond Galaxy...\n1249\n15.46\n4.09\n36\nSamsung\nsmartphones\nhttps://i.dummyjson.com/data/products/3/thumbn...\n[https://i.dummyjson.com/data/products/3/1.jpg]\n\n\n3\n4\nOPPOF19\nOPPO F19 is officially announced on April 2021.\n280\n17.91\n4.30\n123\nOPPO\nsmartphones\nhttps://i.dummyjson.com/data/products/4/thumbn...\n[https://i.dummyjson.com/data/products/4/1.jpg...\n\n\n4\n5\nHuawei P30\nHuawei’s re-badged P30 Pro New Edition was off...\n499\n10.58\n4.09\n32\nHuawei\nsmartphones\nhttps://i.dummyjson.com/data/products/5/thumbn...\n[https://i.dummyjson.com/data/products/5/1.jpg...\n\n\n5\n6\nMacBook Pro\nMacBook Pro 2021 with mini-LED display may lau...\n1749\n11.02\n4.57\n83\nApple\nlaptops\nhttps://i.dummyjson.com/data/products/6/thumbn...\n[https://i.dummyjson.com/data/products/6/1.png...\n\n\n6\n7\nSamsung Galaxy Book\nSamsung Galaxy Book S (2020) Laptop With Intel...\n1499\n4.15\n4.25\n50\nSamsung\nlaptops\nhttps://i.dummyjson.com/data/products/7/thumbn...\n[https://i.dummyjson.com/data/products/7/1.jpg...\n\n\n7\n8\nMicrosoft Surface Laptop 4\nStyle and speed. Stand out on HD video calls b...\n1499\n10.23\n4.43\n68\nMicrosoft Surface\nlaptops\nhttps://i.dummyjson.com/data/products/8/thumbn...\n[https://i.dummyjson.com/data/products/8/1.jpg...\n\n\n8\n9\nInfinix INBOOK\nInfinix Inbook X1 Ci3 10th 8GB 256GB 14 Win10 ...\n1099\n11.83\n4.54\n96\nInfinix\nlaptops\nhttps://i.dummyjson.com/data/products/9/thumbn...\n[https://i.dummyjson.com/data/products/9/1.jpg...\n\n\n9\n10\nHP Pavilion 15-DK1056WM\nHP Pavilion 15-DK1056WM Gaming Laptop 10th Gen...\n1099\n6.18\n4.43\n89\nHP Pavilion\nlaptops\nhttps://i.dummyjson.com/data/products/10/thumb...\n[https://i.dummyjson.com/data/products/10/1.jp...\n\n\n10\n11\nperfume Oil\nMega Discount, Impression of Acqua Di Gio by G...\n13\n8.40\n4.26\n65\nImpression of Acqua Di Gio\nfragrances\nhttps://i.dummyjson.com/data/products/11/thumb...\n[https://i.dummyjson.com/data/products/11/1.jp...\n\n\n11\n12\nBrown Perfume\nRoyal_Mirage Sport Brown Perfume for Men & Wom...\n40\n15.66\n4.00\n52\nRoyal_Mirage\nfragrances\nhttps://i.dummyjson.com/data/products/12/thumb...\n[https://i.dummyjson.com/data/products/12/1.jp...\n\n\n12\n13\nFog Scent Xpressio Perfume\nProduct details of Best Fog Scent Xpressio Per...\n13\n8.14\n4.59\n61\nFog Scent Xpressio\nfragrances\nhttps://i.dummyjson.com/data/products/13/thumb...\n[https://i.dummyjson.com/data/products/13/1.jp...\n\n\n13\n14\nNon-Alcoholic Concentrated Perfume Oil\nOriginal Al Munakh® by Mahal Al Musk | Our Imp...\n120\n15.60\n4.21\n114\nAl Munakh\nfragrances\nhttps://i.dummyjson.com/data/products/14/thumb...\n[https://i.dummyjson.com/data/products/14/1.jp...\n\n\n14\n15\nEau De Perfume Spray\nGenuine Al-Rehab spray perfume from UAE/Saudi...\n30\n10.99\n4.70\n105\nLord - Al-Rehab\nfragrances\nhttps://i.dummyjson.com/data/products/15/thumb...\n[https://i.dummyjson.com/data/products/15/1.jp...\n\n\n15\n16\nHyaluronic Acid Serum\nL'OrÃ©al Paris introduces Hyaluron Expert Repl...\n19\n13.31\n4.83\n110\nL'Oreal Paris\nskincare\nhttps://i.dummyjson.com/data/products/16/thumb...\n[https://i.dummyjson.com/data/products/16/1.pn...\n\n\n16\n17\nTree Oil 30ml\nTea tree oil contains a number of compounds, i...\n12\n4.09\n4.52\n78\nHemani Tea\nskincare\nhttps://i.dummyjson.com/data/products/17/thumb...\n[https://i.dummyjson.com/data/products/17/1.jp...\n\n\n17\n18\nOil Free Moisturizer 100ml\nDermive Oil Free Moisturizer with SPF 20 is sp...\n40\n13.10\n4.56\n88\nDermive\nskincare\nhttps://i.dummyjson.com/data/products/18/thumb...\n[https://i.dummyjson.com/data/products/18/1.jp...\n\n\n18\n19\nSkin Beauty Serum.\nProduct name: rorec collagen hyaluronic acid w...\n46\n10.68\n4.42\n54\nROREC White Rice\nskincare\nhttps://i.dummyjson.com/data/products/19/thumb...\n[https://i.dummyjson.com/data/products/19/1.jp...\n\n\n19\n20\nFreckle Treatment Cream- 15gm\nFair & Clear is Pakistan's only pure Freckle c...\n70\n16.99\n4.06\n140\nFair & Clear\nskincare\nhttps://i.dummyjson.com/data/products/20/thumb...\n[https://i.dummyjson.com/data/products/20/1.jp...\n\n\n20\n21\n- Daal Masoor 500 grams\nFine quality Branded Product Keep in a cool an...\n20\n4.81\n4.44\n133\nSaaf & Khaas\ngroceries\nhttps://i.dummyjson.com/data/products/21/thumb...\n[https://i.dummyjson.com/data/products/21/1.pn...\n\n\n21\n22\nElbow Macaroni - 400 gm\nProduct details of Bake Parlor Big Elbow Macar...\n14\n15.58\n4.57\n146\nBake Parlor Big\ngroceries\nhttps://i.dummyjson.com/data/products/22/thumb...\n[https://i.dummyjson.com/data/products/22/1.jp...\n\n\n22\n23\nOrange Essence Food Flavou\nSpecifications of Orange Essence Food Flavour ...\n14\n8.04\n4.85\n26\nBaking Food Items\ngroceries\nhttps://i.dummyjson.com/data/products/23/thumb...\n[https://i.dummyjson.com/data/products/23/1.jp...\n\n\n23\n24\ncereals muesli fruit nuts\noriginal fauji cereal muesli 250gm box pack or...\n46\n16.80\n4.94\n113\nfauji\ngroceries\nhttps://i.dummyjson.com/data/products/24/thumb...\n[https://i.dummyjson.com/data/products/24/1.jp...\n\n\n24\n25\nGulab Powder 50 Gram\nDry Rose Flower Powder Gulab Powder 50 Gram • ...\n70\n13.58\n4.87\n47\nDry Rose\ngroceries\nhttps://i.dummyjson.com/data/products/25/thumb...\n[https://i.dummyjson.com/data/products/25/1.pn...\n\n\n25\n26\nPlant Hanger For Home\nBoho Decor Plant Hanger For Home Wall Decorati...\n41\n17.86\n4.08\n131\nBoho Decor\nhome-decoration\nhttps://i.dummyjson.com/data/products/26/thumb...\n[https://i.dummyjson.com/data/products/26/1.jp...\n\n\n26\n27\nFlying Wooden Bird\nPackage Include 6 Birds with Adhesive Tape Sha...\n51\n15.58\n4.41\n17\nFlying Wooden\nhome-decoration\nhttps://i.dummyjson.com/data/products/27/thumb...\n[https://i.dummyjson.com/data/products/27/1.jp...\n\n\n27\n28\n3D Embellishment Art Lamp\n3D led lamp sticker Wall sticker 3d wall art l...\n20\n16.49\n4.82\n54\nLED Lights\nhome-decoration\nhttps://i.dummyjson.com/data/products/28/thumb...\n[https://i.dummyjson.com/data/products/28/1.jp...\n\n\n28\n29\nHandcraft Chinese style\nHandcraft Chinese style art luxury palace hote...\n60\n15.34\n4.44\n7\nluxury palace\nhome-decoration\nhttps://i.dummyjson.com/data/products/29/thumb...\n[https://i.dummyjson.com/data/products/29/1.jp...\n\n\n29\n30\nKey Holder\nAttractive DesignMetallic materialFour key hoo...\n30\n2.92\n4.92\n54\nGolden\nhome-decoration\nhttps://i.dummyjson.com/data/products/30/thumb...\n[https://i.dummyjson.com/data/products/30/1.jp...\n\n\n\n\n\n\n\nEsta célula, se executada, irá carregar dados de um site, salvar um arquivo e carrega-lo em um DataFrame que depois será impresso na área de resultados.\n\n\n\nUtilizando um notebook\nOs exemplos acima são bons para mostrar cada parte separadamente, mas vamos a um exemplo que irá ilustrar a utilização típica destes blocos.\n\nExemplo\nDigamos que você precisa entregar um relatório para o seu chefe sobre quais são os primeiros 1000 números primos. Ele também solicita que você explique o que são números primos e como descobrir se um número é primo ou não.\nEm um cenário tradicional de programação, provavelmente se faria a entrega de pelo menos dois arquivos: um documento do word, por exemplo, com a parte descritiva e um arquivo de código-fonte com o código. Como o arquivo de código-fonte não guarda o resultado da execução, é muito provável que este resultado fosse adicionado ao documento do word, ou quem sabe, disponibilizado em um terceiro arquivo.\nDá um certo trabalho preparar tudo… Além precisar de um computador com Word e com um editor de código-fonte para fazer todo o relatório. Mas com o Google Colab, você pode fazer tudo em um único lugar: um notebook pode ser editado de qualquer lugar, através do browser!\nVeja o resultado abaixo:\n\n\n\nNotebook completo\n\n\nÉ bem interessante, não é mesmo? Tudo em um único documento, que eu posso compartilhar com outras pessoas, sem nenhuma complicação. E o melhor, quem abre este notebook, pode executar as partes que são código, quando bem quiserem, sem depender de você para atualizar os resultados.\n\n\n\nFinalizando\nEspero que você tenha gostado de aprender um pouco sobre o ambiente de desenvolvimento que iremos utilizar neste curso. Ao longo do curso, utilizaremos recursos mais avançados, então não perca a oportunidade de aprender mais sobre o Google Colab com estes links abaixo:\n\nO que é Google Colab\nGoogle Colaboratory - Hashtag Treinamentos\nVantagens de usar o Google Colab\n\n\n\n\n\n\n\nNote\n\n\n\nOs artigos citado acima e o conteúdo apresentado neste artigo não são de maneira nenhuma uma revisão extensiva do Google Colab, apresentamos apenas o necessário para você andar com seus próprios pés e no seu ritmo!\n\n\nUm abraço, e até a próxima!\nWalter."
  },
  {
    "objectID": "posts/data-101/index.html",
    "href": "posts/data-101/index.html",
    "title": "Parte 01 - Teoria de Visualização de Dados",
    "section": "",
    "text": "Olá Devs!\nNa primeira parte desta série, vamos aprender um pouco de teoria sobre Visualização e Ciência de Dados, com o objetivo de compreendermos a importância da Visualização de Dados dentro da Ciência de Dados.\n\nO que é Ciência de Dados\nA ciência de dados é uma disciplina que usa habilidades matemáticas e técnicas avançadas de análise de dados para transformar grandes quantidades de informações em insights úteis. Ela é usada em diversos setores para tomada de decisão informada e resolução de problemas complexos.\nCiência de dados é como ser um detetive super nerd que desvenda mistérios escondidos nos dados. Os cientistas de dados mergulham em montanhas de informações, usando suas habilidades matemáticas e de programação para desvendar padrões ocultos e responder a perguntas importantes. Eles são os mestres em transformar dados bagunçados em conhecimento valioso, ajudando empresas e pesquisadores a tomar decisões informadas. É como ter um superpoder de números e algoritmos, só que sem a capa e a máscara.\n\n\nO Fluxo de Trabalho de Ciência de Dados\nO Ciclo de Vida de Ciência de Dados é a formalização das 6 etapas que os cientistas de dados trabalham a cada projeto para chegar ao final com o resultado solicitado pelo cliente, e podemos ver suas fases na imagem abaixo:\n\n\nFonte: blog.betrybe.com.br\n\n1 - Entendendo o problema - aqui é feito o processo de descoberta, onde o problema que o cliente deseja resolvido é devidamente explicado, quebrado em requisitos e os dados disponíveis (ou a falta deles) são disponibilizados.\n2 - Coleta de dados - nesta fase, os conjuntos de dados iniciais caso existam são validados e se determina que outras fontes podem ser usadas para obter ou enriquecer os dados. Também são escritos os primeiros códigos para realizar a busca e download dos dados.\n3 - Processamento de dados - nesta fase os dados são analisados e transformados para atender ao propósito de negócio. Também é a fase em que começa o processo de criação de modelos de machine learning.\n4 - Exploração de dados - esta fase é caracterizada principalmente por visualização de dados sendo utilizada para compreender os dados gerados pelo modelo. São utilizadas técnicas específicas para essa exploração e todas dependem primariamente do bom entendimento na criação de visualizações de dados.\n5 - Comunicação de resultados - esta fase também reconhecida por fazer uso extensivo de técnicas de visualização de dados aliadas a técnicas de story telling para mostrar ao cliente os resultados obtidos.\n6 - Feedback - na última fase deste ciclo, se coleta as impressões do cliente e se inicia (caso necessário) uma nova iteração do projeto, para o refinamento da solução apresentada e a possibilidade de trabalhar em novos requisitos.\n\n\nO que é Visualização de Dados???\n\n\nFonte: o autor\n\n\n\nTipos de Visualização\nExistem diversos tipos de visualizações disponíveis. Sua utilização está associada ao tipo de informação e ao objetivo que temos ao mostrar os dados.\n\n\nFonte: o autor\n\nQuanto a objetivos, as visualizações são utilizadas com as seguintes finalidades: - Comparar valores - Evidenciar a correlação entre valores (como os dois valores se comportam em conjunto) - Como um valor se distribui em relação a uma dimensão contínua (geralmente o tempo) - Como um valor se distribui especificamente em relação a posicionamento geográfico - Como um valor se distribui entre dimensões não continuas que formam partes de um todo; o quanto cada valor representa em relação a esse todo - Como um valor se comporta em relação tempo.\n\n\nTipos de Visualização X Objetivo de Comunicação\nAbaixo segue um diagrama com uma indicação de quais gráficos podem ser utilizados de acordo com o seu objetivo.\n\n\nFonte: o autor\n\n\n\nComo podemos criar Visualizações???\nAssim como existem diversos tipos de visualizações, existem diversas ferramentas. Abaixo, colocamos uma lista de ferramentas para visualização de dados: - Excel - Tableau - Power BI - Qlik - Looker (antes chamada de Google Data Studio) - Oracle Analytics - SAP Business Objects - Grafana - Kibana\nEstas ferramentas se caracterizam por uma interface de usuário totalmente voltada para a criação de visualizações. Se vocês estivessem em um curso de Análise de Dados, seriam nossa escolha para o curso, pois elas focam na modelagem dos dados e criação das visualizações. Mas vocês estão em um curso para iniciarem na carreira de Cientistas de Dados, certo?\n\nEntão, como um Cientista de Dados cria visualizações???\nUm Cientista de Dados utiliza a Visualização de Dados de duas formas: 1) Como uma ferramenta de exploração dos dados, durante a fase em que estão procurando respostas 2) Como uma ferramenta de comunicação, para divulgar resultados\nConsiderando essas duas necessidades, embora o Cientista de Dados pudesse utilizar ferramentas como as citadas anteriormente, a verdade é que ele precisa de uma ferramenta que consiga combinar o poder da programação, com visualização de dados e também com uma estrutura documental organizada para compartilhamento de informação.\nPor isso, iremos utilizar uma tecnologia diferente para aprender visualização de dados: vamos aprender a criar visualizações de forma programática, ou seja, vamos criar visualizações utilizando programas escritos em Python.\n\n\nPorquê vamos fazer isso?\nPor alguns motivos:\n\nComo cientistas de dados, a maneira mais comum de entregar os resultados do seu trabalho, além de apresentações em powerpoint é através de notebooks interativos, como o Google Colab, ou o Jupyter. São ferramentas que ajudam muito no desenvolvimento de um story telling orientado a divulgação dos resultados\nAtualmente Python é a linguagem a se aprender na carreira de Cientista de Dados. Outras linguagens como R, Julia e até Java também são utilizadas, mas por enquanto, Python é a preferida\nAs bibliotecas de visualização em Python são muito flexíveis e poderosas, inclusive são utilizadas por algumas das ferramentas citadas acima\n\n\n\n\n\n\n\nNote\n\n\n\nEntão, agora que toda a teoria necessária está explicada, bora trabalhar??? Na Parte 02, iremos aprender sobre o Google Colab, a ferramenta que escolhemos para conduzir o restante desta série!\n\n\nUm abraço, e até a próxima!\nWalter."
  },
  {
    "objectID": "posts/data-103/index.html",
    "href": "posts/data-103/index.html",
    "title": "Parte 03 - Formatos de Dados",
    "section": "",
    "text": "Olá Devs!\nNeste artigo, vamos aprender um pouco mais sobre os formatos utilizados para armazenar os dados que nossas visualizações irão consumir.\n\nFontes de dados e seus formatos\nPara realizarmos nossas tarefas como Cientistas de Dados, é necessário que acessemos aquilo que nos é mais caro, o nosso combustível: os dados.\nEstes dados vem das mais diversas fontes: websites, dispositivos IoT, bancos de dados, documentos, … Estas diferentes fontes significam que os dados possuem diferentes formatos, e uma de nossas tarefas é transformar este dado em um formato com o qual seja possível trabalhar e gerar os resultados esperados.\nDentro da área de Ciência da Computação, o formato mais utilizado para servir como base para o processamento de informação é o formato tabular.\n\nFormato Tabular\nO formato tabular é utilizado para descrever uma estrutura de dados organizada em linhas e colunas, formando uma tabela. É um formato muito utilizado em bancos de dados relacionais e em arquivos CSV (Comma-Separated Values), onde cada linha representa um registro ou observação e cada coluna representa uma variável ou campo. Esse formato é muito útil para representar dados estruturados de forma clara e organizada, permitindo a fácil manipulação e análise dos dados.\nAbaixo, temos um exemplo prático de como podemos utilizar Python para carregar um arquivo CSV em nosso notebook.\n\nimport csv\n\n# Abre o arquivo CSV em modo leitura\nwith open('exemplo.csv', 'r') as arquivo_csv:\n    # Cria um objeto para ler o arquivo CSV\n    leitor_csv = csv.reader(arquivo_csv, delimiter=',')\n\n    # Percorre as linhas do arquivo CSV\n    for linha in leitor_csv:\n        print(linha)\n\n['Nome', 'Idade', 'Cidade']\n['Maria', '25', 'São Paulo']\n['João', '30', 'Rio de Janeiro']\n['Ana', '20', 'Belo Horizonte']\n['Andre', '23', 'Porto Alegre']\n\n\nNeste exemplo, utilizamos a função open para abrir o arquivo CSV em modo leitura e, em seguida, criamos um objeto csv.reader para ler o arquivo CSV. Utilizamos o parâmetro delimiter para indicar o caractere separador utilizado no arquivo CSV (no caso, a vírgula). Em seguida, utilizamos um loop for para percorrer as linhas do arquivo CSV e imprimir cada uma delas na tela.\nNote que, neste exemplo, o resultado é uma lista de listas, onde cada lista interna representa uma linha do arquivo CSV. Para manipular os dados, é necessário fazer a conversão manualmente para o formato desejado.\nE, apesar deste formato ser adequado ao processamento dos dados para visualização, ainda precisamos fazer alguns ajustes até chegar ao formato ideal.\n\n\n\nOtimizando o Formato Tabular\nO formato tabular padrão também pode ser referenciado pelo termo ‘Formato Largo’ (Wide format em inglês), por sua característica de organização em linhas e colunas, com a linha sendo uma observação e as colunas sendo as variáveis da observação. Isto pode ser percebido pelo formato que nossos código percorrem os arquivos ou selecionam a informação de um banco de dados: sempre pensando em extrair linhas que depois são usadas em algum tipo de processamento. Isso gera o que chamamos de overhead no processamento, porque por vezes precisamos apenas fazer o processamento de uma coluna de dados, mas somos obrigados a acessar todas as colunas para depois selecionar a coluna que queremos.\nPara resolver essa questão, foi criado um caso especial de formato tabular, o chamado ‘Formato Longo’ (Long format em inglês), onde a orientação da organização dos dados é colunas e linhas, ou seja, podemos acessar uma coluna individualmente, com todas as suas linhas.\n\n\n\nFormato Longo X Formato Largo\n\n\nEm Python e em muitas outras linguagens de programação que são utilizadas para Ciência de Dados, o formato tabular é representado por estruturas de dados especiais, chamadas de DataFrames e Series.\nMas antes de explicar em mais detalhes essas estruturas, vamos conhecer um pouco das suas origens.\n\n\nDicionários e Listas\nSe você já conhece o básico de Python, já aprendeu que temos os tipos de dados conhecidos como listas e dicionário de dados. Com estes tipos, podemos representar dados mais complexos, como uma sequência ou um objeto, que são compostos de vários tipos simples. Se você quiser aprender mais sobre listas e dicionários, vá para o final deste notebook.\nEm Python, a representação de dados no formato tabular, seja longo ou largo, passa pela combinação destes dois tipos de dados.\n\nRepresentação em Python do Formato Largo\nPara criar um objeto em Python que represente um conjunto de dados no Formato Largo, é necessário montar uma lista de dicionários.\n\ndados_largos = [\n    {\"codigo\": 1, \"nome\": \"Jose\"},\n    {\"codigo\": 2, \"nome\": \"Maria\"},\n    {\"codigo\": 3, \"nome\": \"Fernandez\"}\n]\n\nNeste objeto, temos uma lista que contém 3 elementos. Cada elemento é um dicionário com dois campos. Conforme explicamos anteriormente, no formato largo, para acessar o nome de uma pessoa, precisamos identificar em que linha ela está. Para identificar a linha, percorremos nossa lista. Para inspecionar o nome, recuperamos todo o dicionário que está naquela posição da lista.\n\n\nRepresentação em Python do Formato Longo\nPara criar um objeto em Python que represente um conjunto de dados no Formato Longo, é necessário montar um dicionário de listas.\n\ndados_longos = {\n                \"codigo\": [1,2,3], \n                \"nome\": [\"Jose\",\"Maria\",\"Fernandez\"]\n               }\n\nNeste objeto, temos o dicionário com seus campos, e cada campo é uma lista com os valores para cada linha.\n\n\nEntendendo a diferença\nVamos ver um exemplo prático para entender a diferença entre os dois. Acompanhe no código abaixo e leia os comentários.\n\n# Queremos saber o nome do usuário que está na segunda linha do nosso conjunto de dados.\n\n# Formato largo\nprint(dados_largos[1][\"nome\"]) # utilizamos o indice 1 porque em Python listas começam no indice 0\n\n# Formato longo\nprint(dados_longos[\"nome\"][1]) # apenas invertemos a referência - primeiro a coluna, depois a linha\n\nMaria\nMaria\n\n\nA diferença parece pouca, certo? Apenas invertemos como os indices são acessados, onde está a tal otimização?\nA otimização está no fato de que, ao acessar a linha de um dado no formato largo, estamos acessando todas as colunas de informação daquela linha.\n\nprint(dados_largos[1])\n\n{'codigo': 2, 'nome': 'Maria'}\n\n\nJá no formato longo, antes de especificar a linha, eu preciso referenciar a coluna, portanto, sempre terei apenas um valor.\n\nprint(dados_longos[\"nome\"][1])\n\nMaria\n\n\n\n\n\nDataFrames e Series\nO DataFrame e as Series são dois dos principais conceitos utilizados para trabalhar com dados em Python. Ambos estão presentes na biblioteca Pandas, que é uma das ferramentas mais usadas para análise de dados.\nO DataFrame é um objeto que tem como base o conceito de dicionário de listas, onde as listas são representadas por Series. O DataFrame adiciona uma série de funcionalidades ao dicionário de listas, simplificando a manipulação dos mesmos.\nExemplo de código:\n\nimport pandas as pd \ndf = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \nprint(df[2][2])\n\n9\n\n\nA Series é uma lista com superpoderes. Assim como o DataFrame, a Series acrescenta muitas facilidades para manipular a lista. Exemplo de código:\n\nimport pandas as pd \ns = pd.Series([1, 2, 3]) \nprint(s[2])\n\n3\n\n\nAlém do Pandas existem outras bibliotecas que utilizam esses conceitos para trabalhar com dados como NumPy (Numerical Python), SciPy (Scientific Python) e Scikit-learn (Machine Learning).\n\n\nFinalizando\nNeste artigo, aprendemos sobre os formatos de dados que podemos utilizar em nossas visualizações e conhecemos mais detalhes dos DataFrames e Series.\nAqui temos alguns links sobre o assunto: - Listas - Dicionários"
  },
  {
    "objectID": "posts/data-105/index.html",
    "href": "posts/data-105/index.html",
    "title": "Parte 04 - Pandas",
    "section": "",
    "text": "Olá Devs!\nSe você chegou até aqui, significa que já deve ter aprendido como carregar os dados no Google Colab utilizando as bibliotecas padrão do python. E deve ter percebido que a tarefa não é simples, e requer muitas linhas de código (Rapadura é doce mas não é mole não, diria o Yusuke Urameshi).\nJustamente com a intenção de simplificar o trabalho dos cientistas e engenheiros de dados é que a biblioteca Pandas foi criada. Com a biblioteca Pandas, todo o trabalho de manipulação dos dados fica simplificado, rápido e mais organizado."
  },
  {
    "objectID": "posts/data-105/index.html#instalando-pandas",
    "href": "posts/data-105/index.html#instalando-pandas",
    "title": "Parte 04 - Pandas",
    "section": "Instalando Pandas",
    "text": "Instalando Pandas\nTenho uma boa notícia: como estamos utilizando o Google Colab para nossas aulas, ele já vem instalado no nosso ambiente! Mas caso você esteja também se aventurando em fazer este curso no VS Code, PyCharm, Sublime ou até mesmo Notepad, o comando para instalar a biblioteca Pandas é o seguinte:\n(venv) $ pip install pandas\nEste comando irá instalar a biblioteca Pandas e todos as bibliotecas dependentes. É aconselhável que você crie um ambiente virtual para instalar as bibliotecas, mas isso é assunto para um outro dia."
  },
  {
    "objectID": "posts/data-105/index.html#utilizando-pandas",
    "href": "posts/data-105/index.html#utilizando-pandas",
    "title": "Parte 04 - Pandas",
    "section": "Utilizando Pandas",
    "text": "Utilizando Pandas\nIremos ver, passo a passo, como utilizar a biblioteca Pandas em nosso notebook Google Colab, passando pelos seus principais conceitos.\n\nCarregando Pandas no notebook\nA primeira coisa que devemos fazer é carregar a biblioteca em nosso notebook. Fazemos isso com o comando import.\n\nimport pandas as pd\n\n\n\n\n\n\n\nTip\n\n\n\nÉ considerado uma boa prática ao carregar a biblioteca sempre utilizar o alias pd. Observe que todos os artigos na internet utilizam essa mesma referência.\n\n\n\n\nCarregando os dados\nNa aula 3, aprendemos que uma maneira de carregar os dados em um notebook on Google Colab é a seguinte:\nimport csv\n\npokemons = {}\nwith open('pokemons.csv', 'r', encoding='utf-8') as arquivo:\n  dados = csv.DictReader(arquivo)\n\n  for pokemon in dados:\n    for key, value in pokemon.items():\n      pokemons.setdefault(key,[]).append(value)\nUtilizando pandas, isso será substituído por uma única linha:\n\npokemons = pd.read_csv('pokemons.csv')\n\nFicou bem mais fácil, não é mesmo? Da mesma forma, verificar o conteúdo que foi carregado também se simplifica - vai disso aqui:\nfor indice in range(0, 2):    # executa um loop dos dois primeiros elementos do array\n  print(pokemons[indice])     # imprime o elemento\npara isso aqui:\n\npokemons.head(2)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n45\n49\n49\n65\n65\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.7\n6.9\n14.1\n\n\n1\n2\nIvysaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n60\n62\n63\n80\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n13.0\n13.0\n\n\n\n\n2 rows × 44 columns\n\n\n\n\n\nMas não é só isso…\nOutra grande vantagem de se utilizar pandas é que temos a nossa disposição um grande número de opções para carregar dados. Além do read_csv, temos readers especializados: read_json, read_excel, e por aí vai… Aconselho a dar uma olhada no manual do pandas aqui.\n\n\nInspecionando os dados\nApós termos os dados carregados, a nossa próxima atividade é inspecionar os dados. Além do comando que vimos acima head(), que pode nos mostrar as primeiras linhas do DataFrame, temos outras funções, como:\n\ntail() - mostra as últimas linhas do DataFrame\nsample() - mostra linhas aleatórias do DataFrame\ndescribe() - mostra os valores de diversas medidas\ninfo() - mostra os campos do DataFrame com seus tipos\nshape - dá as dimensões (coluna, linha) do DataFrame\n\nVamos ver em detalhes cada uma destas funções.\n\nhead()\nEsta função lista as primeiras linhas de dados. O pârametro é opcional, o que fará com que a função liste 10 linhas de dados.\n\npokemons.head(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n0\n1\nBulbasaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n45\n49\n49\n65\n65\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.7\n6.9\n14.1\n\n\n1\n2\nIvysaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n60\n62\n63\n80\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n13.0\n13.0\n\n\n2\n3\nVenusaur\nGrass\nPoison\n['Chlorophyll', 'Overgrow']\n80\n82\n83\n100\n100\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n2.0\n100.0\n25.0\n\n\n3\n3\nMega Venusaur\nGrass\nPoison\n['Thick Fat']\n80\n100\n123\n122\n120\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n2.4\n155.5\n27.0\n\n\n4\n4\nCharmander\nFire\nNaN\n['Blaze', 'Solar Power']\n39\n52\n43\n60\n50\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n0.5\n0.5\n0.6\n8.5\n23.6\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\ntail()\nEsta função lista as últimas linhas de dados. O pârametro é opcional, o que fará com que a função liste 10 linhas de dados.\n\npokemons.tail(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n1027\n896\nGlastrier\nIce\nNaN\n['Chilling Neigh']\n100\n145\n130\n65\n110\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n2.0\n1.0\n2.2\n800.0\n165.3\n\n\n1028\n897\nSpectrier\nGhost\nNaN\n['Grim Neigh']\n100\n65\n60\n145\n80\n...\n0.5\n1.0\n2.0\n1.0\n2.0\n1.0\n1.0\n2.0\n44.5\n11.1\n\n\n1029\n898\nCalyrex\nPsychic\nGrass\n['Unnerve']\n100\n80\n80\n80\n80\n...\n4.0\n1.0\n2.0\n1.0\n2.0\n1.0\n1.0\n1.1\n7.7\n6.4\n\n\n1030\n898\nCalyrex Ice Rider\nPsychic\nIce\n['As One']\n100\n165\n150\n85\n130\n...\n2.0\n2.0\n2.0\n1.0\n2.0\n2.0\n1.0\n2.4\n809.1\n140.5\n\n\n1031\n898\nCalyrex Shadow Rider\nPsychic\nGhost\n['As One']\n100\n85\n80\n165\n100\n...\n1.0\n1.0\n4.0\n1.0\n4.0\n1.0\n1.0\n2.4\n53.6\n9.3\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\nsample()\nEnquanto head() e tail() mostra o início e o fim do conjunto de dados, o sample() traz linhas aleatórias do conjunto, o que pode ser bem interessante.\n\npokemons.sample(5)\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n519\n438\nBonsly\nRock\nNaN\n['Rattled', 'Rock Head', 'Sturdy']\n50\n80\n95\n10\n45\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n2.0\n1.0\n0.5\n15.0\n60.0\n\n\n635\n542\nLeavanny\nBug\nGrass\n['Chlorophyll', 'Overcoat', 'Swarm']\n75\n103\n80\n70\n80\n...\n2.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.2\n20.5\n14.2\n\n\n405\n340\nWhiscash\nWater\nGround\n['Anticipation', 'Hydration', 'Oblivious']\n110\n78\n73\n76\n71\n...\n1.0\n0.5\n1.0\n1.0\n1.0\n0.5\n1.0\n0.9\n23.6\n29.1\n\n\n502\n422\nShellos\nWater\nNaN\n['Sand Force', 'Sticky Hold', 'Storm Drain']\n76\n48\n48\n57\n62\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n0.3\n6.3\n70.0\n\n\n976\n849\nToxtricity\nElectric\nPoison\n['Plus', 'Punk Rock', 'Technician']\n75\n98\n70\n114\n70\n...\n0.5\n1.0\n1.0\n1.0\n1.0\n0.5\n0.5\n1.6\n40.0\n15.6\n\n\n\n\n5 rows × 44 columns\n\n\n\n\n\ndescribe()\nEsta função nos ajuda a ter uma idéia dos valores que temos em nosso conjunto de dados. A função lista todas as colunas numéricas e apresenta os resultados para os seguintes cálculos estatísticos: média, desvio padrão, valor mínimo, percentil 25%, 50%, 75% e valor máximo.\nIsso nos dá uma idéia da variabilidade dos nossos dados, bem como permite uma análise de correlação superficial entre os valores numéricos.\n\npokemons.describe()\n\n\n\n\n\n\n\n\nNumber\nHP\nAtt\nDef\nSpa\nSpd\nSpe\nBST\nMean\nStandard Deviation\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\ncount\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n...\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n1032.000000\n\n\nmean\n439.226744\n69.906008\n80.526163\n74.609496\n72.918605\n72.139535\n68.548450\n438.648256\n73.108043\n20.028104\n...\n1.002180\n1.239826\n1.025678\n0.974806\n1.074855\n0.992006\n1.094234\n1.286822\n71.879845\n136.735756\n\n\nstd\n261.871350\n26.189155\n32.542374\n30.905972\n32.773495\n27.625876\n30.219526\n120.675545\n20.112591\n10.830298\n...\n0.613111\n0.699361\n0.577269\n0.378040\n0.475292\n0.511859\n0.535159\n1.391501\n132.872741\n3111.666658\n\n\nmin\n1.000000\n1.000000\n5.000000\n5.000000\n10.000000\n20.000000\n5.000000\n175.000000\n29.166667\n0.000000\n...\n0.250000\n0.250000\n0.000000\n0.000000\n0.250000\n0.250000\n0.250000\n0.100000\n0.100000\n0.000000\n\n\n25%\n211.750000\n50.000000\n55.000000\n50.000000\n50.000000\n50.000000\n45.000000\n330.000000\n55.000000\n12.801910\n...\n0.500000\n1.000000\n1.000000\n1.000000\n1.000000\n0.500000\n1.000000\n0.600000\n9.000000\n18.600000\n\n\n50%\n434.500000\n67.000000\n78.000000\n70.000000\n65.000000\n70.000000\n65.000000\n459.000000\n76.500000\n18.484228\n...\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n29.750000\n28.350000\n\n\n75%\n667.250000\n83.000000\n100.000000\n90.000000\n95.000000\n90.000000\n90.000000\n515.000000\n85.833333\n24.835709\n...\n1.000000\n2.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.600000\n71.275000\n42.200000\n\n\nmax\n898.000000\n255.000000\n190.000000\n230.000000\n194.000000\n230.000000\n200.000000\n780.000000\n130.000000\n103.215659\n...\n4.000000\n4.000000\n4.000000\n2.000000\n4.000000\n4.000000\n4.000000\n20.000000\n999.900000\n99990.000000\n\n\n\n\n8 rows × 39 columns\n\n\n\n\n\ninfo()\nOutra função útil é a função info() que traz a descrição da estrutura do DataFrame. Com esta função, você pode verificar os seguintes dados:\n\nlista colunas do DataFrame\npara cada coluna, quantos elementos não-nulos ela possui\npara cada coluna, seu tipo\nE ainda o número total de linhas e colunas no DataFrame\n\n\npokemons.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1032 entries, 0 to 1031\nData columns (total 44 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   Number                   1032 non-null   int64  \n 1   Name                     1032 non-null   object \n 2   Type 1                   1032 non-null   object \n 3   Type 2                   548 non-null    object \n 4   Abilities                1032 non-null   object \n 5   HP                       1032 non-null   int64  \n 6   Att                      1032 non-null   int64  \n 7   Def                      1032 non-null   int64  \n 8   Spa                      1032 non-null   int64  \n 9   Spd                      1032 non-null   int64  \n 10  Spe                      1032 non-null   int64  \n 11  BST                      1032 non-null   int64  \n 12  Mean                     1032 non-null   float64\n 13  Standard Deviation       1032 non-null   float64\n 14  Generation               1032 non-null   float64\n 15  Experience type          1032 non-null   object \n 16  Experience to level 100  1032 non-null   int64  \n 17  Final Evolution          1032 non-null   float64\n 18  Catch Rate               1032 non-null   int64  \n 19  Legendary                1032 non-null   float64\n 20  Mega Evolution           1032 non-null   float64\n 21  Alolan Form              1032 non-null   float64\n 22  Galarian Form            1032 non-null   float64\n 23  Against Normal           1032 non-null   float64\n 24  Against Fire             1032 non-null   float64\n 25  Against Water            1032 non-null   float64\n 26  Against Electric         1032 non-null   float64\n 27  Against Grass            1032 non-null   float64\n 28  Against Ice              1032 non-null   float64\n 29  Against Fighting         1032 non-null   float64\n 30  Against Poison           1032 non-null   float64\n 31  Against Ground           1032 non-null   float64\n 32  Against Flying           1032 non-null   float64\n 33  Against Psychic          1032 non-null   float64\n 34  Against Bug              1032 non-null   float64\n 35  Against Rock             1032 non-null   float64\n 36  Against Ghost            1032 non-null   float64\n 37  Against Dragon           1032 non-null   float64\n 38  Against Dark             1032 non-null   float64\n 39  Against Steel            1032 non-null   float64\n 40  Against Fairy            1032 non-null   float64\n 41  Height                   1032 non-null   float64\n 42  Weight                   1032 non-null   float64\n 43  BMI                      1032 non-null   float64\ndtypes: float64(29), int64(10), object(5)\nmemory usage: 354.9+ KB\n\n\n\n\nshape\nEsta não é uma função, mas sim uma propriedade, que retorna uma tupla com as dimensões de linha e coluna do DataFrame.\n\npokemons.shape\n\n(1032, 44)\n\n\n\n\n\nFiltrando os dados\nAgora vamos aprender como executar uma das tarefas mais comuns de manipular DataFrames com o objetivo de realizar análises: filtragem dos dados. A versão atual do pandas trouxe algumas funções que nos facilitam enormemente o processo. Mas, com o objetivo de equipa-los com o máximo de informação possível, vamos também aprender os métodos mais conhecidos.\nMas, antes de mostrarmos como realizar os filtros, vamos explicar alguns conceitos básicos, mas bem relevantes para a operação de filtragem dos dados.\n\nAcessando uma coluna do DataFrame\nPode parecer óbvio, mas para acessar a coluna de um DataFrame, basta fazer o seguinte:\n\ntipos = pokemons[\"Type 1\"]\n\nAssim, a variável tipos conterá o que chamamos de uma Series, que é um array numpy (biblioteca especializada para criação de arrays numéricos) que contém todas as linhas daquela coluna. Para comprovar isso, vamos imprimir o conteúdo.\n\ntipos\n\n0         Grass\n1         Grass\n2         Grass\n3         Grass\n4          Fire\n         ...   \n1027        Ice\n1028      Ghost\n1029    Psychic\n1030    Psychic\n1031    Psychic\nName: Type 1, Length: 1032, dtype: object\n\n\nParece interessante. Mas e se quisessemos criar um novo DataFrame apenas com as colunas Number, Name e Type 1? Parece simples, basta enviar ao DataFrame um array com o nome das colunas que quero extrair.\n\nsub_df = pokemons[[\"Number\", \"Name\", \"Type 1\"]]\n\nsub_df\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\n\n\n\n\n0\n1\nBulbasaur\nGrass\n\n\n1\n2\nIvysaur\nGrass\n\n\n2\n3\nVenusaur\nGrass\n\n\n3\n3\nMega Venusaur\nGrass\n\n\n4\n4\nCharmander\nFire\n\n\n...\n...\n...\n...\n\n\n1027\n896\nGlastrier\nIce\n\n\n1028\n897\nSpectrier\nGhost\n\n\n1029\n898\nCalyrex\nPsychic\n\n\n1030\n898\nCalyrex Ice Rider\nPsychic\n\n\n1031\n898\nCalyrex Shadow Rider\nPsychic\n\n\n\n\n1032 rows × 3 columns\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nObserve a questão da sintaxe de array: quando queremos apenas uma coluna a sintaxe de array não é necessária, ela se aplica apenas a múltiplos campos.\n\n\nMas, e como podemos acessar uma linha específica de um DataFrame? Se você está seguindo a linha de raciocínio, já imaginou que não é da maneira tradicional. Na verdade, é exatamente ao contrário do que estamos acostumados. Primeiro acessamos a coluna, e depois a linha, enquanto que em conjuntos de dados em formato tabular largo, primeiro acessamos a linha e depois a coluna.\n\npokemons[\"Name\"][0]\n\n'Bulbasaur'\n\n\n\n\nPercorrendo um DataFrame\nInteressante, certo? Mas isso levanta o seguinte questionamento: quando vou manipular os dados, como filtra-los ou fazer alguma modificação? Nos conjuntos de dados mais tradicionais, eu geralmente percorro o meu conjunto de dados linha a linha e faço os filtros e então altero as colunas. Como fazer isso em pandas?\n\nfor index, pokemon in pokemons.iterrows():\n    if index &lt;= 2:\n        print(pokemon[\"Name\"])\n    else:\n        break\n\nBulbasaur\nIvysaur\nVenusaur\n\n\nComo pode ser visto no código acima, basta usarmos a função iterrows() e iremos manipular o DataFrame como uma estrutura de dados mais tradicional, como um array de dicionário de dados. No código acima, fizemos um filtro que pega apenas as linhas com index menor ou igual 2, e mostra apenas o nome. Se DataFrames fossem estruturas de dados tradicionais, isso seria a maneira mais lógica de executar esse comando. Mas com pandas, podemos fazer isso:\n\npokemons[pokemons[\"Number\"] &lt;= 3][\"Name\"]\n\n0        Bulbasaur\n1          Ivysaur\n2         Venusaur\n3    Mega Venusaur\nName: Name, dtype: object\n\n\nWow, em uma única linha fizemos o filtro de linha e a seleção de coluna, e a principal vantagem sendo que este comando continuou retornando um DataFrame, o que ainda nos permite continuar trabalhando de forma eficiente com os dados que eu escolhi!\n\n\n\n\n\n\nWarning\n\n\n\nEmbora a utilização da função iterrows() pareça ser a forma mais natural e fácil de se trabalhar com Dataframes Pandas, é com a certeza a que apresenta a pior performance. Então, faça um esforço e aprenda muito bem os métodos mais “pandônicos” de manipular Dataframes, Cientista de Dados!\n\n\nEsta linha também nos introduz ao primeiro jeito de realizar filtros de linha: adicionando a expressão lógica nos primeiros parenteses. Parece simples, embora para referenciar ao campo que será utilizado no filtro, eu ainda precise referenciar o próprio DataFrame. E esse foi apenas um filtro simples. Como seria utilizar mais de um campo no filtro? Vamos ver agora mesmo.\n\npokemons[(pokemons[\"Number\"] &lt; 11) & (pokemons[\"Type 1\"] == \"Bug\")][\"Name\"]\n\n13    Caterpie\nName: Name, dtype: object\n\n\nPodemos perceber duas coisas: cada condição de filtro deve estar envolta em parenteses (vá em frente, se remover, teremos um erro), e em vez de usar o conector lógico tradicional AND ou OR, utilizamos & (AND) ou | (OR). E quanto mais condições, pior será para lermos com clareza nosso código.\nUma variação deste tipo de filtragem é a utilização da propriedade loc. Ela nos permite acessar linhas diretamente, e utilizando a notação de manipulação de arrays, filtrar rapidamente o DataFrame. Vamos a um exemplo: gostaria de extrair 10 linhas do DataFrame, iniciando na linha 10.\n\npokemons.loc[10:19]\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n10\n8\nWartortle\nWater\nNaN\n['Rain Dish', 'Torrent']\n59\n63\n80\n65\n80\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.0\n22.5\n22.5\n\n\n11\n9\nBlastoise\nWater\nNaN\n['Rain Dish', 'Torrent']\n79\n83\n100\n85\n105\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.6\n85.5\n33.4\n\n\n12\n9\nMega Blastoise\nWater\nNaN\n['Mega Launcher']\n79\n103\n120\n135\n115\n...\n1.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n1.6\n101.1\n39.5\n\n\n13\n10\nCaterpie\nBug\nNaN\n['Run Away', 'Shield Dust']\n45\n30\n35\n20\n20\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.3\n2.9\n32.2\n\n\n14\n11\nMetapod\nBug\nNaN\n['Shed Skin']\n50\n20\n55\n25\n25\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.7\n9.9\n20.2\n\n\n15\n12\nButterfree\nBug\nFlying\n['Tinted Lens']\n60\n45\n50\n90\n80\n...\n0.5\n4.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.1\n32.0\n26.4\n\n\n16\n13\nWeedle\nBug\nPoison\n['Run Away', 'Shield Dust']\n40\n35\n30\n20\n20\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.3\n3.2\n35.6\n\n\n17\n14\nKakuna\nBug\nPoison\n['Shed Skin']\n45\n25\n50\n25\n25\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n0.6\n10.0\n27.8\n\n\n18\n15\nBeedrill\nBug\nPoison\n['Sniper', 'Swarm']\n65\n90\n40\n45\n80\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.0\n29.5\n29.5\n\n\n19\n15\nMega Beedrill\nBug\nPoison\n['Adaptability']\n65\n150\n40\n15\n80\n...\n0.5\n2.0\n1.0\n1.0\n1.0\n1.0\n0.5\n1.4\n40.5\n20.7\n\n\n\n\n10 rows × 44 columns\n\n\n\nBem prático. A propriedade loc também pode entender o filtro anterior.\nE agora, a última maneira pela qual podemos realizar filtros em nossos DataFrames e a mais recomendada devido a legibilidade do código gerado: vamos utilizar a função query(). Esta função permite que escrevamos filtros para o DataFrame como se o mesmo fosse um banco de dados, deixando o código mais limpo, pois eliminamos a necessidade de referenciar o DataFrame a cada filtro, bem como parênteses redundantes. Vamos ver um exemplo:\n\npokemons.query(\"Number &lt; 11 and `Type 1` == 'Bug'\")\n\n\n\n\n\n\n\n\nNumber\nName\nType 1\nType 2\nAbilities\nHP\nAtt\nDef\nSpa\nSpd\n...\nAgainst Bug\nAgainst Rock\nAgainst Ghost\nAgainst Dragon\nAgainst Dark\nAgainst Steel\nAgainst Fairy\nHeight\nWeight\nBMI\n\n\n\n\n13\n10\nCaterpie\nBug\nNaN\n['Run Away', 'Shield Dust']\n45\n30\n35\n20\n20\n...\n1.0\n2.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.3\n2.9\n32.2\n\n\n\n\n1 rows × 44 columns\n\n\n\nAssim ficou bem mais limpo. Uma única observação é quanto ao uso do caracter “`” para campos com nomes compostos.\n\n\n\nAgregando os dados\nEm muitos casos, não queremos apenas filtrar os dados, mas também realizar totalizações, calcular valores médios, ou até mesmo cálculos mais complexos, de dados que devem ser agregados em um ou mais níveis.\nComo exemplo, vamos supor que quisessemos totalizar o número de pokemons de acordo com o seu tipo.\n\npokemons.groupby(['Type 1'])[\"Name\"].count().reset_index(name=\"Pokemons\")\n\n\n\n\n\n\n\n\nType 1\nPokemons\n\n\n\n\n0\nBug\n81\n\n\n1\nDark\n46\n\n\n2\nDragon\n42\n\n\n3\nElectric\n59\n\n\n4\nFairy\n22\n\n\n5\nFighting\n42\n\n\n6\nFire\n64\n\n\n7\nFlying\n8\n\n\n8\nGhost\n41\n\n\n9\nGrass\n91\n\n\n10\nGround\n41\n\n\n11\nIce\n38\n\n\n12\nNormal\n114\n\n\n13\nPoison\n40\n\n\n14\nPsychic\n77\n\n\n15\nRock\n59\n\n\n16\nSteel\n36\n\n\n17\nWater\n131\n\n\n\n\n\n\n\nMas quanta coisa nova naquela linha, não é mesmo? Vamos explicar passo a passo:\n\nA primeira função é o groupby, onde especificamos por qual coluna ou colunas iremos fazer o agrupamento. No nosso exemplo, utilizamos a coluna ‘Type 1’\nEm seguida, especificamos que, além da coluna ‘Type 1’, queremos apenas a coluna ‘Name’ nos nossos resultados\nLogo após, indicamos que o valor original da coluna ‘Name’ será substituído pelo resultado da contagem de quantas linhas do DataFrame tem aquele valor específico da coluna ‘Type 1’\nE por último, utilizamos uma função que irá trocar o nome da coluna ‘Name’ por um nome mais significativo\n\nUfa, e tudo isso em apenas uma linha!\nA fórmula para a agregação é sempre a mesma: groupby() e tipo de calculo (sum, count, mean, …). Por exemplo, no código abaixo, vamos agrupar também pela geração.\n\npokemons.groupby(['Generation', 'Type 1'])['Name'].count().reset_index(name='Pokemons')\n\n\n\n\n\n\n\n\nGeneration\nType 1\nPokemons\n\n\n\n\n0\n1.0\nBug\n12\n\n\n1\n1.0\nDragon\n3\n\n\n2\n1.0\nElectric\n9\n\n\n3\n1.0\nFairy\n2\n\n\n4\n1.0\nFighting\n7\n\n\n...\n...\n...\n...\n\n\n129\n8.0\nPoison\n4\n\n\n130\n8.0\nPsychic\n11\n\n\n131\n8.0\nRock\n4\n\n\n132\n8.0\nSteel\n5\n\n\n133\n8.0\nWater\n9\n\n\n\n\n134 rows × 3 columns\n\n\n\nE se quisermos saber a média de pontos de vida por geração de pokemon? Parece simples…\n\npokemons.groupby(['Generation'])['HP'].mean().reset_index(name='Average HP')\n\n\n\n\n\n\n\n\nGeneration\nAverage HP\n\n\n\n\n0\n1.0\n64.211921\n\n\n1\n2.0\n70.980000\n\n\n2\n3.0\n65.326087\n\n\n3\n4.0\n72.775862\n\n\n4\n5.0\n71.601227\n\n\n5\n6.0\n73.323308\n\n\n6\n7.0\n69.793103\n\n\n7\n8.0\n72.808696"
  },
  {
    "objectID": "posts/data-105/index.html#encerrando",
    "href": "posts/data-105/index.html#encerrando",
    "title": "Parte 04 - Pandas",
    "section": "Encerrando",
    "text": "Encerrando\nNeste artigo, conhecemos um pouco mais a respeito da biblioteca Pandas e como ela pode nos ajudar a carregar e analisar conjuntos de dados que podem ser utilizados em nossas visualizações, de forma simplificada e eficiente.\nDentro do processo de utilização de Pandas, aprendemos as executar as principais tarefas:\n\naprender sobre os metadados do conjunto de dados, utilizando: describe, info e shape\nlistar conteúdo com head, tail, sample e iterrows\nacessar células diretamente\nrealizar filtros em cima do DataFrame utilizando o método colunar, utilizando loc ou utilizando a função query\nagregar os dados para sumarizar a informação e facilitar a análise.\n\nSe você quiser saber mais sobre Pandas, eis aqui alguns links que podem ajudar:\n\nPandas - Documentação Oficial\nTutorial Pandas - W3 Schools\nTutorial Pandas - Kaggle\nVídeo sobre Pandas - Hashtag Treinamentos\n\nUm abraço e até a próxima,\nWalter."
  },
  {
    "objectID": "posts/data-107/index.html",
    "href": "posts/data-107/index.html",
    "title": "Parte 06 - Linhas e Áreas",
    "section": "",
    "text": "Olá Cientista de Dados!\nNa última aula, começamos de maneira efetiva o nosso aprendizado da biblioteca seaborn, para a criação de gráficos utilizando a linguagem Python, e tecnologias interativas como o Google Colab.\nMais especificamente, aprendemos a criar gráficos de barras e suas variações como o gráfico de colunas, barras agrupadas ou até mesmo empilhadas (stacked). Esses gráficos correspondem com certeza à maior parte da nossa necessidade em termos de gráficos, mas ainda temos outra categoria que é muito importante: os gráficos de Linhas e Áreas.\n\n\nOs gráficos de Linhas e Áreas são utilizados quando precisamos representar a distribuição de métrica ao longo de um eixo de valores categóricos mas contínuos. O exemplo mais clássico é representar a distribuição de valores ao longo da dimensão do tempo. Mas também é possível utilizar qualquer outra dimensão numérica e contínua.\nEntão, estão preparados para mais uma dose de conhecimento?"
  },
  {
    "objectID": "posts/data-107/index.html#introdução",
    "href": "posts/data-107/index.html#introdução",
    "title": "Parte 06 - Linhas e Áreas",
    "section": "",
    "text": "Olá Cientista de Dados!\nNa última aula, começamos de maneira efetiva o nosso aprendizado da biblioteca seaborn, para a criação de gráficos utilizando a linguagem Python, e tecnologias interativas como o Google Colab.\nMais especificamente, aprendemos a criar gráficos de barras e suas variações como o gráfico de colunas, barras agrupadas ou até mesmo empilhadas (stacked). Esses gráficos correspondem com certeza à maior parte da nossa necessidade em termos de gráficos, mas ainda temos outra categoria que é muito importante: os gráficos de Linhas e Áreas.\n\n\nOs gráficos de Linhas e Áreas são utilizados quando precisamos representar a distribuição de métrica ao longo de um eixo de valores categóricos mas contínuos. O exemplo mais clássico é representar a distribuição de valores ao longo da dimensão do tempo. Mas também é possível utilizar qualquer outra dimensão numérica e contínua.\nEntão, estão preparados para mais uma dose de conhecimento?"
  },
  {
    "objectID": "posts/data-107/index.html#preparação",
    "href": "posts/data-107/index.html#preparação",
    "title": "Parte 06 - Linhas e Áreas",
    "section": "Preparação",
    "text": "Preparação\nA primeira coisa que iremos fazer no nosso notebook é carregar todas as bibliotecas que iremos utilizar e também o nosso conjunto de dados.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npokemons = pd.read_csv('pokemons.csv')"
  },
  {
    "objectID": "posts/data-107/index.html#utilização-básica",
    "href": "posts/data-107/index.html#utilização-básica",
    "title": "Parte 06 - Linhas e Áreas",
    "section": "Utilização Básica",
    "text": "Utilização Básica\nA utilização básica aqui não é muito diferente do que fizemos para os gráficos de barra: temos uma função que deve poder gerar a visualização, através da passagem de alguns parâmetros básicos: fonte de dados, eixo X, Y, …\nNeste caso, a função em questão é a lineplot(). Vamos tentar?\n\nsns.lineplot(pokemons, x='Generation', y='Spe')\nplt.title('Variação de Velocidade de acordo com as Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Velocidade')\nplt.show()\n\n\n\n\n\n\n\n\nPadronização é uma maravilha, não é mesmo? Pegamos o nosso código para gráficos de barras e trocamos a função e tudo funcionou! Podemos perceber, no entanto, que a nossa linha representando está envolta por um delimitador azulado. Para resolver isso, vamos dar uma analisada nos parâmetros específicos da função lineplot().\nPor padrão, o gráfico de linhas também plota o que chamamos de error band, ou margem de erro. Se não for interessante, podemos eliminar essa error band.\n\nsns.lineplot(pokemons, x='Generation', y='Spe', errorbar=None)\nplt.title('Variação de Velocidade de acordo com as Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Velocidade')\nplt.show()\n\n\n\n\n\n\n\n\nE, assim como no gráfico de barras, temos a necessidade de plotar mais de uma série no nosso gráfico de linhas. Como fazemos isso? É simples:\n\npokemons_sb = pokemons[['Generation','Spa','Spd']] # Primeiro selecionamos apenas as colunas que queremos trabalhar\ntidy = pokemons_sb.melt(id_vars='Generation').rename(columns=str.title)\n\nsns.lineplot(tidy, x='Generation', y='Value', hue='Variable', errorbar=None)\nplt.title('Análise das Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Atributos')\nplt.show()\n\n\n\n\n\n\n\n\nBasicamente, tivemos que fazer a mesma operação que fizemos para as múltiplas barras. E o resto do código já é bem conhecido.\nO outro tipo de gráfico baseado em linhas é o popular gráfico de área. Mas somente conseguimos gerar esse gráfico utilizando a função stackplot() do MatplotLib. Veja o exemplo abaixo:\n\npokemons_gb = pokemons.groupby(['Generation'])[['Spa', 'Spd']].mean().reset_index()\n\nplt.stackplot(pokemons_gb['Generation'], pokemons_gb['Spa'], pokemons_gb['Spd'], labels=['Special Attack', 'Special Defense'])\nplt.title('Análise das Gerações')\nplt.xlabel('Geração')\nplt.ylabel('Atributos')\nplt.show()\n\n\n\n\n\n\n\n\nE aí está o nosso gráfico de área! Mais uma vez, recorremos a matplotlib para concluir a plotagem."
  },
  {
    "objectID": "posts/data-107/index.html#conclusão",
    "href": "posts/data-107/index.html#conclusão",
    "title": "Parte 06 - Linhas e Áreas",
    "section": "Conclusão",
    "text": "Conclusão\nNesta aula, aprendemos a criar mais dois tipos de gráfico: linha e área, revisamos a utilização de pandas para transformar os dados e acrescentamos mais uma ferramenta no nosso cinto de utilidades.\nSe você quiser aprender mais sobre gráficos de linha e área em seaborn, seguem alguns links: - Documentação oficial do Seaborn em português: A documentação oficial do Seaborn tem uma versão em português que fornece uma visão geral da biblioteca, exemplos de uso, informações sobre os diferentes tipos de gráficos, e muito mais - Gráficos de Linha em Seaborn\nNa próxima aula, iremos explorar os gráficos de dispersão e pontos.\n\nNavegação\n\n\n\n&lt; Anterior\n|\nPróximo &gt;"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html",
    "href": "posts/p0002-pandasai/index.html",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros.\n\n\nSe você não estava embaixo de uma pedra, certamente já sabe que as LLMs vigentes são muito boas em análise de dados, gerando códigos muito bons, inclusive para alguns casos mais complexos. No entanto, o conteúdo deste artigo ainda tem relevância, pois mostra uma das muitas maneiras de integrar uma LLM ao processo de análise de dados."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#introdução",
    "href": "posts/p0002-pandasai/index.html#introdução",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "",
    "text": "Desde outubro do ano passado, com a liberação do ChatGPT 3.5, as interfaces conversacionais vem se popularizando de maneira muito rápida. É verdade que interfaces conversacionais não são novidade, e chatbots e assistentes virtuais vem dominando tarefas relacionadas a atendimento de clientes, mas desde o advento do ChatGPT, tem-se expandido para outras áreas de atuação.\nUtilizamos o ChatGPT para criarmos resumos de textos longos, para consultar algo que ocorreu no passado, explicar conceitos e por aí vai. Já existem cursos que ensinam como utilizar o ChatGPT para criar campanhas de marketing nas redes sociais e outras tantas funções que são basicamente apoiadas em texto.\nDentro da programação, é possível gerar pequenos trechos de código e até páginas HTML e arquivos CSS inteiros.\n\n\nSe você não estava embaixo de uma pedra, certamente já sabe que as LLMs vigentes são muito boas em análise de dados, gerando códigos muito bons, inclusive para alguns casos mais complexos. No entanto, o conteúdo deste artigo ainda tem relevância, pois mostra uma das muitas maneiras de integrar uma LLM ao processo de análise de dados."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "href": "posts/p0002-pandasai/index.html#e-o-que-isso-tem-a-ver-com-ciências-de-dados",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "E o que isso tem a ver com Ciências de Dados?",
    "text": "E o que isso tem a ver com Ciências de Dados?\nOs DataFrames são basicamente textos organizados em tabelas e colunas, que são correlacionados. Portanto, é possível carregar os dados em um modelo LLM (Large Language Model), habilitando a extração da informação destes DataFrames de maneira conversacional, como se estivéssemos dialogando. Mas o que realmente instiga esta nossa área é descobrir se podemos fazer este modelo realizar o trabalho de análise para nós, cientistas e analistas iniciantes (e até mesmo os mais experientes). A resposta mais recente que temos para isso é chamada de Pandas AI."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "href": "posts/p0002-pandasai/index.html#o-que-é-o-pandas-ai",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que é o Pandas AI?",
    "text": "O que é o Pandas AI?\n\n\n\nPandas e Llamas\n\n\nO Pandas AI é o melhor amigo do seu DataFrame! Com esta nova biblioteca, podemos dar aos nossos DataFrames a capacidade de serem consultados de maneira simples e eficiente, utilizando uma interface conversacional.\nEntão, vamos ver como podemos utilizar Pandas AI?\n\nPreparando o Ambiente\nA primeira coisa é garantir que seu ambiente tenha todas as bibliotecas necessárias instaladas: Pandas, PandasAI, OpenAI.\n$ pip install pandas pandasai openai\nEntão, vamos iniciar o nosso notebook. Temos que fazer o import das bibliotecas que vamos utilizar na nossa demonstração.\n\nimport os\nimport pandas as pd\n\nfrom pandasai import PandasAI\nfrom pandasai.llm.openai import OpenAI\nfrom dotenv import load_dotenv\n\nObserve que carregamos a função load_dotenv, pois iremos precisar carregar a chave de acesso para a API da OpenAI. Para fazer isso, podemos simplesmente executar a função.\n\nload_dotenv()\n\nTrue\n\n\nO próximo passo é carregar os nossos dados no DataFrame. Como sempre, vamos utilizar o dataset de pokemons.\n\npokemons = pd.read_csv('pokemons.csv')\n\nEm seguida, vamos inicializar o LLM para que consigamos conversar com o nosso DataFrame.\n\nllm = OpenAI(api_token=os.environ['OPENAI_API_KEY'])\npandas_ai = PandasAI(llm)\n\nAté agora, tudo correu bem! Agora, podemos executar diversas vezes a função pandas_ai.run, passando nosso DataFrame e um prompt, e ele nos responderá. Vamos testar?\n\npandas_ai.run(pokemons, prompt=\"Quantos pokemons temos no DataFrame?\")\n\n'Unfortunately, I was not able to answer your question. Please try again. If the problem persists, try rephrasing your question.'\n\n\nPara verificar isso, podemos apenas ver o shape do DataFrame e confirmar:\n\npokemons.shape\n\n(1032, 44)\n\n\nDe fato, 1032 pokemons. Vamos continuar?\n\npandas_ai.run(pokemons, prompt=\"Quantos tipos de pokemons existem?\")\n\n'Well, there are actually 18 different types of pokemons out there!'\n\n\nVamos conferir?\n\ntipos = pd.concat([pokemons['Type 1'], pokemons['Type 2']]).unique().tolist()\n\n\nprint(len(tipos))\nprint(tipos)\n\n19\n['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Dark', 'Poison', 'Electric', 'Ground', 'Ice', 'Fairy', 'Steel', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Dragon', 'Flying', nan]\n\n\nParece que funciona mesmo! Note que o nosso vetor tem 19 posições porque está contando o nulo como um valor. Vamos nos aprofundar mais um pouco…\n\npandas_ai.run(pokemons, prompt='Liste os tipos com as quantidades de pokemons')\n\n'Existem diversos tipos de pokemons e suas quantidades variam. O tipo mais comum é o Normal, com 114 pokemons, seguido pelo tipo Água, com 131. Já o tipo Voador é o menos comum, com apenas 8 pokemons. Além disso, existem outros tipos como Fogo, Grama, Elétrico, Psíquico, entre outros, cada um com sua quantidade específica de pokemons. No total, existem mais de 800 espécies diferentes de pokemons.'\n\n\nEle respondeu, mas não exatamente como queríamos - observe que ele listou alguns tipos apenas com suas quantidades. Vamos tentar melhorar, aplicando um pouco de prompt engineering (ou seja, escrever nossa solicitação de forma mais explícita).\n\npandas_ai.run(pokemons, prompt=\"Crie uma tabela que tem duas colunas: tipo de pokemon e quantidade. Liste todos os tipos possíveis e suas quantidades.\")\n\n'Para responder à pergunta, criei uma tabela com duas colunas: tipo de pokemon e quantidade. Nessa tabela, listei todos os tipos possíveis de pokemon e suas respectivas quantidades. Por exemplo, há 81 pokemons do tipo Bug, 46 do tipo Dark, 42 do tipo Dragon, e assim por diante. No total, foram listados 18 tipos diferentes de pokemon e suas quantidades correspondentes.'\n\n\nHumm, ainda não conseguimos listar todos os tipos. Vamos explicar um pouco mais?\n\npandas_ai.run(pokemons, prompt=\"Gerar uma listagem completa da quantidade de pokemons por tipo, em formato markdown.\")\n\n'Para saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo: \\n\\n| Type | Count |\\n|------|-------|\\n| Bug | 81 |\\n| Dark | 46 |\\n| Dragon | 42 |\\n| Electric | 59 |\\n| Fairy | 22 |\\n| Fighting | 42 |\\n| Fire | 64 |\\n| Flying | 8 |\\n| Ghost | 41 |\\n| Grass | 91 |\\n| Ground | 41 |\\n| Ice | 38 |\\n| Normal | 114 |\\n| Poison | 40 |\\n| Psychic | 77 |\\n| Rock | 59 |\\n| Steel | 36 |\\n| Water | 131 |\\n\\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.'\n\n\nOpa,agora foi. Mas como o notebook não formata markdown no output, precisamos fazer um copia e cola do resultado.\nPara saber a quantidade de pokemons por tipo, podemos gerar uma listagem completa em formato markdown. Aqui está a tabela com o número de pokemons para cada tipo:\n\n\n\nType\nCount\n\n\n\n\nBug\n81\n\n\nDark\n46\n\n\nDragon\n42\n\n\nElectric\n59\n\n\nFairy\n22\n\n\nFighting\n42\n\n\nFire\n64\n\n\nFlying\n8\n\n\nGhost\n41\n\n\nGrass\n91\n\n\nGround\n41\n\n\nIce\n38\n\n\nNormal\n114\n\n\nPoison\n40\n\n\nPsychic\n77\n\n\nRock\n59\n\n\nSteel\n36\n\n\nWater\n131\n\n\n\nAssim, você pode ter uma visão geral da distribuição dos tipos de pokemons na lista.’"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "href": "posts/p0002-pandasai/index.html#vamos-complicar-um-pouco",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vamos complicar um pouco?",
    "text": "Vamos complicar um pouco?\nNas primeiras perguntas, utilizamos perguntas que pedem respostas quase que diretas das métricas que temos no DataFrame. Contamos o número de pokemons, contamos valores distinto de tipos, agrupamos a contagem por tipos. Mas será que o Pandas AI pode fazer uma análise comparativa simples, tal como analisar uma métrica e retornar o insight solicitado?\n\npandas_ai.run(pokemons, prompt=\"Qual o pokemon mais pesado?\")\n\n'Bem, o pokemon mais pesado é o Snorlax, ele pode chegar a pesar mais de 460 quilos!'\n\n\nOpa, e não é que respondeu? Mas, sem precipitação, vamos conferir: vamos executar uma query em pandas que filtra os pokemons com peso &gt;= ao do Snorlax.\n\npokemons[[\"Name\",\"Weight\"]].sort_values(\"Weight\").query(\"Weight &gt; 459\")\n\n\n\n\n\n\n\n\nName\nWeight\n\n\n\n\n925\nDusk Mane Necrozma\n460.0\n\n\n181\nSnorlax\n460.0\n\n\n837\nHoopa Unbound\n490.0\n\n\n826\nAvalugg\n505.0\n\n\n1001\nStonjourner\n520.0\n\n\n445\nMetagross\n550.0\n\n\n833\nZygarde Complete\n610.0\n\n\n578\nGiratina-Origin\n650.0\n\n\n1007\nCopperajah\n650.0\n\n\n573\nDialga\n683.0\n\n\n254\nMega Steelix\n740.0\n\n\n577\nGiratina\n750.0\n\n\n1019\nZamazenta Crowned Shield\n785.0\n\n\n1027\nGlastrier\n800.0\n\n\n936\nMelmetal\n800.0\n\n\n1030\nCalyrex Ice Rider\n809.1\n\n\n932\nStakataka\n820.0\n\n\n923\nGuzzlord\n888.0\n\n\n873\nMudsdale\n920.0\n\n\n446\nMega Metagross\n942.9\n\n\n1020\nEternatus\n950.0\n\n\n456\nGroudon\n950.0\n\n\n457\nPrimal Groudon\n999.7\n\n\n914\nCosmoem\n999.9\n\n\n921\nCelesteela\n999.9\n\n\n\n\n\n\n\nOps, algo deu errado. Temos vários pokemons mais pesados. Será que ele não analisou todos os pokemons antes de responder? Quem sabe um problema nos dados? Vamos perguntar algo mais direto.\n\npandas_ai.run(pokemons, prompt=\"O pokemon Dialga é mais ou menos pesado que o Snorlax?\")\n\n'Well, it turns out that Snorlax is actually heavier than Dialga.'\n\n\nIsso certamente deve ser um problema. Ele passou a responder em inglês, como se tivesse perdido o contexto. Vamos perguntar de maneira diferente…\n\npandas_ai.run(pokemons, prompt=\"Porque o pokemon Dialga é mais pesado que o Snorlax?\")\n\n'Well, actually, Snorlax weighs more than Dialga.'\n\n\nÉ, ele realmente tem uma implicância com o Snorlax… Caso você não tenha lido nada a respeito do ChatGPT e LLMs em geral, esse tipo de erro é chamado de “alucinação” que ocorre quando o modelo produz resultados incorretos, correlacionando informações de maneira espúria."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "href": "posts/p0002-pandasai/index.html#usando-outras-funcionalidades-do-pandas-via-conversação",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Usando outras funcionalidades do Pandas via conversação",
    "text": "Usando outras funcionalidades do Pandas via conversação\nAgora vamos testar se o pandasAI consegue entender instruções para plotar gráficos. Isso é um DataFrame pandas, correto? Será que eu posso plotar um countplot() por geração?\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de colunas totalizando pokemons por geração.\")\n\n\n\n\n\n\n\n\n'Claro! Vou plotar um gráfico de colunas que mostra a quantidade total de pokemons por geração.'\n\n\nParece que funcionou bem! Vamos tentar mais um?\n\n\npandas_ai.run(pokemons, prompt=\"Plote um gráfico de pizza totalizando pokemons pelo campo lendário.\")\n\n\n\n\n\n\n\n\n'Sure, I can help you with that! To plot a pie chart showing the total number of legendary Pokémon, we need to gather the data first. Once we have the numbers, we can create a visual representation of the data using a pie chart. Would you like me to proceed with the task?'"
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "href": "posts/p0002-pandasai/index.html#o-que-aprendemos-até-aqui",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "O que aprendemos até aqui",
    "text": "O que aprendemos até aqui\nA biblioteca Pandas AI é uma biblioteca interessante, que nos permite “dialogar”com nossos DataFrames, extraindo informações do mesmo. Através de nossos exemplos, podemos verificar que quase tudo que podemos descobrir através de consultas normais pandas, podemos perguntar ao DataFrame através do Pandas AI.\n\nMas nem tudo são flores…\nApesar dos acertos, observamos que a biblioteca Pandas AI não é imune aos problemas comuns das LLM, e mesmo com uma base de conhecimento mais limitada, é acometida de alucinações. A biblioteca também sofre de um problema de performance: uma resposta que em pandas leva um segundo ou menos para ser mostrada, como podemos ver, pode levar até mais de 1 minuto usando PandasAI.\nPor último, podemos perceber que a biblioteca ainda precisa um pouco mais de trabalho até mesmo em sua usabilidade - notamos que a mesma passa a responder em inglês quando a resposta está errada, deixando o usuário confuso."
  },
  {
    "objectID": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "href": "posts/p0002-pandasai/index.html#vale-a-pena-utilizar",
    "title": "Pandas AI - Converse com seu DataFrame",
    "section": "Vale a pena utilizar?",
    "text": "Vale a pena utilizar?\nSe você quer fazer explorações simples dos dados, parece ser uma boa idéia utilizar o PandasAI, visto que é mais fácil perguntar em português ou inglês do que lembrar a sintaxe de todos os comandos Pandas que você teria que fazer para isso. No entanto, é preciso tomar muito cuidado com os resultados, que podem estar errados, mas são comunicados com convicção.\nÉ, com certeza, mais uma ferramenta no seu cinto de utilidades de cientista de dados, e como toda ferramenta, devemos conhece-la bem antes de usar. Explore mais, entenda suas limitações e faça o melhor uso possivel!\nAté mais!!!\nWalter."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html",
    "href": "posts/p0004-classif-texto/index.html",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#introdução",
    "href": "posts/p0004-classif-texto/index.html#introdução",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "",
    "text": "Olá, tudo bem?\nA esta altura do ano de 2023, é quase impossível que você não tenha ouvido falar sobre o ChatGPT. E verdade seja dita, o ChatGPT é uma aplicação incrível, que permite sermos mais eficientes em diversas tarefas do dia dia-a-dia! Mas é importante salientar que ele é apenas uma aplicação, o que está por trás do ChatGPT e que chamamos de um LLM (Large Language Model) é o que realmente faz toda a mágica acontecer. Não iremos entrar em detalhes de como o modelo GPT (Generative Pretrained Transformer) funciona (veja os links no final do post), mas vamos explicar como podemos trazer todo esse poder para dentro de nossos códigos Python e criar scripts e aplicações que vão aumentar ainda mais nossa produtividade.\nEste será o primeiro de uma série de artigos que visam auxiliar na compreensão de como as IAs podem ser assistentes poderosos para o Analista de Dados."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "href": "posts/p0004-classif-texto/index.html#classificação-de-dados",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "Classificação de Dados",
    "text": "Classificação de Dados\nClassificação de dados é uma tarefa de aprendizado supervisionado que envolve a categorização de uma determinada amostra de dados em uma das várias classes predefinidas. Cada amostra é atribuída a uma e somente uma classe, baseando-se nas características dessa amostra.\nPor exemplo, imagine que você tem um conjunto de emails e você quer classificá-los como “spam” ou “não spam”. Nesse caso, “spam” e “não spam” são as classes, e cada email é uma amostra que será classificada em uma dessas classes.\nA classificação é geralmente realizada utilizando algoritmos de aprendizado de máquina. Esses algoritmos aprendem a classificar novas amostras baseando-se em um conjunto de treinamento. O conjunto de treinamento é um conjunto de amostras para as quais as classes verdadeiras são conhecidas.\nOs algoritmos de classificação incluem árvores de decisão, regressão logística, máquinas de vetores de suporte, redes neurais e muitos outros. A escolha do algoritmo depende de vários fatores, como a natureza dos dados, o número de classes, a necessidade de interpretabilidade e outros.\n\nMas e se não temos conjuntos de dados de treinamento?\nSe você não tem um conjunto de dados de treinamento rotulado, ainda existem várias abordagens que você pode usar, tais como:\n\nAprendizado não supervisionado\nAprendizado semi-supervisionado\nAprendizado por reforço\nRotulagem manual\nGeração de rótulos sintéticos\nProcessamento de Linguagem Natural\n\nE é nesta última opção que podemos utilizar o GPT para nos ajudar, pois o modelo do GPT é gigantesco, tendo sido treinado com conteúdo de toda a internet.\n\n\nGPT versus métodos mais tradicionais de classificação\nOs modelos de linguagem como o GPT (Generative Pretrained Transformer) têm várias vantagens e desvantagens, especialmente quando comparados a outros métodos de análise de texto. Aqui estão algumas delas:\nVantagens:\n\nCompreensão Profunda da Linguagem: O GPT é treinado em enormes quantidades de texto, o que lhe permite aprender uma rica compreensão da linguagem natural. Isso inclui uma compreensão de sintaxe, semântica, e até mesmo alguns elementos de conhecimento do mundo real.\nVersatilidade: O GPT pode ser usado para uma ampla gama de tarefas de processamento de linguagem natural, incluindo tradução de texto, geração de texto, resumo de texto, análise de sentimento, resposta a perguntas e muito mais.\nAprendizado Transferível: O GPT utiliza o aprendizado transferível, o que significa que o conhecimento aprendido durante o treinamento em um grande conjunto de dados pode ser aplicado a tarefas específicas com relativamente poucos dados de treinamento adicionais. Isso permite ao GPT se adaptar a uma ampla gama de tarefas com um desempenho impressionante.\nModelagem de Contexto: A arquitetura do Transformer, utilizada pelo GPT, é especialmente boa para entender o contexto em uma sequência de texto, o que é crucial para muitas tarefas de processamento de linguagem natural.\n\nDesvantagens:\n\nNecessidade de Grandes Quantidades de Dados de Treinamento: O GPT precisa de grandes quantidades de dados de treinamento para aprender efetivamente. Isso pode tornar o treinamento do modelo do zero proibitivamente caro em termos de tempo e recursos computacionais.\nDificuldade de Interpretação: O GPT, como muitos modelos de aprendizado profundo, pode ser difícil de interpretar. Ele pode produzir resultados impressionantes, mas pode ser difícil entender por que fez uma determinada previsão.\nSensibilidade ao Ruído e Erros: Embora o GPT seja robusto em muitos aspectos, ele pode ser sensível a ruído e erros no texto de entrada. Pequenas mudanças no texto de entrada podem às vezes levar a grandes mudanças nas previsões do modelo.\nPotencial de Viés: O GPT aprende com os dados em que é treinado, e se esses dados contêm viés, o modelo também pode exibir viés. Isso pode ser um problema significativo quando o modelo é usado em contextos sensíveis."
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "href": "posts/p0004-classif-texto/index.html#ok-o-gpt-é-legal-e-tudo-o-mais-mas-e-daí",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "Ok, o GPT é legal e tudo o mais… Mas e daí?",
    "text": "Ok, o GPT é legal e tudo o mais… Mas e daí?\nE daí que, graças ao modelo GPT, podemos ter um classificador de texto super calibrado para nos ajudar em nossas tarefas, sem o ônus de treinar tal modelo. E podemos utilizar o GPT a partir da API da OpenAI, de maneira muito simples! Outra vantagem que vale ressaltar é que, ao contrário de modelos tradicionais de classificação, podemos atribuir múltiplas categorias ao nosso texto.\nVamos ver um exemplo?"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "href": "posts/p0004-classif-texto/index.html#organizando-um-catálogo-de-artigos",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "Organizando um catálogo de artigos",
    "text": "Organizando um catálogo de artigos\nImagine o seguinte cenário: temos uma lista de todos os artigos que salvamos no site Medium. O problema desta lista é que o Medium não oferece nenhum tipo de categorização dos artigos. A única maneira de fazer isso é separando em várias listas, o que dificulta principalmente o processo de busca dos artigos. Além, é claro, de pressupor a classificação antes de ler o artigo.\nEssa tarefa realmente não é trivial, e seria muito útil poder fazer isso de forma automatizada. E o primeiro problema que temos é que nossa lista tem apenas o título e a url dos artigos. Para que a classificação seja mais precisa, precisamos de pelo menos algum texto que nos ajude a ter mais contexto a respeito do artigo.\nEntão, vamos criar o nosso script classificador? Esse script vai executar as seguintes tarefas:\n\n\n\n\n\nflowchart LR\n  A[Carregar Lista de Arquivos] --&gt; B\n  B[Buscar Título e Resumo&lt;br&gt;dos Artigos] --&gt; C\n  C[Classificar Artigos] --&gt; D[Salvar Lista de Artigos]\n\n\n\n\n\n\n\nInicializando o ambiente\nVamos utilizar as seguintes bibliotecas: - beautifulsoup4 - biblioteca para extrair a informação do HTML que contém a lista de artigos - openai - biblioteca para utilizar a API da openAI - requests - bibliotea para buscar informações da internet\n\nimport os\nimport openai\nimport bs4\nimport json\n\nfrom dotenv import load_dotenv\nfrom requests_html import HTMLSession # importando o objeto de sessão do html requests\n\nA próxima etapa é carregar variáveis de ambiente. Lembrando que é necessário ter uma API key para usar a API da OpenAI.\n\nload_dotenv()\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nAgora, precisamos carregar nossa lista de artigos, que está em um arquivo HTML, que podemos baixar lá no site do Medium. Vamos criar uma função, de forma que poderemos re-utilizar essa parte da rotina sempre que for necessário.\n\ndef retorna_lista(nomearquivo: str):\n  html_artigos = bs4.BeautifulSoup(open(nomearquivo, \"r\"))\n  list_artigos = html_artigos.find_all(\"li\")\n\n  artigos = []\n  for item in list_artigos:\n    record = {}\n    record = {\n        \"titulo\": item.a.text,\n        \"link\": item.a[\"href\"],\n        \"autores\": None,\n        \"resumo\": None,\n        \"categorias\": None\n    }\n    artigos.append(record)\n  return artigos\n\nEste código define uma função chamada “retorna_lista” que recebe um único parâmetro chamado “nomearquivo” do tipo string. A função primeiro abre o arquivo especificado pela string “nomearquivo” usando a função “open”, lê o conteúdo e usa o método “find_all” do Beautiful Soup para procurar todos os elementos de lista no documento HTML e armazená-los na variável “list_artigos”. A função, então, inicializa uma lista vazia chamada “artigos”. Em um loop, ela itera sobre cada item da lista na variável “list_artigos” e cria um dicionário chamado “record” com três chaves: “titulo”, “link”, “autores”, “resumo” e “categorias”. Os valores para “titulo” e “link” são extraídos do texto da tag “a” e do atributo “href”, respectivamente. O valor das chaves “autores”, “resumo” e “categorias” são uma string vazia. O dicionário “record” completo é então adicionado à lista “artigos”. Depois que todos os itens da lista são processados, a função retorna a lista “artigos”.\nEntão, podemos utilizar essa função conforme abaixo:\n\nartigos = retorna_lista(\"reading-list-medium.html\")\n\nprint(f\" Número de Artigos: {len(artigos)}.\")\n\n Número de Artigos: 1865.\n\n\nVamos ver como ficou um registro:\n\nprint(json.dumps(artigos[0], indent=4))\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": null,\n    \"resumo\": null,\n    \"categorias\": null\n}\n\n\nPerfeito! Estamos com os artigos preparados para buscarmos os dados extra que nos darão mais contexto para a categorização.\nPara fazer isso, vamos utilizar a biblioteca requests-html. Novamente, criaremos uma função para reutilizar depois.\n\ndef retorna_campos(registro: dict):\n    # Declaramos variaveis que contem seletores HTML\n    # Esses seletores nos ajudarão a encontrar os elementos HTML que contém o \n    # conteúdo referente ao autor, data publicação, titulo e lead\n    seletor_autor = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(1) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\", \n      \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2) &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; div &gt; span &gt; div &gt; div &gt; div &gt; div &gt; div &gt; p &gt; a\"\n    ]\n    seletor_titulo_lead = [\n      \"#root &gt; div &gt; div &gt; div:nth-child(3) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div &gt; div &gt; div:nth-child(2)\", \"#root &gt; div &gt; div &gt; div:nth-child(2) &gt; div &gt; article &gt; div &gt; div &gt; section &gt; div &gt; div:nth-child(3) &gt; div:nth-child(1) &gt; div &gt; div:nth-child(2)\"\n    ]\n  \n    # Inicializamos o objeto HTMLSession para fazer a coleta da informação dos artigos\n    request = HTMLSession()\n    try:\n      print(registro[\"link\"])\n      conteudo_html = request.get(registro[\"link\"])\n      autor = \"Not available\"\n      \n      for item in seletor_autor:\n        aux_autor = None\n        aux_autor = conteudo_html.html.find(item, first=True)\n        if aux_autor is not None:\n          autor = aux_autor\n          break\n\n      head = \"Not available\"\n      for item in seletor_titulo_lead:\n        aux_head = None\n        aux_head = conteudo_html.html.find(item, first=True)\n        if aux_head:\n          aux_lead = aux_head.find('h2', first=True)\n          if aux_lead is not None:\n            head = aux_lead.text\n          \n      registro[\"autores\"] = autor.text\n      registro[\"resumo\"] = head\n        \n      return registro\n    except:\n      print('URL {0} com erro. Verifique.'.format(registro[\"link\"]))\n      return None\n\nA função retorna_campos faz o scraping de dados de páginas da web, especificamente páginas de notícias ou artigos de blog do Medium. Ele pega um dicionário de “registro” como entrada, que parece conter um “link” para uma página da web.\nPasso-a-Passo:\n\nVariáveis seletor_autor e seletor_titulo_lead são listas de seletores CSS. Seletores CSS são padrões usados para selecionar os elementos que você deseja estilizar. Aqui, eles são usados para identificar os elementos HTML onde as informações de autor e título/lead estão localizadas no HTML da página.\nA função então inicia uma sessão HTML usando o módulo HTMLSession() do pacote requests_html, que é uma biblioteca Python para fazer solicitações HTTP e para parsing de HTML.\nA função tenta fazer uma solicitação GET para a URL que está no campo “link” do dicionário de entrada.\nEm seguida, a função tenta encontrar o autor do artigo. Para isso, itera sobre a lista seletor_autor e, para cada seletor, tenta encontrar um elemento correspondente na página HTML. Se encontrar um autor, interrompe o loop e guarda o autor encontrado.\nDepois disso, a função tenta encontrar o título do artigo da mesma maneira, usando a lista seletor_titulo_lead.\nOs resultados são então adicionados ao dicionário de entrada no campo “autores” para o autor e “resumo” para o título.\nSe houver algum erro durante o processo, como um link quebrado ou se o seletor CSS não corresponder a nenhum elemento, a função exibe uma mensagem de erro e retorna None.\nSe tudo correr bem, a função retorna o dicionário de entrada, agora com informações adicionais sobre o autor e o resumo do artigo.\n\nAgora vamos a execução da função para cada artigo em nossa lista. Observe que colocamos um limitador para fazer isso para 10 registros.\n\nartigos_comp = []\ni = 0\nfor item in artigos:\n    artigos_comp.append(retorna_campos(item))\n    i += 1\n    if i == 10:\n        break\n\nhttps://medium.com/p/e323b2d24987\nhttps://medium.com/p/9e9536ebd839\nhttps://medium.com/p/bb7d31ed2e76\nhttps://medium.com/p/2688e319e2a5\nhttps://medium.com/p/7edae42a20b3\nhttps://medium.com/p/f87419cb14cb\nhttps://medium.com/p/d6169fc81204\nhttps://medium.com/p/74361bc3b92e\nhttps://medium.com/p/9dc1566d960d\nhttps://medium.com/p/3c053357c47f\n\n\nAgora temos os nossos artigos com título, autor e uma lead line, que vai nos ajudar no processo da categorização.\nVamos agora, a nossa rotina de categorização, usando a API do OpenAI.\n\ndef retorna_categorias(titulo, resumo):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=f\"We have these categories: dbt, Python, DataViz, Tableau, PowerBI, and Generative AI. Given those categories, please classify the following text with those categories: {titulo} - {resumo}. You can use only the categories listed. You can classify with multiple categories. If you think that none of the categories applies, you can tag as Other.\",\n        temperature=0.8,\n        max_tokens=20,\n    )\n    return response.choices[0].text.strip()\n\nEste código define uma função chamada “retorna_categorias” que recebe dois parâmetros: “titulo” e “resumo”. A função utiliza a API OpenAI para classificar o título e o resumo com base em um conjunto de categorias previamente determinadas - dbt, Python, DataViz, Tableau, PowerBI e Generative AI. Em seguida, retorna o resultado da classificação como uma string.\nA função retorna então a primeira (e única) escolha da resposta da API OpenAI, que é a string que representa a categoria que foi escolhida como a melhor correspondência para o texto de entrada. O método strip() é usado para remover qualquer espaço em branco inicial ou final da string retornada.\nObservação: Para usar este código, o módulo openai precisa ser importado e uma chave de API OpenAI precisa ser obtida.\n\nlista_final = []\nfor item in artigos_comp:\n  item[\"categorias\"] = retorna_categorias(item['titulo'], item['resumo'])\n  lista_final.append(item)\n\nAgora que executamos a rotina acima, podemos imprimir os três primeiros registros e verificar que agora, temos categorias.\n\nfor idx, item in enumerate(lista_final):\n    print(json.dumps(item, indent=4))\n    if idx == 2:\n        break\n\n{\n    \"titulo\": \"Prompting ChatGPT for Python Code Generation: An Effective Framework\",\n    \"link\": \"https://medium.com/p/e323b2d24987\",\n    \"autores\": \"John Loewen\",\n    \"resumo\": \"I\\u2019ve done the prompt engineering research so you don\\u2019t have to\",\n    \"categorias\": \"Python, Generative AI\"\n}\n{\n    \"titulo\": \"Power BI: How I Started Using Python To Automate Tasks\",\n    \"link\": \"https://medium.com/p/9e9536ebd839\",\n    \"autores\": \"Gabe Araujo, M.Sc.\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"PowerBI, Python\"\n}\n{\n    \"titulo\": \"Chat with your databases using LangChain\",\n    \"link\": \"https://medium.com/p/bb7d31ed2e76\",\n    \"autores\": \"Vishnu Sivan\",\n    \"resumo\": \"Not available\",\n    \"categorias\": \"Other\"\n}\n\n\nE aí estão os nossos artigos, devidamente categorizados. Inclusive, podemos ver um artigo que foi classificado como “Other”, indicando que o texto que foi enviado não foi suficiente para classificar com as categorias selecionadas.\nObrigado por ler até aqui! Espero que este script seja útil para vocês!!!"
  },
  {
    "objectID": "posts/p0004-classif-texto/index.html#links-úteis",
    "href": "posts/p0004-classif-texto/index.html#links-úteis",
    "title": "AI na Análise de Dados - Classificação de Texto com a API da OpenAI",
    "section": "Links Úteis",
    "text": "Links Úteis\n\nUnderstanding GPT-3: OpenAI’s Language Generation AI: Blog oficial da OpenAI sobre GPT-3 - Apresenta uma explicação detalhada do GPT-3 e seu uso potencial\nData Classification in Machine Learning - Este é um artigo do site GeeksforGeeks que explica o conceito básico de classificação de dados em aprendizado de máquina, os diferentes tipos de algoritmos de classificação e como eles funcionam.\nBibliotecas Python utilizadas no artigo:\n\nrequests-html\nopenai\nBeautifulSoup4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WV Code - Educação e Consultoria",
    "section": "",
    "text": "Todos os posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAI na Análise de Dados - Classificação de Texto com a API da OpenAI\n\n\n\n\n\n\nOpenAI API\n\n\n\nVamos utilizar a API da OpenAI para executar uma das tarefas mais comuns em NLP - a classificação de textos.\n\n\n\n\n\nJun 16, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPower BI no Jupyter!\n\n\n\n\n\n\nPandas\n\n\nPower BI\n\n\nJupyter\n\n\n\nUse o Power BI para plotar gráficos no seu Jupyter Notebook.\n\n\n\n\n\nMay 30, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nPandas AI - Converse com seu DataFrame\n\n\n\n\n\n\nCiência de Dados\n\n\nPandas\n\n\nAI\n\n\nGPT\n\n\n\nNova biblioteca se propõe a permitir que você “converse” com o seu DataFrame.\n\n\n\n\n\nMay 29, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 06 - Linhas e Áreas\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nSeaborn\n\n\nMatPlotLib\n\n\n\nAnálise em dimensão contínua\n\n\n\n\n\nFeb 9, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 05 - Iniciando com Seaborn\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nMatPlotLib\n\n\nSeaborn\n\n\n\nApresentando os Gráficos de Barras!\n\n\n\n\n\nFeb 8, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 04 - Pandas\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\n\nPreparando dados para serem visualizados de maneira prática e intuitiva!\n\n\n\n\n\nFeb 7, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 03 - Formatos de Dados\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nTeoria\n\n\nptbr\n\n\n\nComo o dado precisa ser estruturado para que possamos visualizar de maneira correta?\n\n\n\n\n\nFeb 5, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 02 - Google Colab\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nGoogle Colab\n\n\nptbr\n\n\n\nConhecendo nossa ferramenta de trabalho…\n\n\n\n\n\nFeb 4, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nParte 01 - Teoria de Visualização de Dados\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nTeoria\n\n\nCiência de Dados\n\n\nptbr\n\n\n\nUm pouco de teoria antes de iniciar…\n\n\n\n\n\nFeb 3, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\n\n\n\n\n\n\nIntrodução\n\n\n\n\n\n\nVisualização\n\n\nPython\n\n\nPandas\n\n\nptbr\n\n\n\nIniciando com tudo!\n\n\n\n\n\nFeb 2, 2023\n\n\nWalter R. Paixão-Côrtes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "vanessa.html",
    "href": "vanessa.html",
    "title": "Vanessa S.M. Paixão-Côrtes",
    "section": "",
    "text": "Vanessa é professora, manda muito bem.\n\nFormação\n\nPUCRS\n\nDoutorado em Ciência da Computação - 2019\nMestrado em Ciência da Computação - 2015\n\nURI - Santo Ângelo\n\nBacharelado em Sistemas de Informação - 2013\nLicenciatura em Ciências Biológicas - 2004\n\n\n\n\nCertificados\nN/A\n\n\nExperiência\n\nTrybe\n\nPessoa Especialista - 2021 - 2022\n\nCESUCA\n\nProfessora - 2020 - 2021\n\nUFSCPA\n\nProfessora - 2020 - 2021"
  }
]